{"function":
[{
    "source file": "_arraytools2.py",
    "line number": "210",
    "func name": "zero_ext",
    "func arg": "(x, n, axis)",
    "comments": "Zero padding at the boundaries of an array\n\nGenerate a new ndarray that is a zero-padded extension of `x` along an axis.\n\nParameters ---------- x : ndarray The array to be extended. n : int The number of elements by which to extend `x` at each end of the axis. axis : int, optional The axis along which to extend `x`. Default is -1.\n\nExamples -------- >>> from scipy.signal._arraytools import zero_ext >>> a = np.array([[1, 2, 3, 4, 5], [0, 1, 4, 9, 16]]) >>> zero_ext(a, 2) array([[ 0,\n\n0,\n\n1,\n\n2,\n\n3,\n\n4,\n\n5,\n\n0,\n\n0], [ 0,\n\n0,\n\n0,\n\n1,\n\n4,\n\n9, 16,\n\n0,\n\n0]])\n"
},{
    "source file": "_backend.py",
    "line number": "404",
    "func name": "wrap_single_convertor",
    "func arg": "(convert_single)",
    "comments": "Wraps a ``__ua_convert__`` defined for a single element to all elements. If any of them return ``NotImplemented``, the operation is assumed to be undefined.\n\nAccepts a signature of (value, type, coerce).\n"
},{
    "source file": "_backend3.py",
    "line number": "151",
    "func name": "skip_backend",
    "func arg": "(backend)",
    "comments": "Context manager to skip a backend within a fixed scope.\n\nWithin the context of a ``with`` statement, the given backend will not be called. This covers backends registered both locally and globally. Upon exit, the backend will again be considered.\n\nParameters ---------- backend: {object, 'scipy'} The backend to skip. Can either be a ``str`` containing the name of a known backend {'scipy'} or an object that implements the uarray protocol.\n\nExamples -------- >>> import scipy.fft as fft >>> fft.fft([1])\n\n# Calls default SciPy backend array([1.+0.j]) >>> with fft.skip_backend('scipy'):\n\n# We explicitly skip the SciPy backend ...\n\n\n\n fft.fft([1])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n # leaving no implementation available Traceback (most recent call last): ... BackendNotImplementedError: No selected backends had an implementation ...\n"
},{
    "source file": "_basic.py",
    "line number": "2481",
    "func name": "zeta",
    "func arg": "(x, q, out)",
    "comments": "Riemann or Hurwitz zeta function.\n\nParameters ---------- x : array_like of float Input data, must be real q : array_like of float, optional Input data, must be real.\n\nDefaults to Riemann zeta. out : ndarray, optional Output array for the computed values.\n##### Returns\n* **out **: array_like\n    Values of zeta(x).\n\n* **.. math**: \n\n* **.. [dlmf] NIST, Digital Library of Mathematical Functions,\n    https**: //dlmf.nist.gov/25.11#i\n\n* **Some specific values**: \n\n* **Relation to the `polygamma` function**: \n\n"
},{
    "source file": "_basic4.py",
    "line number": "1568",
    "func name": "ihfft2",
    "func arg": "(x, s, axes, norm, overwrite_x, workers)",
    "comments": "Compute the 2-D inverse FFT of a real spectrum.\n\nParameters ---------- x : array_like The input array s : sequence of ints, optional Shape of the real input to the inverse FFT. axes : sequence of ints, optional The axes over which to compute the inverse fft. Default is the last two axes. norm : {None, \"ortho\"}, optional Normalization mode (see `fft`). Default is None. overwrite_x : bool, optional If True, the contents of `x` can be destroyed; the default is False. See :func:`fft` for more details. workers : int, optional Maximum number of workers to use for parallel computation. If negative, the value wraps around from ``os.cpu_count()``. See :func:`~scipy.fft.fft` for more details. plan: object, optional This argument is reserved for passing in a precomputed plan provided by downstream FFT vendors. It is currently not used in SciPy.\n\n.. versionadded:: 1.5.0\n##### Returns\n* **out **: ndarray\n    The result of the inverse real 2-D FFT.\n\n* **ihfftn **: Compute the inverse of the N-D FFT of Hermitian input.\n\n"
},{
    "source file": "_basinhopping.py",
    "line number": "720",
    "func name": "_test_func2d",
    "func arg": "(x)",
    "comments": ""
},{
    "source file": "_binned_statistic5.py",
    "line number": "705",
    "func name": "_bin_numbers",
    "func arg": "(sample, nbin, edges, dedges)",
    "comments": "Compute the bin number each sample falls into, in each dimension\n\n\n"
},{
    "source file": "_bsplines6.py",
    "line number": "854",
    "func name": "make_lsq_spline",
    "func arg": "(x, y, t, k, w, axis, check_finite)",
    "comments": "Compute the (coefficients of) an LSQ B-spline.\n\nThe result is a linear combination\n\n.. math::\n\nS(x) = \\sum_j c_j B_j(x; t)\n\nof the B-spline basis elements, :math:`B_j(x; t)`, which minimizes\n\n.. math::\n\n\\sum_{j} \\left( w_j \\times (S(x_j)\n\n- y_j) \\right)^2\n\nParameters ---------- x : array_like, shape (m,) Abscissas. y : array_like, shape (m, ...) Ordinates. t : array_like, shape (n + k + 1,). Knots. Knots and data points must satisfy Schoenberg-Whitney conditions. k : int, optional B-spline degree. Default is cubic, k=3. w : array_like, shape (n,), optional Weights for spline fitting. Must be positive. If ``None``, then weights are all equal. Default is ``None``. axis : int, optional Interpolation axis. Default is zero. check_finite : bool, optional Whether to check that the input arrays contain only finite numbers. Disabling may give a performance gain, but may result in problems (crashes, non-termination) if the inputs do contain infinities or NaNs. Default is True.\n##### Returns\n* **b **: a BSpline object of the degree `k` with knots `t`.\n\n* **Generate some noisy data**: \n\n* **Here we make the knot vector (k+1)-regular by adding boundary knots**: \n\n* **set of data**: \n\n* **Plot both**: \n\n* ****NaN handling****: If the input arrays contain ``nan`` values, the result is\n\n* **``nan``. A workaround is to use zero weights for not-a-number data points**: \n\n* **BSpline **: base class representing the B-spline objects\n\n* **make_interp_spline **: a similar factory function for interpolating splines\n\n* **LSQUnivariateSpline **: a FITPACK-based spline fitting routine\n\n* **splrep **: a FITPACK-based fitting routine\n\n"
},{
    "source file": "_bunch.py",
    "line number": "33",
    "func name": "_make_tuple_bunch",
    "func arg": "(typename, field_names, extra_field_names, module)",
    "comments": "Create a namedtuple-like class with additional attributes.\n\nThis function creates a subclass of tuple that acts like a namedtuple and that has additional attributes.\n\nThe additional attributes are listed in `extra_field_names`.\n\nThe values assigned to these attributes are not part of the tuple.\n\nThe reason this function exists is to allow functions in SciPy that currently return a tuple or a namedtuple to returned objects that have additional attributes, while maintaining backwards compatibility.\n\nThis should only be used to enhance *existing* functions in SciPy. New functions are free to create objects as return values without having to maintain backwards compatibility with an old tuple or namedtuple return value.\n\nParameters ---------- typename : str The name of the type. field_names : list of str List of names of the values to be stored in the tuple. These names will also be attributes of instances, so the values in the tuple can be accessed by indexing or as attributes.\n\nAt least one name is required.\n\nSee the Notes for additional restrictions. extra_field_names : list of str, optional List of names of values that will be stored as attributes of the object.\n\nSee the notes for additional restrictions.\n##### Returns\n* **cls **: type\n    The new class.\n\n* **and `extra_field_names`**: \n\n* **names `x` and `y`) that will also have the attributes `w` and `beta`**: \n\n* **`result1` acts like a tuple of length 2**: \n\n* **>>> result1[**: ]\n\n* **attributes**: \n\n"
},{
    "source file": "_bvp.py",
    "line number": "711",
    "func name": "solve_bvp",
    "func arg": "(fun, bc, x, y, p, S, fun_jac, bc_jac, tol, max_nodes, verbose, bc_tol)",
    "comments": "Solve a boundary value problem for a system of ODEs.\n\nThis function numerically solves a first order system of ODEs subject to two-point boundary conditions::\n\ndy / dx = f(x, y, p) + S * y / (x\n\n- a), a <= x <= b bc(y(a), y(b), p) = 0\n\nHere x is a 1-D independent variable, y(x) is an N-D vector-valued function and p is a k-D vector of unknown parameters which is to be found along with y(x). For the problem to be determined, there must be n + k boundary conditions, i.e., bc must be an (n + k)-D function.\n\nThe last singular term on the right-hand side of the system is optional. It is defined by an n-by-n matrix S, such that the solution must satisfy S y(a) = 0. This condition will be forced during iterations, so it must not contradict boundary conditions. See [2]_ for the explanation how this term is handled when solving BVPs numerically.\n\nProblems in a complex domain can be solved as well. In this case, y and p are considered to be complex, and f and bc are assumed to be complex-valued functions, but x stays real. Note that f and bc must be complex differentiable (satisfy Cauchy-Riemann equations [4]_), otherwise you should rewrite your problem for real and imaginary parts separately. To solve a problem in a complex domain, pass an initial guess for y with a complex data type (see below).\n\nParameters ---------- fun : callable Right-hand side of the system. The calling signature is ``fun(x, y)``, or ``fun(x, y, p)`` if parameters are present. All arguments are ndarray: ``x`` with shape (m,), ``y`` with shape (n, m), meaning that ``y[:, i]`` corresponds to ``x[i]``, and ``p`` with shape (k,). The return value must be an array with shape (n, m) and with the same layout as ``y``. bc : callable Function evaluating residuals of the boundary conditions. The calling signature is ``bc(ya, yb)``, or ``bc(ya, yb, p)`` if parameters are present. All arguments are ndarray: ``ya`` and ``yb`` with shape (n,), and ``p`` with shape (k,). The return value must be an array with shape (n + k,). x : array_like, shape (m,) Initial mesh. Must be a strictly increasing sequence of real numbers with ``x[0]=a`` and ``x[-1]=b``. y : array_like, shape (n, m) Initial guess for the function values at the mesh nodes, ith column corresponds to ``x[i]``. For problems in a complex domain pass `y` with a complex data type (even if the initial guess is purely real). p : array_like with shape (k,) or None, optional Initial guess for the unknown parameters. If None (default), it is assumed that the problem doesn't depend on any parameters. S : array_like with shape (n, n) or None Matrix defining the singular term. If None (default), the problem is solved without the singular term. fun_jac : callable or None, optional Function computing derivatives of f with respect to y and p. The calling signature is ``fun_jac(x, y)``, or ``fun_jac(x, y, p)`` if parameters are present. The return must contain 1 or 2 elements in the following order:\n\n* df_dy : array_like with shape (n, n, m), where an element (i, j, q) equals to d f_i(x_q, y_q, p) / d (y_q)_j. * df_dp : array_like with shape (n, k, m), where an element (i, j, q) equals to d f_i(x_q, y_q, p) / d p_j.\n\nHere q numbers nodes at which x and y are defined, whereas i and j number vector components. If the problem is solved without unknown parameters, df_dp should not be returned.\n\nIf `fun_jac` is None (default), the derivatives will be estimated by the forward finite differences. bc_jac : callable or None, optional Function computing derivatives of bc with respect to ya, yb, and p. The calling signature is ``bc_jac(ya, yb)``, or ``bc_jac(ya, yb, p)`` if parameters are present. The return must contain 2 or 3 elements in the following order:\n\n* dbc_dya : array_like with shape (n, n), where an element (i, j) equals to d bc_i(ya, yb, p) / d ya_j. * dbc_dyb : array_like with shape (n, n), where an element (i, j) equals to d bc_i(ya, yb, p) / d yb_j. * dbc_dp : array_like with shape (n, k), where an element (i, j) equals to d bc_i(ya, yb, p) / d p_j.\n\nIf the problem is solved without unknown parameters, dbc_dp should not be returned.\n\nIf `bc_jac` is None (default), the derivatives will be estimated by the forward finite differences. tol : float, optional Desired tolerance of the solution. If we define ``r = y'\n\n- f(x, y)``, where y is the found solution, then the solver tries to achieve on each mesh interval ``norm(r / (1 + abs(f)) < tol``, where ``norm`` is estimated in a root mean squared sense (using a numerical quadrature formula). Default is 1e-3. max_nodes : int, optional Maximum allowed number of the mesh nodes. If exceeded, the algorithm terminates. Default is 1000. verbose : {0, 1, 2}, optional Level of algorithm's verbosity:\n\n* 0 (default) : work silently. * 1 : display a termination report. * 2 : display progress during iterations. bc_tol : float, optional Desired absolute tolerance for the boundary condition residuals: `bc` value should satisfy ``abs(bc) < bc_tol`` component-wise. Equals to `tol` by default. Up to 10 iterations are allowed to achieve this tolerance.\n##### Returns\n* **Bunch object with the following fields defined**: \n\n* **sol **: PPoly\n    Found solution for y as `scipy.interpolate.PPoly` instance, a C1\n    continuous cubic spline.\n\n* **p **: ndarray or None, shape (k,)\n    Found parameters. None, if the parameters were not present in the\n    problem.\n\n* **x **: ndarray, shape (m,)\n    Nodes of the final mesh.\n\n* **y **: ndarray, shape (n, m)\n    Solution values at the mesh nodes.\n\n* **yp **: ndarray, shape (n, m)\n    Solution derivatives at the mesh nodes.\n\n* **rms_residuals **: ndarray, shape (m - 1,)\n    RMS values of the relative residuals over each mesh interval (see the\n    description of `tol` parameter).\n\n* **niter **: int\n    Number of completed iterations.\n\n* **status **: int\n    Reason for algorithm termination\n\n* **message **: string\n    Verbal description of the termination reason.\n\n* **success **: bool\n    True if the algorithm converged to the desired accuracy (``status=0``).\n\n* **.. versionadded**: \n\n* **.. [4] `Cauchy-Riemann equations\n        <https**: //en.wikipedia.org/wiki/Cauchy-Riemann_equations>`_ on\n        Wikipedia.\n\n* **In the first example, we solve Bratu's problem**: \n\n* **right-hand side evaluation**: \n\n* **>>> def fun(x, y)**: \n\n* **Implement evaluation of the boundary condition residuals**: \n\n* **>>> def bc(ya, yb)**: \n\n* **Define the initial mesh with 5 nodes**: \n\n* **In the second example, we solve a simple Sturm-Liouville problem**: \n\n* **A = 1 we add a boundary condition**: \n\n* **>>> def fun(x, y, p)**: \n\n* **Implement the boundary conditions**: \n\n* **>>> def bc(ya, yb, p)**: \n\n* **sin(2 * pi * x)**: \n\n* **We see that the found k is approximately correct**: \n\n* **And, finally, plot the solution to see the anticipated sinusoid**: \n\n"
},{
    "source file": "_ccallback.py",
    "line number": "225",
    "func name": "_get_cffi_data",
    "func arg": "(data)",
    "comments": ""
},{
    "source file": "_constraints.py",
    "line number": "426",
    "func name": "old_constraint_to_new",
    "func arg": "(ic, con)",
    "comments": "Converts old-style constraint dictionaries to new-style constraint objects.\n\n\n"
},{
    "source file": "_continuous_distns8.py",
    "line number": "8389",
    "func name": "_argus_phi",
    "func arg": "(chi)",
    "comments": "Utility function for the argus distribution used in the CDF and norm of the Argus Funktion\n\n\n"
},{
    "source file": "_cubic9.py",
    "line number": "302",
    "func name": "pchip_interpolate",
    "func arg": "(xi, yi, x, der, axis)",
    "comments": "Convenience function for pchip interpolation.\n\nxi and yi are arrays of values used to approximate some function f, with ``yi = f(xi)``. The interpolant uses monotonic cubic splines to find the value of new points x and the derivatives there.\n\nSee `scipy.interpolate.PchipInterpolator` for details.\n\nParameters ---------- xi : array_like A sorted list of x-coordinates, of length N. yi :\n\narray_like A 1-D array of real values. `yi`'s length along the interpolation axis must be equal to the length of `xi`. If N-D array, use axis parameter to select correct axis. x : scalar or array_like Of length M. der : int or list, optional Derivatives to extract. The 0th derivative can be included to return the function value. axis : int, optional Axis in the yi array corresponding to the x-coordinate values.\n\nSee Also -------- PchipInterpolator : PCHIP 1-D monotonic cubic interpolator.\n##### Returns\n* **y **: scalar or array_like\n    The result, of length R or length M or M by R,\n\n* **We can interpolate 2D observed data using pchip interpolation**: \n\n"
},{
    "source file": "_cython_signature_generator.py",
    "line number": "55",
    "func name": "sigs_from_dir",
    "func arg": "(directory, outfile, manual_wrappers, exclusions)",
    "comments": ""
},{
    "source file": "_decomp_cossin.py",
    "line number": "12",
    "func name": "cossin",
    "func arg": "(X, p, q, separate, swap_sign, compute_u, compute_vh)",
    "comments": "Compute the cosine-sine (CS) decomposition of an orthogonal/unitary matrix.\n\nX is an ``(m, m)`` orthogonal/unitary matrix, partitioned as the following where upper left block has the shape of ``(p, q)``::\n\n\u250c\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u2510 \u2502 I\n\n0\n\n0 \u2502 0\n\n0\n\n0 \u2502 \u250c\n\n\n\n\n\n\n\n\n\n \u2510\n\n \u250c\n\n\n\n\n\n\n\n \u2510\u2502 0\n\nC\n\n0 \u2502 0 -S\n\n0 \u2502\u250c\n\n\n\n\n\n\n\n \u2510* \u2502 X11 \u2502 X12 \u2502\n\n \u2502 U1 \u2502\n\n\n\n\u2502\u2502 0\n\n0\n\n0 \u2502 0\n\n0 -I \u2502\u2502 V1 \u2502\n\n\n\n\u2502 \u2502 \u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500 \u2502 = \u2502\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2502\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u2502\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2502 \u2502 X21 \u2502 X22 \u2502\n\n \u2502\n\n\n\n\u2502 U2 \u2502\u2502 0\n\n0\n\n0 \u2502 I\n\n0\n\n0 \u2502\u2502\n\n\n\n\u2502 V2 \u2502 \u2514\n\n\n\n\n\n\n\n\n\n \u2518\n\n \u2514\n\n\n\n\n\n\n\n \u2518\u2502 0\n\nS\n\n0 \u2502 0\n\nC\n\n0 \u2502\u2514\n\n\n\n\n\n\n\n \u2518 \u2502 0\n\n0\n\nI \u2502 0\n\n0\n\n0 \u2502 \u2514\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \u2518\n\n``U1``, ``U2``, ``V1``, ``V2`` are square orthogonal/unitary matrices of dimensions ``(p,p)``, ``(m-p,m-p)``, ``(q,q)``, and ``(m-q,m-q)`` respectively, and ``C`` and ``S`` are ``(r, r)`` nonnegative diagonal matrices satisfying ``C^2 + S^2 = I`` where ``r = min(p, m-p, q, m-q)``.\n\nMoreover, the rank of the identity matrices are ``min(p, q)\n\n- r``, ``min(p, m\n\n- q)\n\n- r``, ``min(m\n\n- p, q)\n\n- r``, and ``min(m\n\n- p, m\n\n- q)\n\n- r`` respectively.\n\nX can be supplied either by itself and block specifications p, q or its subblocks in an iterable from which the shapes would be derived. See the examples below.\n\nParameters ---------- X : array_like, iterable complex unitary or real orthogonal matrix to be decomposed, or iterable of subblocks ``X11``, ``X12``, ``X21``, ``X22``, when ``p``, ``q`` are omitted. p : int, optional Number of rows of the upper left block ``X11``, used only when X is given as an array. q : int, optional Number of columns of the upper left block ``X11``, used only when X is given as an array. separate : bool, optional if ``True``, the low level components are returned instead of the matrix factors, i.e. ``(u1,u2)``, ``theta``, ``(v1h,v2h)`` instead of ``u``, ``cs``, ``vh``. swap_sign : bool, optional if ``True``, the ``-S``, ``-I`` block will be the bottom left, otherwise (by default) they will be in the upper right block. compute_u : bool, optional if ``False``, ``u`` won't be computed and an empty array is returned. compute_vh : bool, optional if ``False``, ``vh`` won't be computed and an empty array is returned.\n##### Returns\n* **u **: ndarray\n    When ``compute_u=True``, contains the block diagonal orthogonal/unitary\n    matrix consisting of the blocks ``U1`` (``p`` x ``p``) and ``U2``\n    (``m-p`` x ``m-p``) orthogonal/unitary matrices. If ``separate=True``,\n    this contains the tuple of ``(U1, U2)``.\n\n* **cs **: ndarray\n    The cosine-sine factor with the structure described above.\n     If ``separate=True``, this contains the ``theta`` array containing the\n     angles in radians.\n\n* **vh **: ndarray\n    When ``compute_vh=True`, contains the block diagonal orthogonal/unitary\n    matrix consisting of the blocks ``V1H`` (``q`` x ``q``) and ``V2H``\n    (``m-q`` x ``m-q``) orthogonal/unitary matrices. If ``separate=True``,\n    this contains the tuple of ``(V1H, V2H)``.\n\n* **>>> ue, cs, vdh = cossin((x[**: 2,\n\n* **.. [1] **: Brian D. Sutton. Computing the complete CS decomposition. Numer.\n       Algorithms, 50(1)\n\n"
},{
    "source file": "_decomp_ldl.py",
    "line number": "298",
    "func name": "_ldl_construct_tri_factor",
    "func arg": "(lu, swap_vec, pivs, lower)",
    "comments": "Helper function to construct explicit outer factors of LDL factorization.\n\nIf lower is True the permuted factors are multiplied as L(1)*L(2)*...*L(k). Otherwise, the permuted factors are multiplied as L(k)*...*L(2)*L(1). See LAPACK documentation for more details.\n\nParameters ---------- lu : ndarray The triangular array that is extracted from LAPACK routine call with ones on the diagonals. swap_vec : ndarray The array that defines the row swapping indices. If the kth entry is m then rows k,m are swapped. Notice that the mth entry is not necessarily k to avoid undoing the swapping. pivs : ndarray The array that defines the block diagonal structure returned by _ldl_sanitize_ipiv(). lower : bool, optional The boolean to switch between lower and upper triangular structure.\n##### Returns\n* **lu **: ndarray\n    The square outer factor which satisfies the L * D * L.T = A\n\n* **perm **: ndarray\n    The permutation vector that brings the lu to the triangular form\n\n"
},{
    "source file": "_decomp_polar.py",
    "line number": "8",
    "func name": "polar",
    "func arg": "(a, side)",
    "comments": "Compute the polar decomposition.\n\n\n##### Returns\n* **u **: (m, n) ndarray\n    If `a` is square, then `u` is unitary. If m > n, then the columns\n    of `a` are orthonormal, and if m < n, then the rows of `u` are\n    orthonormal.\n\n* **p **: ndarray\n    `p` is Hermitian positive semidefinite. If `a` is nonsingular, `p`\n    is positive definite. The shape of `p` is (n, n) or (m, m), depending\n    on whether `side` is \"right\" or \"left\", respectively.\n\n* **.. [2] N. J. Higham, \"Functions of Matrices**: Theory and Computation\",\n       SIAM, 2008.\n\n* **A non-square example, with m < n**: \n\n* **Another non-square example, with m > n**: \n\n"
},{
    "source file": "_decomp_qz.py",
    "line number": "265",
    "func name": "ordqz",
    "func arg": "(A, B, sort, output, overwrite_a, overwrite_b, check_finite)",
    "comments": "QZ decomposition for a pair of matrices with reordering.\n\n.. versionadded:: 0.17.0\n\nParameters ---------- A : (N, N) array_like 2-D array to decompose B : (N, N) array_like 2-D array to decompose sort : {callable, 'lhp', 'rhp', 'iuc', 'ouc'}, optional Specifies whether the upper eigenvalues should be sorted. A callable may be passed that, given an ordered pair ``(alpha, beta)`` representing the eigenvalue ``x = (alpha/beta)``, returns a boolean denoting whether the eigenvalue should be sorted to the top-left (True). For the real matrix pairs ``beta`` is real while ``alpha`` can be complex, and for complex matrix pairs both ``alpha`` and ``beta`` can be complex. The callable must be able to accept a NumPy array. Alternatively, string parameters may be used:\n\n- 'lhp'\n\n Left-hand plane (x.real < 0.0)\n\n- 'rhp'\n\n Right-hand plane (x.real > 0.0)\n\n- 'iuc'\n\n Inside the unit circle (x*x.conjugate() < 1.0)\n\n- 'ouc'\n\n Outside the unit circle (x*x.conjugate() > 1.0)\n\nWith the predefined sorting functions, an infinite eigenvalue (i.e., ``alpha != 0`` and ``beta = 0``) is considered to lie in neither the left-hand nor the right-hand plane, but it is considered to lie outside the unit circle. For the eigenvalue ``(alpha, beta) = (0, 0)``, the predefined sorting functions all return `False`. output : str {'real','complex'}, optional Construct the real or complex QZ decomposition for real matrices. Default is 'real'. overwrite_a : bool, optional If True, the contents of A are overwritten. overwrite_b : bool, optional If True, the contents of B are overwritten. check_finite : bool, optional If true checks the elements of `A` and `B` are finite numbers. If false does no checking and passes matrix through to underlying algorithm.\n##### Returns\n* **AA **: (N, N) ndarray\n    Generalized Schur form of A.\n\n* **BB **: (N, N) ndarray\n    Generalized Schur form of B.\n\n* **alpha **: (N,) ndarray\n    alpha = alphar + alphai * 1j. See notes.\n\n* **beta **: (N,) ndarray\n    See notes.\n\n* **Q **: (N, N) ndarray\n    The left Schur vectors.\n\n* **Z **: (N, N) ndarray\n    The right Schur vectors.\n\n"
},{
    "source file": "_differentialevolution.py",
    "line number": "22",
    "func name": "differential_evolution",
    "func arg": "(func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, seed, callback, disp, polish, init, atol, updating, workers, constraints)",
    "comments": "Finds the global minimum of a multivariate function.\n\nDifferential Evolution is stochastic in nature (does not use gradient methods) to find the minimum, and can search large areas of candidate space, but often requires larger numbers of function evaluations than conventional gradient-based techniques.\n\nThe algorithm is due to Storn and Price [1]_.\n\nParameters ---------- func : callable The objective function to be minimized. Must be in the form ``f(x, *args)``, where ``x`` is the argument in the form of a 1-D array and ``args`` is a\n\ntuple of any additional fixed parameters needed to completely specify the function. bounds : sequence or `Bounds`, optional Bounds for variables. There are two ways to specify the bounds: 1. Instance of `Bounds` class. 2. ``(min, max)`` pairs for each element in ``x``, defining the finite lower and upper bounds for the optimizing argument of `func`. It is required to have ``len(bounds) == len(x)``. ``len(bounds)`` is used to determine the number of parameters in ``x``. args : tuple, optional Any additional fixed parameters needed to completely specify the objective function. strategy : str, optional The differential evolution strategy to use. Should be one of:\n\n- 'best1bin'\n\n- 'best1exp'\n\n- 'rand1exp'\n\n- 'randtobest1exp'\n\n- 'currenttobest1exp'\n\n- 'best2exp'\n\n- 'rand2exp'\n\n- 'randtobest1bin'\n\n- 'currenttobest1bin'\n\n- 'best2bin'\n\n- 'rand2bin'\n\n- 'rand1bin'\n\nThe default is 'best1bin'. maxiter : int, optional The maximum number of generations over which the entire population is evolved. The maximum number of function evaluations (with no polishing) is: ``(maxiter + 1) * popsize * len(x)`` popsize : int, optional A multiplier for setting the total population size. The population has ``popsize * len(x)`` individuals (unless the initial population is supplied via the `init` keyword). tol : float, optional Relative tolerance for convergence, the solving stops when ``np.std(pop) <= atol + tol * np.abs(np.mean(population_energies))``, where and `atol` and `tol` are the absolute and relative tolerance respectively. mutation : float or tuple(float, float), optional The mutation constant. In the literature this is also known as differential weight, being denoted by F. If specified as a float it should be in the range [0, 2]. If specified as a tuple ``(min, max)`` dithering is employed. Dithering randomly changes the mutation constant on a generation by generation basis. The mutation constant for that generation is taken from ``U[min, max)``. Dithering can help speed convergence significantly. Increasing the mutation constant increases the search radius, but will slow down convergence. recombination : float, optional The recombination constant, should be in the range [0, 1]. In the literature this is also known as the crossover probability, being denoted by CR. Increasing this value allows a larger number of mutants to progress into the next generation, but at the risk of population stability. seed : {int, `~np.random.RandomState`, `~np.random.Generator`}, optional If `seed` is not specified the `~np.random.RandomState` singleton is used. If `seed` is an int, a new ``RandomState`` instance is used, seeded with seed. If `seed` is already a ``RandomState`` or a ``Generator`` instance, then that object is used. Specify `seed` for repeatable minimizations. disp : bool, optional Prints the evaluated `func` at every iteration. callback : callable, `callback(xk, convergence=val)`, optional A function to follow the progress of the minimization. ``xk`` is the current value of ``x0``. ``val`` represents the fractional value of the population convergence.\n\nWhen ``val`` is greater than one the function halts. If callback returns `True`, then the minimization is halted (any polishing is still carried out). polish : bool, optional If True (default), then `scipy.optimize.minimize` with the `L-BFGS-B` method is used to polish the best population member at the end, which can improve the minimization slightly. If a constrained problem is being studied then the `trust-constr` method is used instead. init : str or array-like, optional Specify which type of population initialization is performed. Should be one of:\n\n- 'latinhypercube'\n\n- 'random'\n\n- array specifying the initial population. The array should have shape ``(M, len(x))``, where M is the total population size and len(x) is the number of parameters. `init` is clipped to `bounds` before use.\n\nThe default is 'latinhypercube'. Latin Hypercube sampling tries to maximize coverage of the available parameter space. 'random' initializes the population randomly\n\n- this has the drawback that clustering can occur, preventing the whole of parameter space being covered. Use of an array to specify a population subset could be used, for example, to create a tight bunch of initial guesses in an location where the solution is known to exist, thereby reducing time for convergence. atol : float, optional Absolute tolerance for convergence, the solving stops when ``np.std(pop) <= atol + tol * np.abs(np.mean(population_energies))``, where and `atol` and `tol` are the absolute and relative tolerance respectively. updating : {'immediate', 'deferred'}, optional If ``'immediate'``, the best solution vector is continuously updated within a single generation [4]_. This can lead to faster convergence as trial vectors can take advantage of continuous improvements in the best solution. With ``'deferred'``, the best solution vector is updated once per generation. Only ``'deferred'`` is compatible with parallelization, and the `workers` keyword can over-ride this option.\n\n.. versionadded:: 1.2.0\n\nworkers : int or map-like callable, optional If `workers` is an int the population is subdivided into `workers` sections and evaluated in parallel (uses `multiprocessing.Pool <multiprocessing>`). Supply -1 to use all available CPU cores. Alternatively supply a map-like callable, such as `multiprocessing.Pool.map` for evaluating the population in parallel. This evaluation is carried out as ``workers(func, iterable)``. This option will override the `updating` keyword to ``updating='deferred'`` if ``workers != 1``. Requires that `func` be pickleable.\n\n.. versionadded:: 1.2.0\n\nconstraints : {NonLinearConstraint, LinearConstraint, Bounds} Constraints on the solver, over and above those applied by the `bounds` kwd. Uses the approach by Lampinen [5]_.\n\n.. versionadded:: 1.4.0\n##### Returns\n* **res **: OptimizeResult\n    The optimization result represented as a `OptimizeResult` object.\n    Important attributes are\n\n* **is used to mutate the best member (the 'best' in 'best1bin'), **: math\n\n* **so far**: \n\n* **.. math**: \n\n* **.. versionadded**: \n\n* **>>> def constr_f(x)**: \n\n* **(https**: //en.wikipedia.org/wiki/Test_functions_for_optimization).\n\n* **>>> def ackley(x)**: \n\n* **.. [2] http**: //www1.icsi.berkeley.edu/~storn/code.html\n\n* **.. [3] http**: //en.wikipedia.org/wiki/Differential_evolution\n\n"
},{
    "source file": "_distn_infrastructure12.py",
    "line number": "3634",
    "func name": "get_distribution_names",
    "func arg": "(namespace_pairs, rv_base_class)",
    "comments": "Collect names of statistical distributions and their generators.\n\nParameters ---------- namespace_pairs : sequence A snapshot of (name, value) pairs in the namespace of a module. rv_base_class : class The base class of random variable generator classes in a module.\n##### Returns\n* **distn_names **: list of strings\n    Names of the statistical distributions.\n\n* **distn_gen_names **: list of strings\n    Names of the generators of the statistical distributions.\n    Note that these are not simply the names of the statistical\n    distributions, with a _gen suffix added.\n\n"
},{
    "source file": "_dual_annealing.py",
    "line number": "427",
    "func name": "dual_annealing",
    "func arg": "(func, bounds, args, maxiter, local_search_options, initial_temp, restart_temp_ratio, visit, accept, maxfun, seed, no_local_search, callback, x0)",
    "comments": "Find the global minimum of a function using Dual Annealing.\n\nParameters ---------- func : callable The objective function to be minimized. Must be in the form ``f(x, *args)``, where ``x`` is the argument in the form of a 1-D array and ``args`` is a\n\ntuple of any additional fixed parameters needed to completely specify the function. bounds : sequence, shape (n, 2) Bounds for variables.\n\n``(min, max)`` pairs for each element in ``x``, defining bounds for the objective function parameter. args : tuple, optional Any additional fixed parameters needed to completely specify the objective function. maxiter : int, optional The maximum number of global search iterations. Default value is 1000. local_search_options : dict, optional Extra keyword arguments to be passed to the local minimizer (`minimize`). Some important options could be: ``method`` for the minimizer method to use and ``args`` for objective function additional arguments. initial_temp : float, optional The initial temperature, use higher values to facilitates a wider search of the energy landscape, allowing dual_annealing to escape local minima that it is trapped in. Default value is 5230. Range is (0.01, 5.e4]. restart_temp_ratio : float, optional During the annealing process, temperature is decreasing, when it reaches ``initial_temp * restart_temp_ratio``, the reannealing process is triggered. Default value of the ratio is 2e-5. Range is (0, 1). visit : float, optional Parameter for visiting distribution. Default value is 2.62. Higher values give the visiting distribution a heavier tail, this makes the algorithm jump to a more distant region. The value range is (0, 3]. accept : float, optional Parameter for acceptance distribution. It is used to control the probability of acceptance. The lower the acceptance parameter, the smaller the probability of acceptance. Default value is -5.0 with a range (-1e4, -5]. maxfun : int, optional Soft limit for the number of objective function calls. If the algorithm is in the middle of a local search, this number will be exceeded, the algorithm will stop just after the local search is done. Default value is 1e7. seed : {int, `~numpy.random.RandomState`, `~numpy.random.Generator`}, optional If `seed` is not specified the `~numpy.random.RandomState` singleton is used. If `seed` is an int, a new ``RandomState`` instance is used, seeded with `seed`. If `seed` is already a ``RandomState`` or ``Generator`` instance, then that instance is used. Specify `seed` for repeatable minimizations. The random numbers generated with this seed only affect the visiting distribution function and new coordinates generation. no_local_search : bool, optional If `no_local_search` is set to True, a traditional Generalized Simulated Annealing will be performed with no local search strategy applied. callback : callable, optional A callback function with signature ``callback(x, f, context)``, which will be called for all minima found. ``x`` and ``f`` are the coordinates and function value of the latest minimum found, and ``context`` has value in [0, 1, 2], with the following meaning:\n\n- 0: minimum detected in the annealing process.\n\n- 1: detection occurred in the local search process.\n\n- 2: detection done in the dual annealing process.\n\nIf the callback implementation returns True, the algorithm will stop. x0 : ndarray, shape(n,), optional Coordinates of a single N-D starting point.\n##### Returns\n* **res **: OptimizeResult\n    The optimization result represented as a `OptimizeResult` object.\n    Important attributes are\n\n* **distribution, with its shape controlled by the parameter **: math\n\n* **.. math**: \n\n* **Where **: math\n\n* **to generate a trial jump distance **: math\n\n* ****: math\n\n* **function, the acceptance probability is computed as follows**: \n\n* **The artificial temperature **: math\n\n* **.. versionadded**: \n\n* **.. [5] Xiang Y, Gubian S, Suomela B, Hoeng J. Generalized\n    Simulated Annealing for Efficient Global Optimization**: the GenSA\n    Package for R. The R Journal, Volume 5/1 (2013).\n\n* **.. [6] Mullen, K. Continuous Global Optimization in R. Journal of\n    Statistical Software, 60(6), 1 - 45, (2014). DOI**: 10.18637/jss.v060.i06\n\n* **(https**: //en.wikipedia.org/wiki/Rastrigin_function)\n\n* **>>> func = lambda x**: np.sum(x*x - 10*np.cos(2*np.pi*x)) + 10*np.size(x)\n\n"
},{
    "source file": "_ellip_harm.py",
    "line number": "164",
    "func name": "ellip_normal",
    "func arg": "(h2, k2, n, p)",
    "comments": "Ellipsoidal harmonic normalization constants gamma^p_n\n\nThe normalization constant is defined as\n\n.. math::\n\n\\gamma^p_n=8\\int_{0}^{h}dx\\int_{h}^{k}dy\\frac{(y^2-x^2)(E^p_n(y)E^p_n(x))^2},{\\sqrt((k^2-y^2)(y^2-h^2)(h^2-x^2)(k^2-x^2)}\n\nParameters ---------- h2 : float ``h**2`` k2 : float ``k**2``; should be larger than ``h**2`` n : int Degree. p : int Order, can range between [1,2n+1].\n##### Returns\n* **gamma **: float\n    The normalization constant\n\n* **.. versionadded**: \n\n"
},{
    "source file": "_expm_frechet.py",
    "line number": "351",
    "func name": "expm_cond",
    "func arg": "(A, check_finite)",
    "comments": "Relative condition number of the matrix exponential in the Frobenius norm.\n\nParameters ---------- A : 2-D array_like Square input matrix with shape (N, N). check_finite : bool, optional Whether to check that the input matrix contains only finite numbers. Disabling may give a performance gain, but may result in problems (crashes, non-termination) if the inputs do contain infinities or NaNs.\n##### Returns\n* **kappa **: float\n    The relative condition number of the matrix exponential\n    in the Frobenius norm\n\n* **.. versionadded**: \n\n* **expm **: Compute the exponential of a matrix.\n\n* **expm_frechet **: Compute the Frechet derivative of the matrix exponential.\n\n"
},{
    "source file": "_expm_multiply14.py",
    "line number": "680",
    "func name": "_expm_multiply_interval_core_2",
    "func arg": "(A, X, h, mu, m_star, s, q, tol)",
    "comments": "A helper function, for the case q > s and q % s > 0.\n\n\n"
},{
    "source file": "_fitpack_impl15.py",
    "line number": "1229",
    "func name": "splantider",
    "func arg": "(tck, n)",
    "comments": "Compute the spline for the antiderivative (integral) of a given spline.\n\nParameters ---------- tck : tuple of (t, c, k) Spline whose antiderivative to compute n : int, optional Order of antiderivative to evaluate. Default: 1\n##### Returns\n* **tck_ader **: tuple of (t2, c2, k2)\n    Spline of order k2=k+n representing the antiderivative of the input\n    spline.\n\n* **.. versionadded**: \n\n* **although some floating point error accumulates**: \n\n* **Antiderivative can be used to evaluate definite integrals**: \n\n* ****: math\n\n"
},{
    "source file": "_fortran_format_parser.py",
    "line number": "31",
    "func name": "number_digits",
    "func arg": "(n)",
    "comments": ""
},{
    "source file": "_fortran16.py",
    "line number": "415",
    "func name": "get_blas_lapack_symbols",
    "func arg": "()",
    "comments": ""
},{
    "source file": "_gcrotmk17.py",
    "line number": "182",
    "func name": "gcrotmk",
    "func arg": "(A, b, x0, tol, maxiter, M, callback, m, k, CU, discard_C, truncate, atol)",
    "comments": "Solve a matrix equation using flexible GCROT(m,k) algorithm.\n\nParameters ---------- A : {sparse matrix, dense matrix, LinearOperator} The real or complex N-by-N matrix of the linear system. Alternatively, ``A`` can be a linear operator which can produce ``Ax`` using, e.g., ``scipy.sparse.linalg.LinearOperator``. b : {array, matrix} Right hand side of the linear system. Has shape (N,) or (N,1). x0\n\n: {array, matrix} Starting guess for the solution. tol, atol : float, optional Tolerances for convergence, ``norm(residual) <= max(tol*norm(b), atol)``. The default for ``atol`` is `tol`.\n\n.. warning::\n\nThe default value for `atol` will be changed in a future release. For future compatibility, specify `atol` explicitly. maxiter : int, optional Maximum number of iterations.\n\nIteration will stop after maxiter steps even if the specified tolerance has not been achieved. M : {sparse matrix, dense matrix, LinearOperator}, optional Preconditioner for A.\n\nThe preconditioner should approximate the inverse of A. gcrotmk is a 'flexible' algorithm and the preconditioner can vary from iteration to iteration. Effective preconditioning dramatically improves the rate of convergence, which implies that fewer iterations are needed to reach a given error tolerance. callback : function, optional User-supplied function to call after each iteration.\n\nIt is called as callback(xk), where xk is the current solution vector. m : int, optional Number of inner FGMRES iterations per each outer iteration. Default: 20 k : int, optional Number of vectors to carry between inner FGMRES iterations. According to [2]_, good values are around m. Default: m CU : list of tuples, optional List of tuples ``(c, u)`` which contain the columns of the matrices C and U in the GCROT(m,k) algorithm. For details, see [2]_. The list given and vectors contained in it are modified in-place. If not given, start from empty matrices. The ``c`` elements in the tuples can be ``None``, in which case the vectors are recomputed via ``c = A u`` on start and orthogonalized as described in [3]_. discard_C : bool, optional Discard the C-vectors at the end. Useful if recycling Krylov subspaces for different linear systems. truncate : {'oldest', 'smallest'}, optional Truncation scheme to use. Drop: oldest vectors, or vectors with smallest singular values using the scheme discussed in [1,2]. See [2]_ for detailed comparison. Default: 'oldest'\n##### Returns\n* **x **: array or matrix\n    The solution found.\n\n* **info **: int\n    Provides convergence information\n\n"
},{
    "source file": "_gcutils.py",
    "line number": "61",
    "func name": "assert_deallocated",
    "func arg": "(func, **kwargs)",
    "comments": "Context manager to check that object is deallocated\n\nThis is useful for checking that an object can be freed directly by reference counting, without requiring gc to break reference cycles. GC is disabled inside the context manager.\n\nThis check is not available on PyPy.\n\nParameters ---------- func : callable Callable to create object to check \\*args : sequence positional arguments to `func` in order to create object to check \\*\\*kwargs : dict keyword arguments to `func` in order to create object to check\n\nExamples -------- >>> class C(object): pass >>> with assert_deallocated(C) as c: ...\n\n\n\n # do something ...\n\n\n\n del c\n\n>>> class C(object): ...\n\n\n\n def __init__(self): ...\n\n\n\n\n\n\n\n self._circular = self # Make circular reference >>> with assert_deallocated(C) as c: #doctest: +IGNORE_EXCEPTION_DETAIL ...\n\n\n\n # do something ...\n\n\n\n del c Traceback (most recent call last): ... ReferenceError: Remaining reference(s) to object\n"
},{
    "source file": "_generate_pyx.py",
    "line number": "1442",
    "func name": "main",
    "func arg": "()",
    "comments": ""
},{
    "source file": "_generate_pyx18.py",
    "line number": "679",
    "func name": "make_all",
    "func arg": "(blas_signature_file, lapack_signature_file, blas_name, lapack_name, blas_fortran_name, lapack_fortran_name, blas_header_name, lapack_header_name)",
    "comments": ""
},{
    "source file": "_geometric_slerp19.py",
    "line number": "31",
    "func name": "geometric_slerp",
    "func arg": "(start, end, t, tol)",
    "comments": "Geometric spherical linear interpolation.\n\nThe interpolation occurs along a unit-radius great circle arc in arbitrary dimensional space.\n\nParameters ---------- start : (n_dimensions, ) array-like Single n-dimensional input coordinate in a 1-D array-like object. `n` must be greater than 1. end : (n_dimensions, ) array-like Single n-dimensional input coordinate in a 1-D array-like object. `n` must be greater than 1. t: float or (n_points,) array-like A float or array-like of doubles representing interpolation parameters, with values required in the inclusive interval between 0 and 1. A common approach is to generate the array with ``np.linspace(0, 1, n_pts)`` for linearly spaced points. Ascending, descending, and scrambled orders are permitted. tol: float The absolute tolerance for determining if the start and end coordinates are antipodes.\n##### Returns\n* **result **: (t.size, D)\n    An array of doubles containing the interpolated\n    spherical path and including start and\n    end when 0 and 1 t are used. The\n    interpolated values should correspond to the\n    same sort order provided in the t array. The result\n    may be 1-dimensional if ``t`` is a float.\n\n"
},{
    "source file": "_helper20.py",
    "line number": "69",
    "func name": "_init_nd_shape_and_axes",
    "func arg": "(x, shape, axes)",
    "comments": "Handle shape and axes arguments for N-D transforms.\n\n\n##### Returns\n* **shape **: array\n    The shape of the result. It is a 1-D integer array.\n\n* **axes **: array\n    The shape of the result. It is a 1-D integer array.\n\n"
},{
    "source file": "_hypotests21.py",
    "line number": "135",
    "func name": "_get_wilcoxon_distr",
    "func arg": "(n)",
    "comments": "Distribution of counts of the Wilcoxon ranksum statistic r_plus (sum of ranks of positive differences). Returns an array with the counts/frequencies of all the possible ranks r = 0, ..., n*(n+1)/2\n\n\n"
},{
    "source file": "_index22.py",
    "line number": "364",
    "func name": "_boolean_index_to_array",
    "func arg": "(idx)",
    "comments": ""
},{
    "source file": "_interpolative_backend.py",
    "line number": "1643",
    "func name": "idzr_rsvd",
    "func arg": "(m, n, matveca, matvec, k)",
    "comments": "Compute SVD of a complex matrix to a specified rank using random matrix-vector multiplication.\n\nparam m: Matrix row dimension. :type m: int :param n: Matrix column dimension. :type n: int :param matveca: Function to apply the matrix adjoint to a vector, with call signature `y = matveca(x)`, where `x` and `y` are the input and output vectors, respectively. :type matveca: function :param matvec: Function to apply the matrix to a vector, with call signature `y = matvec(x)`, where `x` and `y` are the input and output vectors, respectively. :type matvec: function :param k: Rank of SVD. :type k: int\n\n:return: Left singular vectors. :rtype: :class:`numpy.ndarray` :return: Right singular vectors. :rtype: :class:`numpy.ndarray` :return: Singular values. :rtype: :class:`numpy.ndarray`\n"
},{
    "source file": "_ksstats23.py",
    "line number": "567",
    "func name": "kolmogni",
    "func arg": "(n, q, cdf)",
    "comments": "Computes the PPF(or ISF) for the two-sided Kolmogorov-Smirnov distribution.\n\nParameters ---------- n : integer, array_like the number of samples q : float, array_like Probabilities, float between 0 and 1 cdf : bool, optional whether to compute the PPF(default=true) or the ISF.\n##### Returns\n* **ppf **: ndarray\n    PPF (or ISF if cdf is False) at the specified locations\n\n"
},{
    "source file": "_lambertw.py",
    "line number": "4",
    "func name": "lambertw",
    "func arg": "(z, k, tol)",
    "comments": "lambertw(z, k=0, tol=1e-8)\n\nLambert W function.\n\nThe Lambert W function `W(z)` is defined as the inverse function of ``w * exp(w)``. In other words, the value of ``W(z)`` is such that ``z = W(z) * exp(W(z))`` for any complex number ``z``.\n\nThe Lambert W function is a multivalued function with infinitely many branches. Each branch gives a separate solution of the equation ``z = w exp(w)``. Here, the branches are indexed by the integer `k`.\n\nParameters ---------- z : array_like Input argument. k : int, optional Branch index. tol : float, optional Evaluation tolerance.\n##### Returns\n* **w **: array\n    `w` will have the same shape as `z`.\n\n* **All branches are supported by `lambertw`**: \n\n* **The Lambert W function has two partially real branches**: the\n\n* **wrightomega **: the Wright Omega function\n\n* **.. [1] https**: //en.wikipedia.org/wiki/Lambert_W_function\n\n* **.. [2] Corless et al, \"On the Lambert W function\", Adv. Comp. Math. 5\n   (1996) 329-359.\n   https**: //cs.uwaterloo.ca/research/tr/1993/03/W.pdf\n\n* **The Lambert W function is the inverse of ``w exp(w)``**: \n\n* **Any branch gives a valid inverse**: \n\n* **tower **: math\n\n* **>>> def tower(z, n)**: \n\n* **...     if n == 0**: \n\n"
},{
    "source file": "_laplacian24.py",
    "line number": "112",
    "func name": "_laplacian_dense",
    "func arg": "(graph, normed, axis)",
    "comments": ""
},{
    "source file": "_linprog_ip.py",
    "line number": "820",
    "func name": "_linprog_ip",
    "func arg": "(c, c0, A, b, callback, postsolve_args, maxiter, tol, disp, alpha0, beta, sparse, lstsq, sym_pos, cholesky, pc, ip, permc_spec, **unknown_options)",
    "comments": "Minimize a linear objective function subject to linear equality and non-negativity constraints using the interior point method of [4]_. Linear programming is intended to solve problems of the following form\n\nMinimize::\n\nc @ x\n\nSubject to::\n\nA @ x == b x >= 0\n\nParameters ---------- c : 1-D array Coefficients of the linear objective function to be minimized. c0 : float Constant term in objective function due to fixed (and eliminated) variables. (Purely for display.) A : 2-D array 2-D array such that ``A @ x``, gives the values of the equality constraints at ``x``. b : 1-D array 1-D array of values representing the right hand side of each equality constraint (row) in ``A``. callback : callable, optional Callback function to be executed once per iteration. postsolve_args : tuple Data needed by _postsolve to convert the solution to the standard-form problem into the solution to the original problem.\n\nOptions ------- maxiter : int (default = 1000) The maximum number of iterations of the algorithm. tol : float (default = 1e-8) Termination tolerance to be used for all termination criteria; see [4]_ Section 4.5. disp : bool (default = False) Set to ``True`` if indicators of optimization status are to be printed to the console each iteration. alpha0 : float (default = 0.99995) The maximal step size for Mehrota's predictor-corrector search direction; see :math:`\\beta_{3}` of [4]_ Table 8.1. beta : float (default = 0.1) The desired reduction of the path parameter :math:`\\mu` (see [6]_) when Mehrota's predictor-corrector is not in use (uncommon). sparse : bool (default = False) Set to ``True`` if the problem is to be treated as sparse after presolve. If either ``A_eq`` or ``A_ub`` is a sparse matrix, this option will automatically be set ``True``, and the problem will be treated as sparse even during presolve. If your constraint matrices contain mostly zeros and the problem is not very small (less than about 100 constraints or variables), consider setting ``True`` or providing ``A_eq`` and ``A_ub`` as sparse matrices. lstsq : bool (default = False) Set to ``True`` if the problem is expected to be very poorly conditioned. This should always be left ``False`` unless severe numerical difficulties are encountered. Leave this at the default unless you receive a warning message suggesting otherwise. sym_pos : bool (default = True) Leave ``True`` if the problem is expected to yield a well conditioned symmetric positive definite normal equation matrix (almost always). Leave this at the default unless you receive a warning message suggesting otherwise. cholesky : bool (default = True) Set to ``True`` if the normal equations are to be solved by explicit Cholesky decomposition followed by explicit forward/backward substitution. This is typically faster for problems that are numerically well-behaved. pc : bool (default = True) Leave ``True`` if the predictor-corrector method of Mehrota is to be used. This is almost always (if not always) beneficial. ip : bool (default = False) Set to ``True`` if the improved initial point suggestion due to [4]_ Section 4.3 is desired. Whether this is beneficial or not depends on the problem. permc_spec : str (default = 'MMD_AT_PLUS_A') (Has effect only with ``sparse = True``, ``lstsq = False``, ``sym_pos = True``, and no SuiteSparse.) A matrix is factorized in each iteration of the algorithm. This option specifies how to permute the columns of the matrix for sparsity preservation. Acceptable values are:\n\n- ``NATURAL``: natural ordering.\n\n- ``MMD_ATA``: minimum degree ordering on the structure of A^T A.\n\n- ``MMD_AT_PLUS_A``: minimum degree ordering on the structure of A^T+A.\n\n- ``COLAMD``: approximate minimum degree column ordering.\n\nThis option can impact the convergence of the interior point algorithm; test different values to determine which performs best for your problem. For more information, refer to ``scipy.sparse.linalg.splu``. unknown_options : dict Optional arguments not used by this particular solver. If `unknown_options` is non-empty a warning is issued listing all unused options.\n##### Returns\n* **x **: 1-D array\n    Solution vector.\n\n* **status **: int\n    An integer representing the exit status of the optimization\n\n* **message **: str\n    A string descriptor of the exit status of the optimization.\n\n* **iteration **: int\n    The number of iterations taken to solve the problem.\n\n* **For dense problems, solvers are tried in the following order**: \n\n* **For sparse problems**: \n\n* **problem in standard form**: \n\n* **Minimize**: \n\n* **Subject to**: \n\n* **Whereas the top level ``linprog`` module expects a problem of form**: \n\n* **.. [4] Andersen, Erling D., and Knud D. Andersen. \"The MOSEK interior point\n       optimizer for linear programming**: an implementation of the\n       homogeneous algorithm.\" High performance optimization. Springer US,\n       2000. 197-232.\n\n* **.. [6] Freund, Robert M. \"Primal-Dual Interior-Point Methods for Linear\n       Programming based on Newton's Method.\" Unpublished Course Notes,\n       March 2004. Available 2/25/2017 at\n       https**: //ocw.mit.edu/courses/sloan-school-of-management/15-084j-nonlinear-programming-spring-2004/lecture-notes/lec14_int_pt_mthd.pdf\n\n* **.. [8] Andersen, Erling D., and Knud D. Andersen. \"Presolving in linear\n       programming.\" Mathematical Programming 71.2 (1995)**: 221-245.\n\n* **.. [9] Bertsimas, Dimitris, and J. Tsitsiklis. \"Introduction to linear\n       programming.\" Athena Scientific 1 (1997)**: 997.\n\n"
},{
    "source file": "_linprog_rs.py",
    "line number": "403",
    "func name": "_linprog_rs",
    "func arg": "(c, c0, A, b, x0, callback, postsolve_args, maxiter, tol, disp, maxupdate, mast, pivot, **unknown_options)",
    "comments": "Solve the following linear programming problem via a two-phase revised simplex algorithm.\n\nminimize:\n\n\n\n c @ x\n\nsubject to:\n\nA @ x == b 0 <= x < oo\n\nParameters ---------- c : 1-D array Coefficients of the linear objective function to be minimized. c0 : float Constant term in objective function due to fixed (and eliminated) variables. (Currently unused.) A : 2-D array 2-D array which, when matrix-multiplied by ``x``, gives the values of the equality constraints at ``x``. b : 1-D array 1-D array of values representing the RHS of each equality constraint (row) in ``A_eq``. x0 : 1-D array, optional Starting values of the independent variables, which will be refined by the optimization algorithm. For the revised simplex method, these must correspond with a basic feasible solution. callback : callable, optional If a callback function is provided, it will be called within each iteration of the algorithm. The callback function must accept a single `scipy.optimize.OptimizeResult` consisting of the following fields:\n\nx : 1-D array Current solution vector. fun : float Current value of the objective function ``c @ x``. success : bool True only when an algorithm has completed successfully, so this is always False as the callback function is called only while the algorithm is still iterating. slack : 1-D array The values of the slack variables. Each slack variable corresponds to an inequality constraint. If the slack is zero, the corresponding constraint is active. con : 1-D array The (nominally zero) residuals of the equality constraints, that is, ``b\n\n- A_eq @ x``. phase : int The phase of the algorithm being executed. status : int For revised simplex, this is always 0 because if a different status is detected, the algorithm terminates. nit : int The number of iterations performed. message : str A string descriptor of the exit status of the optimization. postsolve_args : tuple Data needed by _postsolve to convert the solution to the standard-form problem into the solution to the original problem.\n\nOptions ------- maxiter : int The maximum number of iterations to perform in either phase. tol : float The tolerance which determines when a solution is \"close enough\" to zero in Phase 1 to be considered a basic feasible solution or close enough to positive to serve as an optimal solution. disp : bool Set to ``True`` if indicators of optimization status are to be printed to the console each iteration. maxupdate : int The maximum number of updates performed on the LU factorization. After this many updates is reached, the basis matrix is factorized from scratch. mast : bool Minimize Amortized Solve Time. If enabled, the average time to solve a linear system using the basis factorization is measured. Typically, the average solve time will decrease with each successive solve after initial factorization, as factorization takes much more time than the solve operation (and updates). Eventually, however, the updated factorization becomes sufficiently complex that the average solve time begins to increase. When this is detected, the basis is refactorized from scratch. Enable this option to maximize speed at the risk of nondeterministic behavior. Ignored if ``maxupdate`` is 0. pivot : \"mrc\" or \"bland\" Pivot rule: Minimum Reduced Cost (default) or Bland's rule. Choose Bland's rule if iteration limit is reached and cycling is suspected. unknown_options : dict Optional arguments not used by this particular solver. If `unknown_options` is non-empty a warning is issued listing all unused options.\n##### Returns\n* **x **: 1-D array\n    Solution vector.\n\n* **status **: int\n    An integer representing the exit status of the optimization\n\n* **message **: str\n    A string descriptor of the exit status of the optimization.\n\n* **iteration **: int\n    The number of iterations taken to solve the problem.\n\n"
},{
    "source file": "_linprog_simplex.py",
    "line number": "438",
    "func name": "_linprog_simplex",
    "func arg": "(c, c0, A, b, callback, postsolve_args, maxiter, tol, disp, bland, **unknown_options)",
    "comments": "Minimize a linear objective function subject to linear equality and non-negativity constraints using the two phase simplex method. Linear programming is intended to solve problems of the following form\n\nMinimize::\n\nc @ x\n\nSubject to::\n\nA @ x == b x >= 0\n\nParameters ---------- c : 1-D array Coefficients of the linear objective function to be minimized. c0 : float Constant term in objective function due to fixed (and eliminated) variables. (Purely for display.) A : 2-D array 2-D array such that ``A @ x``, gives the values of the equality constraints at ``x``. b : 1-D array 1-D array of values representing the right hand side of each equality constraint (row) in ``A``. callback : callable, optional If a callback function is provided, it will be called within each iteration of the algorithm. The callback function must accept a single `scipy.optimize.OptimizeResult` consisting of the following fields:\n\nx : 1-D array Current solution vector fun : float Current value of the objective function success : bool True when an algorithm has completed successfully. slack : 1-D array The values of the slack variables. Each slack variable corresponds to an inequality constraint. If the slack is zero, the corresponding constraint is active. con : 1-D array The (nominally zero) residuals of the equality constraints, that is, ``b\n\n- A_eq @ x`` phase : int The phase of the algorithm being executed. status : int An integer representing the status of the optimization::\n\n0 : Algorithm proceeding nominally 1 : Iteration limit reached 2 : Problem appears to be infeasible 3 : Problem appears to be unbounded 4 : Serious numerical difficulties encountered nit : int The number of iterations performed. message : str A string descriptor of the exit status of the optimization. postsolve_args : tuple Data needed by _postsolve to convert the solution to the standard-form problem into the solution to the original problem.\n\nOptions ------- maxiter : int The maximum number of iterations to perform. disp : bool If True, print exit status message to sys.stdout tol : float The tolerance which determines when a solution is \"close enough\" to zero in Phase 1 to be considered a basic feasible solution or close enough to positive to serve as an optimal solution. bland : bool If True, use Bland's anti-cycling rule [3]_ to choose pivots to prevent cycling. If False, choose pivots which should lead to a converged solution more quickly. The latter method is subject to cycling (non-convergence) in rare instances. unknown_options : dict Optional arguments not used by this particular solver. If `unknown_options` is non-empty a warning is issued listing all unused options.\n##### Returns\n* **x **: 1-D array\n    Solution vector.\n\n* **status **: int\n    An integer representing the exit status of the optimization\n\n* **message **: str\n    A string descriptor of the exit status of the optimization.\n\n* **iteration **: int\n    The number of iterations taken to solve the problem.\n\n* **.. [3] Bland, Robert G. New finite pivoting rules for the simplex method.\n       Mathematics of Operations Research (2), 1977**: pp. 103-107.\n\n* **problem in standard form**: \n\n* **Minimize**: \n\n* **Subject to**: \n\n* **Whereas the top level ``linprog`` module expects a problem of form**: \n\n"
},{
    "source file": "_linprog_util.py",
    "line number": "1353",
    "func name": "_check_result",
    "func arg": "(x, fun, status, slack, con, bounds, tol, message)",
    "comments": "Check the validity of the provided solution.\n\nA valid (optimal) solution satisfies all bounds, all slack variables are negative and all equality constraint residuals are strictly non-zero. Further, the lower-bounds, upper-bounds, slack and residuals contain no nan values.\n\nParameters ---------- x : 1-D array Solution vector to original linear programming problem fun: float optimal objective value for original problem status : int An integer representing the exit status of the optimization::\n\n0 : Optimization terminated successfully 1 : Iteration limit reached 2 : Problem appears to be infeasible 3 : Problem appears to be unbounded 4 : Serious numerical difficulties encountered\n\nslack : 1-D array The (non-negative) slack in the upper bound constraints, that is, ``b_ub\n\n- A_ub @ x`` con : 1-D array The (nominally zero) residuals of the equality constraints, that is, ``b\n\n- A_eq @ x`` bounds : 2D array The bounds on the original variables ``x`` message : str A string descriptor of the exit status of the optimization. tol : float Termination tolerance; see [1]_ Section 4.5.\n##### Returns\n* **status **: int\n    An integer representing the exit status of the optimization\n\n* **message **: str\n    A string descriptor of the exit status of the optimization.\n\n"
},{
    "source file": "_linprog.py",
    "line number": "163",
    "func name": "linprog",
    "func arg": "(c, A_ub, b_ub, A_eq, b_eq, bounds, method, callback, options, x0)",
    "comments": "Linear programming: minimize a linear objective function subject to linear equality and inequality constraints.\n\nLinear programming solves problems of the following form:\n\n.. math::\n\n\\min_x \\ & c^T x \\\\ \\mbox{such that} \\ & A_{ub} x \\leq b_{ub},\\\\ & A_{eq} x = b_{eq},\\\\ & l \\leq x \\leq u ,\n\nwhere :math:`x` is a vector of decision variables; :math:`c`, :math:`b_{ub}`, :math:`b_{eq}`, :math:`l`, and :math:`u` are vectors; and :math:`A_{ub}` and :math:`A_{eq}` are matrices.\n\nInformally, that's:\n\nminimize::\n\nc @ x\n\nsuch that::\n\nA_ub @ x <= b_ub A_eq @ x == b_eq lb <= x <= ub\n\nNote that by default ``lb = 0`` and ``ub = None`` unless specified with ``bounds``.\n\nParameters ---------- c : 1-D array The coefficients of the linear objective function to be minimized. A_ub : 2-D array, optional The inequality constraint matrix. Each row of ``A_ub`` specifies the coefficients of a linear inequality constraint on ``x``. b_ub : 1-D array, optional The inequality constraint vector. Each element represents an upper bound on the corresponding value of ``A_ub @ x``. A_eq : 2-D array, optional The equality constraint matrix. Each row of ``A_eq`` specifies the coefficients of a linear equality constraint on ``x``. b_eq : 1-D array, optional The equality constraint vector. Each element of ``A_eq @ x`` must equal the corresponding element of ``b_eq``. bounds : sequence, optional A sequence of ``(min, max)`` pairs for each element in ``x``, defining the minimum and maximum values of that decision variable. Use ``None`` to indicate that there is no bound. By default, bounds are ``(0, None)`` (all decision variables are non-negative). If a single tuple ``(min, max)`` is provided, then ``min`` and ``max`` will serve as bounds for all decision variables. method : {'interior-point', 'revised simplex', 'simplex'}, optional The algorithm used to solve the standard form problem. :ref:`'interior-point' <optimize.linprog-interior-point>` (default), :ref:`'revised simplex' <optimize.linprog-revised_simplex>`, and :ref:`'simplex' <optimize.linprog-simplex>` (legacy) are supported. callback : callable, optional If a callback function is provided, it will be called at least once per iteration of the algorithm. The callback function must accept a single `scipy.optimize.OptimizeResult` consisting of the following fields:\n\nx : 1-D array The current solution vector. fun : float The current value of the objective function ``c @ x``. success : bool ``True`` when the algorithm has completed successfully. slack : 1-D array The (nominally positive) values of the slack, ``b_ub\n\n- A_ub @ x``. con : 1-D array The (nominally zero) residuals of the equality constraints, ``b_eq\n\n- A_eq @ x``. phase : int The phase of the algorithm being executed. status : int An integer representing the status of the algorithm.\n\n``0`` : Optimization proceeding nominally.\n\n``1`` : Iteration limit reached.\n\n``2`` : Problem appears to be infeasible.\n\n``3`` : Problem appears to be unbounded.\n\n``4`` : Numerical difficulties encountered.\n\nnit : int The current iteration number. message : str A string descriptor of the algorithm status.\n\noptions : dict, optional A dictionary of solver options. All methods accept the following options:\n\nmaxiter : int Maximum number of iterations to perform. Default: see method-specific documentation. disp : bool Set to ``True`` to print convergence messages. Default: ``False``. autoscale : bool Set to ``True`` to automatically perform equilibration. Consider using this option if the numerical values in the constraints are separated by several orders of magnitude. Default: ``False``. presolve : bool Set to ``False`` to disable automatic presolve. Default: ``True``. rr : bool Set to ``False`` to disable automatic redundancy removal. Default: ``True``.\n\nFor method-specific options, see :func:`show_options('linprog') <show_options>`.\n\nx0 : 1-D array, optional Guess values of the decision variables, which will be refined by the optimization algorithm. This argument is currently used only by the 'revised simplex' method, and can only be used if `x0` represents a basic feasible solution.\n##### Returns\n* **res **: OptimizeResult\n    A\n\n* **show_options **: Additional options accepted by the solvers.\n\n* ****: ref\n\n* **.. versionadded**: \n\n* **problem simplifications. Specifically, it checks for**: \n\n* **Several potential improvements can be made here**: additional presolve\n\n* **.. [3] Bland, Robert G. New finite pivoting rules for the simplex method.\n       Mathematics of Operations Research (2), 1977**: pp. 103-107.\n\n* **.. [4] Andersen, Erling D., and Knud D. Andersen. \"The MOSEK interior point\n       optimizer for linear programming**: an implementation of the\n       homogeneous algorithm.\" High performance optimization. Springer US,\n       2000. 197-232.\n\n* **.. [5] Andersen, Erling D. \"Finding all linearly dependent rows in\n       large-scale linear programming.\" Optimization Methods and Software\n       6.3 (1995)**: 219-227.\n\n* **.. [6] Freund, Robert M. \"Primal-Dual Interior-Point Methods for Linear\n       Programming based on Newton's Method.\" Unpublished Course Notes,\n       March 2004. Available 2/25/2017 at\n       https**: //ocw.mit.edu/courses/sloan-school-of-management/15-084j-nonlinear-programming-spring-2004/lecture-notes/lec14_int_pt_mthd.pdf\n\n* **.. [7] Fourer, Robert. \"Solving Linear Programs by Interior-Point Methods.\"\n       Unpublished Course Notes, August 26, 2005. Available 2/25/2017 at\n       http**: //www.4er.org/CourseNotes/Book%20B/B-III.pdf\n\n* **.. [8] Andersen, Erling D., and Knud D. Andersen. \"Presolving in linear\n       programming.\" Mathematical Programming 71.2 (1995)**: 221-245.\n\n* **.. [9] Bertsimas, Dimitris, and J. Tsitsiklis. \"Introduction to linear\n       programming.\" Athena Scientific 1 (1997)**: 997.\n\n* **.. [11] Bartels, Richard H. \"A stabilization of the simplex method.\"\n        Journal in  Numerische Mathematik 16.5 (1971)**: 414-434.\n\n* **.. [12] Tomlin, J. A. \"On scaling linear programming problems.\"\n        Mathematical Programming Study 4 (1975)**: 146-166.\n\n* **Consider the following problem**: \n\n* **.. math**: \n\n* **multiplying both sides by a factor of **: math\n\n* **constraint is really the simple bound **: math\n\n* **Finally, since there are no bounds on **: math\n\n* **specify the bounds **: math\n\n* **into arrays and tuples, the input for this problem is**: \n\n* **>>> print(res)\n     con**: array([], dtype=float64)\n     fun\n\n"
},{
    "source file": "_logsumexp.py",
    "line number": "217",
    "func name": "log_softmax",
    "func arg": "(x, axis)",
    "comments": "Logarithm of softmax function\n\nlog_softmax(x) = log(softmax(x))\n\nParameters ---------- x : array_like Input array. axis : int or tuple of ints, optional Axis to compute values along. Default is None and softmax will be computed over the entire array `x`.\n##### Returns\n* **s **: ndarray or scalar\n    An array with the same shape as `x`. Exponential of the result will\n    sum to 1 along the specified axis. If `x` is a scalar, a scalar is\n    returned.\n\n* **.. versionadded**: \n\n* **>>> with np.errstate(divide='ignore')**: \n\n"
},{
    "source file": "_lsap.py",
    "line number": "16",
    "func name": "linear_sum_assignment",
    "func arg": "(cost_matrix, maximize)",
    "comments": "Solve the linear sum assignment problem.\n\nThe linear sum assignment problem is also known as minimum weight matching in bipartite graphs. A problem instance is described by a matrix C, where each C[i,j] is the cost of matching vertex i of the first partite set (a \"worker\") and vertex j of the second set (a \"job\"). The goal is to find a complete assignment of workers to jobs of minimal cost.\n\nFormally, let X be a boolean matrix where :math:`X[i,j] = 1` iff row i is assigned to column j. Then the optimal assignment has cost\n\n.. math:: \\min \\sum_i \\sum_j C_{i,j} X_{i,j}\n\nwhere, in the case where the matrix X is square, each row is assigned to exactly one column, and each column to exactly one row.\n\nThis function can also solve a generalization of the classic assignment problem where the cost matrix is rectangular. If it has more rows than columns, then not every row needs to be assigned to a column, and vice versa.\n\nParameters ---------- cost_matrix : array The cost matrix of the bipartite graph.\n\nmaximize : bool (default: False) Calculates a maximum weight matching if true.\n##### Returns\n* **row_ind, col_ind **: array\n    An array of row indices and one of corresponding column indices giving\n    the optimal assignment. The cost of the assignment can be computed\n    as ``cost_matrix[row_ind, col_ind].sum()``. The row indices will be\n    sorted; in the case of a square cost matrix they will be equal to\n    ``numpy.arange(cost_matrix.shape[0])``.\n\n* **.. versionadded**: \n\n* **1. https**: //en.wikipedia.org/wiki/Assignment_problem\n\n* **2. DF Crouse. On implementing 2D rectangular assignment algorithms.\n   *IEEE Transactions on Aerospace and Electronic Systems*,\n   52(4)**: 1679-1696, August 2016, https\n\n"
},{
    "source file": "_matfuncs_inv_ssq.py",
    "line number": "840",
    "func name": "_logm",
    "func arg": "(A)",
    "comments": "Compute the matrix logarithm.\n\nSee the logm docstring in matfuncs.py for more info.\n\nNotes ----- In this function we look at triangular matrices that are similar to the input matrix. If any diagonal entry of such a triangular matrix is exactly zero then the original matrix is singular. The matrix logarithm does not exist for such matrices, but in such cases we will pretend that the diagonal entries that are zero are actually slightly positive by an ad-hoc amount, in the interest of returning something more useful than NaN. This will cause a warning.\n"
},{
    "source file": "_matfuncs_sqrtm.py",
    "line number": "114",
    "func name": "sqrtm",
    "func arg": "(A, disp, blocksize)",
    "comments": "Matrix square root.\n\nParameters ---------- A : (N, N) array_like Matrix whose square root to evaluate disp : bool, optional Print warning if error in the result is estimated large instead of returning estimated error. (Default: True) blocksize : integer, optional If the blocksize is not degenerate with respect to the size of the input array, then use a blocked algorithm. (Default: 64)\n##### Returns\n* **sqrtm **: (N, N) ndarray\n    Value of the sqrt function at `A`\n\n* **errest **: float\n    (if disp == False)\n    Frobenius norm of the estimated error, ||err||_F / ||A||_F\n\n"
},{
    "source file": "_matrix_io25.py",
    "line number": "75",
    "func name": "load_npz",
    "func arg": "(file)",
    "comments": "Load a sparse matrix from a file using ``.npz`` format.\n\nParameters ---------- file : str or file-like object Either the file name (string) or an open file (file-like object) where the data will be loaded.\n##### Returns\n* **result **: csc_matrix, csr_matrix, bsr_matrix, dia_matrix or coo_matrix\n    A sparse matrix containing the loaded data.\n\n"
},{
    "source file": "_max_len_seq26.py",
    "line number": "22",
    "func name": "max_len_seq",
    "func arg": "(nbits, state, length, taps)",
    "comments": "Maximum length sequence (MLS) generator.\n\nParameters ---------- nbits : int Number of bits to use. Length of the resulting sequence will be ``(2**nbits)\n\n- 1``. Note that generating long sequences (e.g., greater than ``nbits == 16``) can take a long time. state : array_like, optional If array, must be of length ``nbits``, and will be cast to binary (bool) representation. If None, a seed of ones will be used, producing a repeatable representation. If ``state`` is all zeros, an error is raised as this is invalid. Default: None. length : int, optional Number of samples to compute. If None, the entire length ``(2**nbits)\n\n- 1`` is computed. taps : array_like, optional Polynomial taps to use (e.g., ``[7, 6, 1]`` for an 8-bit sequence). If None, taps will be automatically selected (for up to ``nbits == 32``).\n##### Returns\n* **seq **: array\n    Resulting MLS sequence of 0's and 1's.\n\n* **state **: array\n    The final state of the shift register.\n\n* **The algorithm for MLS generation is generically described in**: https\n\n* **option listed for each value of ``nbits`` in**: http\n\n* **.. versionadded**: \n\n* **MLS uses binary convention**: \n\n* **MLS has a white spectrum (except for DC)**: \n\n* **Circular autocorrelation of MLS is an impulse**: \n\n* **Linear autocorrelation of MLS is approximately an impulse**: \n\n"
},{
    "source file": "_minimize.py",
    "line number": "818",
    "func name": "standardize_constraints",
    "func arg": "(constraints, x0, meth)",
    "comments": "Converts constraints to the form required by the solver.\n\n\n"
},{
    "source file": "_mptestutils.py",
    "line number": "418",
    "func name": "mp_assert_allclose",
    "func arg": "(res, std, atol, rtol)",
    "comments": "Compare lists of mpmath.mpf's or mpmath.mpc's directly so that it can be done to higher precision than double.\n\n\n"
},{
    "source file": "_multivariate27.py",
    "line number": "2314",
    "func name": "_cho_inv_batch",
    "func arg": "(a, check_finite)",
    "comments": "Invert the matrices a_i, using a Cholesky factorization of A, where a_i resides in the last two dimensions of a and the other indices describe the index i.\n\nOverwrites the data in a.\n\nParameters ---------- a : array Array of matrices to invert, where the matrices themselves are stored in the last two dimensions. check_finite : bool, optional Whether to check that the input matrices contain only finite numbers. Disabling may give a performance gain, but may result in problems (crashes, non-termination) if the inputs do contain infinities or NaNs.\n##### Returns\n* **x **: array\n    Array of inverses of the matrices ``a_i``.\n\n* **scipy.linalg.cholesky **: Cholesky factorization of a matrix\n\n"
},{
    "source file": "_ni_support.py",
    "line number": "68",
    "func name": "_get_output",
    "func arg": "(output, input, shape)",
    "comments": ""
},{
    "source file": "_nnls.py",
    "line number": "7",
    "func name": "nnls",
    "func arg": "(A, b, maxiter)",
    "comments": "Solve ``argmin_x || Ax - b ||_2`` for ``x>=0``. This is a wrapper for a FORTRAN non-negative least squares solver.\n\nParameters ---------- A : ndarray Matrix ``A`` as shown above. b : ndarray Right-hand side vector. maxiter: int, optional Maximum number of iterations, optional. Default is ``3 * A.shape[1]``.\n##### Returns\n* **x **: ndarray\n    Solution vector.\n\n* **rnorm **: float\n    The residual, ``|| Ax-b ||_2``.\n\n* **lsq_linear **: Linear least squares with bounds on the variables\n\n"
},{
    "source file": "_norm28.py",
    "line number": "20",
    "func name": "norm",
    "func arg": "(x, ord, axis)",
    "comments": "Norm of a sparse matrix\n\nThis function is able to return one of seven different matrix norms, depending on the value of the ``ord`` parameter.\n\nParameters ---------- x : a sparse matrix Input sparse matrix. ord : {non-zero int, inf, -inf, 'fro'}, optional Order of the norm (see table under ``Notes``). inf means numpy's `inf` object. axis : {int, 2-tuple of ints, None}, optional If `axis` is an integer, it specifies the axis of `x` along which to compute the vector norms.\n\nIf `axis` is a 2-tuple, it specifies the axes that hold 2-D matrices, and the matrix norms of these matrices are computed.\n\nIf `axis` is None then either a vector norm (when `x` is 1-D) or a matrix norm (when `x` is 2-D) is returned.\n##### Returns\n* **n **: float or ndarray\n\n* **https**: //github.com/numpy/numpy/blob/master/numpy/linalg/linalg.py\n\n* **The following norms can be calculated**: \n\n* **The Frobenius norm is given by [1]_**: \n\n"
},{
    "source file": "_numdiff.py",
    "line number": "607",
    "func name": "check_derivative",
    "func arg": "(fun, jac, x0, bounds, args, kwargs)",
    "comments": "Check correctness of a function computing derivatives (Jacobian or gradient) by comparison with a finite difference approximation.\n\nParameters ---------- fun : callable Function of which to estimate the derivatives. The argument x passed to this function is ndarray of shape (n,) (never a scalar even if n=1). It must return 1-D array_like of shape (m,) or a scalar. jac : callable Function which computes Jacobian matrix of `fun`. It must work with argument x the same way as `fun`. The return value must be array_like or sparse matrix with an appropriate shape. x0 : array_like of shape (n,) or float Point at which to estimate the derivatives. Float will be converted to 1-D array. bounds : 2-tuple of array_like, optional Lower and upper bounds on independent variables. Defaults to no bounds. Each bound must match the size of `x0` or be a scalar, in the latter case the bound will be the same for all variables. Use it to limit the range of function evaluation. args, kwargs : tuple and dict, optional Additional arguments passed to `fun` and `jac`. Both empty by default. The calling signature is ``fun(x, *args, **kwargs)`` and the same for `jac`.\n##### Returns\n* **accuracy **: float\n    The maximum among all relative errors for elements with absolute values\n    higher than 1 and absolute errors for elements with absolute values\n    less or equal than 1. If `accuracy` is on the order of 1e-6 or lower,\n    then it is likely that your `jac` implementation is correct.\n\n* **approx_derivative **: Compute finite difference approximation of derivative.\n\n* **>>> def f(x, c1, c2)**: \n\n* **>>> def jac(x, c1, c2)**: \n\n"
},{
    "source file": "_ode.py",
    "line number": "825",
    "func name": "_vode_banded_jac_wrapper",
    "func arg": "(jacfunc, ml, jac_params)",
    "comments": "Wrap a banded Jacobian function with a function that pads the Jacobian with `ml` rows of zeros.\n\n\n"
},{
    "source file": "_onenormest29.py",
    "line number": "323",
    "func name": "_onenormest_core",
    "func arg": "(A, AT, t, itmax)",
    "comments": "Compute a lower bound of the 1-norm of a sparse matrix.\n\nParameters ---------- A : ndarray or other linear operator A linear operator that can produce matrix products. AT : ndarray or other linear operator The transpose of A. t : int, optional A positive parameter controlling the tradeoff between accuracy versus time and memory usage. itmax : int, optional Use at most this many iterations.\n##### Returns\n* **est **: float\n    An underestimate of the 1-norm of the sparse matrix.\n\n* **v **: ndarray, optional\n    The vector such that ||Av||_1 == est*||v||_1.\n    It can be thought of as an input to the linear operator\n    that gives an output with particularly large norm.\n\n* **w **: ndarray, optional\n    The vector Av which has relatively large 1-norm.\n    It can be thought of as an output of the linear operator\n    that is relatively large in norm compared to the input.\n\n* **nmults **: int, optional\n    The number of matrix products that were computed.\n\n* **nresamples **: int, optional\n    The number of times a parallel column was observed,\n    necessitating a re-randomization of the column.\n\n"
},{
    "source file": "_pade30.py",
    "line number": "6",
    "func name": "pade",
    "func arg": "(an, m, n)",
    "comments": "Return Pade approximation to a polynomial as the ratio of two polynomials.\n\nParameters ---------- an : (N,) array_like Taylor series coefficients. m : int The order of the returned approximating polynomial `q`. n : int, optional The order of the returned approximating polynomial `p`. By default, the order is ``len(an)-m``.\n##### Returns\n* **p, q **: Polynomial class\n    The Pade approximation of the polynomial defined by `an` is\n    ``p(x)/q(x)``.\n\n"
},{
    "source file": "_peak_finding31.py",
    "line number": "1189",
    "func name": "find_peaks_cwt",
    "func arg": "(vector, widths, wavelet, max_distances, gap_thresh, min_length, min_snr, noise_perc, window_size)",
    "comments": "Find peaks in a 1-D array with wavelet transformation.\n\nThe general approach is to smooth `vector` by convolving it with `wavelet(width)` for each width in `widths`. Relative maxima which appear at enough length scales, and with sufficiently high SNR, are accepted.\n\nParameters ---------- vector : ndarray 1-D array in which to find the peaks. widths : sequence 1-D array of widths to use for calculating the CWT matrix. In general, this range should cover the expected width of peaks of interest. wavelet : callable, optional Should take two parameters and return a 1-D array to convolve with `vector`. The first parameter determines the number of points of the returned wavelet array, the second parameter is the scale (`width`) of the wavelet. Should be normalized and symmetric. Default is the ricker wavelet. max_distances : ndarray, optional At each row, a ridge line is only connected if the relative max at row[n] is within ``max_distances[n]`` from the relative max at ``row[n+1]``.\n\nDefault value is ``widths/4``. gap_thresh : float, optional If a relative maximum is not found within `max_distances`, there will be a gap. A ridge line is discontinued if there are more than `gap_thresh` points without connecting a new relative maximum. Default is the first value of the widths array i.e. widths[0]. min_length : int, optional Minimum length a ridge line needs to be acceptable. Default is ``cwt.shape[0] / 4``, ie 1/4-th the number of widths. min_snr : float, optional Minimum SNR ratio. Default 1. The signal is the value of the cwt matrix at the shortest length scale (``cwt[0, loc]``), the noise is the `noise_perc`th percentile of datapoints contained within a window of `window_size` around ``cwt[0, loc]``. noise_perc : float, optional When calculating the noise floor, percentile of data points examined below which to consider noise. Calculated using `stats.scoreatpercentile`.\n\nDefault is 10. window_size : int, optional Size of window to use to calculate noise floor. Default is ``cwt.shape[1] / 20``.\n##### Returns\n* **peaks_indices **: ndarray\n    Indices of the locations in the `vector` where peaks were found.\n    The list is sorted.\n\n* **The algorithm is as follows**: 1. Perform a continuous wavelet transform on `vector`, for the supplied\n    `widths`. This is a convolution of `vector` with `wavelet(width)` for\n    each width in `widths`. See `cwt`.\n 2. Identify \"ridge lines\" in the cwt matrix. These are relative maxima\n    at each row, connected across adjacent rows. See identify_ridge_lines\n 3. Filter the ridge_lines using filter_ridge_lines.\n\n* **.. versionadded**: \n\n* **.. [1] Bioinformatics (2006) 22 (17)**: 2059-2065.\n\n"
},{
    "source file": "_pep440.py",
    "line number": "437",
    "func name": "_cmpkey",
    "func arg": "(epoch, release, pre, post, dev, local)",
    "comments": ""
},{
    "source file": "_plotutils32.py",
    "line number": "150",
    "func name": "voronoi_plot_2d",
    "func arg": "(vor, ax, **kw)",
    "comments": "Plot the given Voronoi diagram in 2-D\n\nParameters ---------- vor : scipy.spatial.Voronoi instance Diagram to plot ax : matplotlib.axes.Axes instance, optional Axes to plot on show_points: bool, optional Add the Voronoi points to the plot. show_vertices : bool, optional Add the Voronoi vertices to the plot. line_colors : string, optional Specifies the line color for polygon boundaries line_width : float, optional Specifies the line width for polygon boundaries line_alpha: float, optional Specifies the line alpha for polygon boundaries point_size: float, optional Specifies the size of points\n##### Returns\n* **fig **: matplotlib.figure.Figure instance\n    Figure for the plot\n\n* **Set of point**: \n\n* **Voronoi diagram of the points**: \n\n* **using `voronoi_plot_2d` for visualisation**: \n\n* **using `voronoi_plot_2d` for visualisation with enhancements**: \n\n"
},{
    "source file": "_procrustes.py",
    "line number": "12",
    "func name": "orthogonal_procrustes",
    "func arg": "(A, B, check_finite)",
    "comments": "Compute the matrix solution of the orthogonal Procrustes problem.\n\nGiven matrices A and B of equal shape, find an orthogonal matrix R that most closely maps A to B using the algorithm given in [1]_.\n\nParameters ---------- A : (M, N) array_like Matrix to be mapped. B : (M, N) array_like Target matrix. check_finite : bool, optional Whether to check that the input matrices contain only finite numbers. Disabling may give a performance gain, but may result in problems (crashes, non-termination) if the inputs do contain infinities or NaNs.\n##### Returns\n* **R **: (N, N) ndarray\n    The matrix solution of the orthogonal Procrustes problem.\n    Minimizes the Frobenius norm of ``(A @ R) - B``, subject to\n    ``R.T @ R = I``.\n\n* **scale **: float\n    Sum of the singular values of ``A.T @ B``.\n\n"
},{
    "source file": "_procrustes33.py",
    "line number": "15",
    "func name": "procrustes",
    "func arg": "(data1, data2)",
    "comments": "Procrustes analysis, a similarity test for two data sets.\n\nEach input matrix is a set of points or vectors (the rows of the matrix). The dimension of the space is the number of columns of each matrix. Given two identically sized matrices, procrustes standardizes both such that:\n\n- :math:`tr(AA^{T}) = 1`.\n\n- Both sets of points are centered around the origin.\n\nProcrustes ([1]_, [2]_) then applies the optimal transform to the second matrix (including scaling/dilation, rotations, and reflections) to minimize :math:`M^{2}=\\sum(data1-data2)^{2}`, or the sum of the squares of the pointwise differences between the two input datasets.\n\nThis function was not designed to handle datasets with different numbers of datapoints (rows).\n\nIf two data sets have different dimensionality (different number of columns), simply add columns of zeros to the smaller of the two.\n\nParameters ---------- data1 : array_like Matrix, n rows represent points in k (columns) space `data1` is the reference data, after it is standardised, the data from `data2` will be transformed to fit the pattern in `data1` (must have >1 unique points). data2 : array_like n rows of data in k space to be fit to `data1`.\n\nMust be the\n\nsame shape ``(numrows, numcols)`` as data1 (must have >1 unique points).\n##### Returns\n* **mtx1 **: array_like\n    A standardized version of `data1`.\n\n* **mtx2 **: array_like\n    The orientation of `data2` that best fits `data1`. Centered, but not\n    necessarily\n\n* **disparity **: float\n\n"
},{
    "source file": "_quad_vec.py",
    "line number": "588",
    "func name": "_quadrature_gk15",
    "func arg": "(a, b, f, norm_func)",
    "comments": "Gauss-Kronrod 15 quadrature with error estimate\n\n\n"
},{
    "source file": "_quadrature.py",
    "line number": "866",
    "func name": "newton_cotes",
    "func arg": "(rn, equal)",
    "comments": "Return weights and error coefficient for Newton-Cotes integration.\n\nSuppose we have (N+1) samples of f at the positions x_0, x_1, ..., x_N. Then an N-point Newton-Cotes formula for the integral between x_0 and x_N is:\n\n:math:`\\int_{x_0}^{x_N} f(x)dx = \\Delta x \\sum_{i=0}^{N} a_i f(x_i) + B_N (\\Delta x)^{N+2} f^{N+1} (\\xi)`\n\nwhere :math:`\\xi \\in [x_0,x_N]` and :math:`\\Delta x = \\frac{x_N-x_0},{N}` is the average samples spacing.\n\nIf the samples are equally-spaced and N is even, then the error term is :math:`B_N (\\Delta x)^{N+3} f^{N+2}(\\xi)`.\n\nParameters ---------- rn : int The integer order for equally-spaced data or the relative positions of the samples with the first sample at 0 and the last at N, where N+1 is the length of `rn`. N is the order of the Newton-Cotes integration. equal : int, optional Set to 1 to enforce equally spaced data.\n##### Returns\n* **an **: ndarray\n    1-D array of weights to apply to the function at the provided sample\n    positions.\n\n* **B **: float\n    Error coefficient.\n\n* **Compute the integral of sin(x) in [0, **: math\n\n* **>>> def f(x)**: \n\n* **>>> for N in [2, 4, 6, 8, 10]**: \n\n* **...     print('{**: 2d}  {\n\n"
},{
    "source file": "_realtransforms34.py",
    "line number": "572",
    "func name": "idst",
    "func arg": "(x, type, n, axis, norm, overwrite_x, workers)",
    "comments": "Return the Inverse Discrete Sine Transform of an arbitrary type sequence.\n\nParameters ---------- x : array_like The input array. type : {1, 2, 3, 4}, optional Type of the DST (see Notes). Default type is 2. n : int, optional Length of the transform. If ``n < x.shape[axis]``, `x` is truncated.\n\nIf ``n > x.shape[axis]``, `x` is zero-padded. The default results in ``n = x.shape[axis]``. axis : int, optional Axis along which the idst is computed; the default is over the last axis (i.e., ``axis=-1``). norm : {None, 'ortho'}, optional Normalization mode (see Notes). Default is None. overwrite_x : bool, optional If True, the contents of `x` can be destroyed; the default is False. workers : int, optional Maximum number of workers to use for parallel computation. If negative, the value wraps around from ``os.cpu_count()``. See :func:`~scipy.fft.fft` for more details.\n##### Returns\n* **idst **: ndarray of real\n    The transformed input array.\n\n* **dst **: Forward DST\n\n"
},{
    "source file": "_remove_redundancy.py",
    "line number": "361",
    "func name": "_remove_redundancy",
    "func arg": "(A, b)",
    "comments": "Eliminates redundant equations from system of equations defined by Ax = b and identifies infeasibilities.\n\nParameters ---------- A : 2-D array An array representing the left-hand side of a system of equations b : 1-D array An array representing the right-hand side of a system of equations\n##### Returns\n* **A **: 2-D array\n    An array representing the left-hand side of a system of equations\n\n* **b **: 1-D array\n    An array representing the right-hand side of a system of equations\n\n* **status**: int\n    An integer indicating the status of the system\n    0\n\n* **message **: str\n    A string descriptor of the exit status of the optimization.\n\n* **.. [2] Andersen, Erling D. \"Finding all linearly dependent rows in\n       large-scale linear programming.\" Optimization Methods and Software\n       6.3 (1995)**: 219-227.\n\n"
},{
    "source file": "_root_scalar.py",
    "line number": "442",
    "func name": "_root_scalar_bisect_doc",
    "func arg": "()",
    "comments": "Options ------- args : tuple, optional Extra arguments passed to the objective function. xtol : float, optional Tolerance (absolute) for termination. rtol : float, optional Tolerance (relative) for termination. maxiter : int, optional Maximum number of iterations. options: dict, optional Specifies any method-specific options not covered above.\n\n\n"
},{
    "source file": "_root.py",
    "line number": "589",
    "func name": "_root_krylov_doc",
    "func arg": "()",
    "comments": "Options ------- nit : int, optional Number of iterations to make. If omitted (default), make as many as required to meet tolerances. disp : bool, optional Print status to stdout on every iteration. maxiter : int, optional Maximum number of iterations to make. If more are needed to meet convergence, `NoConvergence` is raised. ftol : float, optional Relative tolerance for the residual. If omitted, not used. fatol : float, optional Absolute tolerance (in max-norm) for the residual. If omitted, default is 6e-6. xtol : float, optional Relative minimum step size. If omitted, not used. xatol : float, optional Absolute minimum step size, as determined from the Jacobian approximation. If the step size is smaller than this, optimization is terminated as successful. If omitted, not used. tol_norm : function(vector) -> scalar, optional Norm to use in convergence check. Default is the maximum norm. line_search : {None, 'armijo' (default), 'wolfe'}, optional Which type of a line search to use to determine the step size in the direction given by the Jacobian approximation. Defaults to 'armijo'. jac_options : dict, optional Options for the respective Jacobian approximation.\n\nrdiff : float, optional Relative step size to use in numerical differentiation. method : {'lgmres', 'gmres', 'bicgstab', 'cgs', 'minres'} or function Krylov method to use to approximate the Jacobian. Can be a string, or a function implementing the same interface as the iterative solvers in `scipy.sparse.linalg`.\n\nThe default is `scipy.sparse.linalg.lgmres`. inner_M : LinearOperator or InverseJacobian Preconditioner for the inner Krylov iteration. Note that you can use also inverse Jacobians as (adaptive) preconditioners. For example,\n\n>>> jac = BroydenFirst() >>> kjac = KrylovJacobian(inner_M=jac.inverse).\n\nIf the preconditioner has a method named 'update', it will be called as ``update(x, f)`` after each nonlinear step, with ``x`` giving the current point, and ``f`` the current function value. inner_tol, inner_maxiter, ... Parameters to pass on to the \"inner\" Krylov solver. See `scipy.sparse.linalg.gmres` for details. outer_k : int, optional Size of the subspace kept across LGMRES nonlinear iterations.\n\nSee `scipy.sparse.linalg.lgmres` for details.\n"
},{
    "source file": "_rotation_groups35.py",
    "line number": "108",
    "func name": "create_group",
    "func arg": "(cls, group, axis)",
    "comments": ""
},{
    "source file": "_rotation_spline36.py",
    "line number": "192",
    "func name": "_create_block_3_diagonal_matrix",
    "func arg": "(A, B, d)",
    "comments": "Create a 3-diagonal block matrix as banded.\n\nThe matrix has the following structure:\n\nDB... ADB.. .ADB. ..ADB ...AD\n\nThe blocks A, B and D are 3-by-3 matrices. The D matrices has the form d * I.\n\nParameters ---------- A : ndarray, shape (n, 3, 3) Stack of A blocks. B : ndarray, shape (n, 3, 3) Stack of B blocks. d : ndarray, shape (n + 1,) Values for diagonal blocks.\n##### Returns\n"
},{
    "source file": "_rvs_sampling37.py",
    "line number": "5",
    "func name": "rvs_ratio_uniforms",
    "func arg": "(pdf, umax, vmin, vmax, size, c, random_state)",
    "comments": "Generate random samples from a probability density function using the ratio-of-uniforms method.\n\nParameters ---------- pdf : callable A function with signature `pdf(x)` that is proportional to the probability density function of the distribution. umax : float The upper bound of the bounding rectangle in the u-direction. vmin : float The lower bound of the bounding rectangle in the v-direction. vmax : float The upper bound of the bounding rectangle in the v-direction. size : int or tuple of ints, optional Defining number of random variates (default is 1). c : float, optional. Shift parameter of ratio-of-uniforms method, see Notes. Default is 0. random_state : {None, int, `~np.random.RandomState`, `~np.random.Generator`}, optional If `random_state` is `None` the `~np.random.RandomState` singleton is used. If `random_state` is an int, a new ``RandomState`` instance is used, seeded with random_state. If `random_state` is already a ``RandomState`` or ``Generator`` instance, then that object is used. Default is None.\n##### Returns\n* **rvs **: ndarray\n    The random variates distributed according to the probability\n    distribution defined by the pdf.\n\n* **define the set ``A = {(u, v) **: 0 < u <= sqrt(pdf(v/u + c))}``.\n\n* **>>> f = lambda x**: np.exp(-x**2 / 2)\n\n* **distributed (normality is not rejected at 5% significance level)**: \n\n* **>>> rvs = stats.rvs_ratio_uniforms(lambda x**: np.exp(-x), umax=1,\n\n"
},{
    "source file": "_savitzky_golay38.py",
    "line number": "225",
    "func name": "savgol_filter",
    "func arg": "(x, window_length, polyorder, deriv, delta, axis, mode, cval)",
    "comments": "Apply a Savitzky-Golay filter to an array.\n\nThis is a 1-D filter. If `x`\n\nhas dimension greater than 1, `axis` determines the axis along which the filter is applied.\n\nParameters ---------- x : array_like The data to be filtered. If `x` is not a single or double precision floating point array, it will be converted to type ``numpy.float64`` before filtering. window_length : int The length of the filter window (i.e., the number of coefficients). `window_length` must be a positive odd integer. If `mode` is 'interp', `window_length` must be less than or equal to the size of `x`. polyorder : int The order of the polynomial used to fit the samples. `polyorder` must be less than `window_length`. deriv : int, optional The order of the derivative to compute. This must be a nonnegative integer. The default is 0, which means to filter the data without differentiating. delta : float, optional The spacing of the samples to which the filter will be applied. This is only used if deriv > 0. Default is 1.0. axis : int, optional The axis of the array `x` along which the filter is to be applied. Default is -1. mode : str, optional Must be 'mirror', 'constant', 'nearest', 'wrap' or 'interp'. This determines the type of extension to use for the padded signal to which the filter is applied.\n\nWhen `mode` is 'constant', the padding value is given by `cval`.\n\nSee the Notes for more details on 'mirror', 'constant', 'wrap', and 'nearest'. When the 'interp' mode is selected (the default), no extension is used.\n\nInstead, a degree `polyorder` polynomial is fit to the last `window_length` values of the edges, and this polynomial is used to evaluate the last `window_length // 2` output values. cval : scalar, optional Value to fill past the edges of the input if `mode` is 'constant'. Default is 0.0.\n##### Returns\n* **y **: ndarray, same shape as `x`\n    The filtered data.\n\n* **Details on the `mode` options**: 'mirror'\n\n* **the various `mode` options (assuming `cval` is 0)**: \n\n* **.. versionadded**: \n\n* **`mode='nearest'`**: \n\n"
},{
    "source file": "_shgo.py",
    "line number": "18",
    "func name": "shgo",
    "func arg": "(func, bounds, args, constraints, n, iters, callback, minimizer_kwargs, options, sampling_method)",
    "comments": "Finds the global minimum of a function using SHG optimization.\n\nSHGO stands for \"simplicial homology global optimization\".\n\nParameters ---------- func : callable The objective function to be minimized.\n\nMust be in the form ``f(x, *args)``, where ``x`` is the argument in the form of a 1-D array and ``args`` is a tuple of any additional fixed parameters needed to completely specify the function. bounds : sequence Bounds for variables.\n\n``(min, max)`` pairs for each element in ``x``, defining the lower and upper bounds for the optimizing argument of `func`. It is required to have ``len(bounds) == len(x)``. ``len(bounds)`` is used to determine the number of parameters in ``x``. Use ``None`` for one of min or max when there is no bound in that direction. By default bounds are ``(None, None)``. args : tuple, optional Any additional fixed parameters needed to completely specify the objective function. constraints : dict or sequence of dict, optional Constraints definition. Function(s) ``R**n`` in the form::\n\ng(x) >= 0 applied as g : R^n -> R^m h(x) == 0 applied as h : R^n -> R^p\n\nEach constraint is defined in a dictionary with fields:\n\ntype : str Constraint type: 'eq' for equality, 'ineq' for inequality. fun : callable The function defining the constraint. jac : callable, optional The Jacobian of `fun` (only for SLSQP). args : sequence, optional Extra arguments to be passed to the function and Jacobian.\n\nEquality constraint means that the constraint function result is to be zero whereas inequality means that it is to be non-negative. Note that COBYLA only supports inequality constraints.\n\n.. note::\n\nOnly the COBYLA and SLSQP local minimize methods currently support constraint arguments. If the ``constraints`` sequence used in the local optimization problem is not defined in ``minimizer_kwargs`` and a constrained method is used then the global ``constraints`` will be used. (Defining a ``constraints`` sequence in ``minimizer_kwargs`` means that ``constraints`` will not be added so if equality constraints and so forth need to be added then the inequality functions in ``constraints`` need to be added to ``minimizer_kwargs`` too).\n\nn : int, optional Number of sampling points used in the construction of the simplicial complex. Note that this argument is only used for ``sobol`` and other arbitrary `sampling_methods`. iters : int, optional Number of iterations used in the construction of the simplicial complex. callback : callable, optional Called after each iteration, as ``callback(xk)``, where ``xk`` is the current parameter vector. minimizer_kwargs : dict, optional Extra keyword arguments to be passed to the minimizer ``scipy.optimize.minimize`` Some important options could be:\n\n* method : str The minimization method (e.g. ``SLSQP``). * args : tuple Extra arguments passed to the objective function (``func``) and its derivatives (Jacobian, Hessian). * options : dict, optional Note that by default the tolerance is specified as ``{ftol: 1e-12}``\n\noptions : dict, optional A dictionary of solver options. Many of the options specified for the global routine are also passed to the scipy.optimize.minimize routine. The options that are also passed to the local routine are marked with \"(L)\".\n\nStopping criteria, the algorithm will terminate if any of the specified criteria are met. However, the default algorithm does not require any to be specified:\n\n* maxfev : int (L) Maximum number of function evaluations in the feasible domain. (Note only methods that support this option will terminate the routine at precisely exact specified value. Otherwise the criterion will only terminate during a global iteration) * f_min Specify the minimum objective function value, if it is known. * f_tol : float Precision goal for the value of f in the stopping criterion. Note that the global routine will also terminate if a sampling point in the global routine is within this tolerance. * maxiter : int Maximum number of iterations to perform. * maxev : int Maximum number of sampling evaluations to perform (includes searching in infeasible points). * maxtime : float Maximum processing runtime allowed * minhgrd : int Minimum homology group rank differential. The homology group of the objective function is calculated (approximately) during every iteration. The rank of this group has a one-to-one correspondence with the number of locally convex subdomains in the objective function (after adequate sampling points each of these subdomains contain a unique global minimum). If the difference in the hgr is 0 between iterations for ``maxhgrd`` specified iterations the algorithm will terminate.\n\nObjective function knowledge:\n\n* symmetry : bool Specify True if the objective function contains symmetric variables. The search space (and therefore performance) is decreased by O(n!).\n\n* jac : bool or callable, optional Jacobian (gradient) of objective function. Only for CG, BFGS, Newton-CG, L-BFGS-B, TNC, SLSQP, dogleg, trust-ncg. If ``jac`` is a boolean and is True, ``fun`` is assumed to return the gradient along with the objective function. If False, the gradient will be estimated numerically. ``jac`` can also be a callable returning the gradient of the objective. In this case, it must accept the same arguments as ``fun``. (Passed to `scipy.optimize.minmize` automatically)\n\n* hess, hessp : callable, optional Hessian (matrix of second-order derivatives) of objective function or Hessian of objective function times an arbitrary vector p. Only for Newton-CG, dogleg, trust-ncg. Only one of ``hessp`` or ``hess`` needs to be given. If ``hess`` is provided, then ``hessp`` will be ignored. If neither ``hess`` nor ``hessp`` is provided, then the Hessian product will be approximated using finite differences on ``jac``. ``hessp`` must compute the Hessian times an arbitrary vector. (Passed to `scipy.optimize.minmize` automatically)\n\nAlgorithm settings:\n\n* minimize_every_iter : bool If True then promising global sampling points will be passed to a local minimization routine every iteration. If False then only the final minimizer pool will be run. Defaults to False. * local_iter : int Only evaluate a few of the best minimizer pool candidates every iteration. If False all potential points are passed to the local minimization routine. * infty_constraints: bool If True then any sampling points generated which are outside will the feasible domain will be saved and given an objective function value of ``inf``. If False then these points will be discarded. Using this functionality could lead to higher performance with respect to function evaluations before the global minimum is found, specifying False will use less memory at the cost of a slight decrease in performance. Defaults to True.\n\nFeedback:\n\n* disp : bool (L) Set to True to print convergence messages.\n\nsampling_method : str or function, optional Current built in sampling method options are ``sobol`` and ``simplicial``. The default ``simplicial`` uses less memory and provides the theoretical guarantee of convergence to the global minimum in finite time. The ``sobol`` method is faster in terms of sampling point generation at the cost of higher memory resources and the loss of guaranteed convergence. It is more appropriate for most \"easier\" problems where the convergence is relatively fast. User defined sampling functions must accept two arguments of ``n`` sampling points of dimension ``dim`` per call and output an array of sampling points with shape `n x dim`.\n##### Returns\n* **res **: OptimizeResult\n    The optimization result represented as a `OptimizeResult` object.\n    Important attributes are\n\n* **In general, the optimization problems are of the form**: \n\n* **described at https**: //web.maths.unsw.edu.au/~fkuo/sobol/ translated to\n\n* **.. [4] Hoch, W and Schittkowski, K (1981) \"Test examples for nonlinear\n       programming codes\", Lecture Notes in Economics and Mathematical\n       Systems, 187. Springer-Verlag, New York.\n       http**: //www.ai7.uni-bayreuth.de/test_problem_coll.pdf\n\n* **.. [5] Wales, DJ (2015) \"Perspective**: Insight into reaction coordinates and\n       dynamics from the potential energy landscape\",\n       Journal of Chemical Physics, 142(13), 2015.\n\n* **First consider the problem of minimizing the Rosenbrock function, `rosen`**: \n\n* **(https**: //en.wikipedia.org/wiki/Test_functions_for_optimization)\n\n* **>>> def eggholder(x)**: \n\n* **input 30 initial sampling points of the Sobol sequence**: \n\n* **can be called using**: \n\n* **following example from Hock and Schittkowski problem 73 (cattle-feed) [4]_**: \n\n* **The approximate answer given in [4]_ is**: \n\n* **>>> def f(x)**: # (cattle-feed)\n\n* **>>> def g1(x)**: \n\n* **>>> def g2(x)**: \n\n* **>>> def h1(x)**: \n\n* **>>> cons = ({'type'**: 'ineq', 'fun'\n\n* **...         {'type'**: 'eq', 'fun'\n\n* **>>> res\n     fun**: 29.894378159142136\n    funl\n\n"
},{
    "source file": "_sketches.py",
    "line number": "55",
    "func name": "clarkson_woodruff_transform",
    "func arg": "(input_matrix, sketch_size, seed)",
    "comments": "\" Applies a Clarkson-Woodruff Transform/sketch to the input matrix.\n\nGiven an input_matrix ``A`` of size ``(n, d)``, compute a matrix ``A'`` of size (sketch_size, d) so that\n\n.. math:: \\|Ax\\| \\approx \\|A'x\\|\n\nwith high probability via the Clarkson-Woodruff Transform, otherwise known as the CountSketch matrix.\n\nParameters ---------- input_matrix: array_like Input matrix, of shape ``(n, d)``. sketch_size: int Number of rows for the sketch. seed : None or int or `numpy.random.RandomState` instance, optional This parameter defines the ``RandomState`` object to use for drawing random variates. If None (or ``np.random``), the global ``np.random`` state is used. If integer, it is used to seed the local ``RandomState`` instance. Default is None.\n##### Returns\n* **A' **: array_like\n    Sketch of the input matrix ``A``, of size ``(sketch_size, d)``.\n\n* **.. math**: \n\n* **This implementation takes advantage of sparsity**: computing\n\n* **Given a big dense matrix ``A``**: \n\n* **regression of **: math\n\n* **>>> SA, Sb = SAb[**: ,\n\n"
},{
    "source file": "_solvers.py",
    "line number": "737",
    "func name": "_are_validate_args",
    "func arg": "(a, b, q, r, e, s, eq_type)",
    "comments": "A helper function to validate the arguments supplied to the Riccati equation solvers. Any discrepancy found in the input matrices leads to a ``ValueError`` exception.\n\nEssentially, it performs:\n\n- a check whether the input is free of NaN and Infs\n\n- a pass for the data through ``numpy.atleast_2d()``\n\n- squareness check of the relevant arrays\n\n- shape consistency check of the arrays\n\n- singularity check of the relevant arrays\n\n- symmetricity check of the relevant matrices\n\n- a check whether the regular or the generalized version is asked.\n\nThis function is used by ``solve_continuous_are`` and ``solve_discrete_are``.\n\nParameters ---------- a, b, q, r, e, s : array_like Input data eq_type : str Accepted arguments are 'care' and 'dare'.\n##### Returns\n* **a, b, q, r, e, s **: ndarray\n    Regularized input data\n\n* **m, n **: int\n    shape of the problem\n\n* **r_or_c **: type\n    Data type of the problem, returns float or complex\n\n* **gen_or_not **: bool\n    Type of the equation, True for generalized and False for regular ARE.\n\n"
},{
    "source file": "_spectral.py",
    "line number": "256",
    "func name": "_complex2real",
    "func arg": "(z)",
    "comments": ""
},{
    "source file": "_spherical_bessel.py",
    "line number": "157",
    "func name": "spherical_kn",
    "func arg": "(n, z, derivative)",
    "comments": "Modified spherical Bessel function of the second kind or its derivative.\n\nDefined as [1]_,\n\n.. math:: k_n(z) = \\sqrt{\\frac{\\pi},{2z}} K_{n + 1/2}(z),\n\nwhere :math:`K_n` is the modified Bessel function of the second kind.\n\nParameters ---------- n : int, array_like Order of the Bessel function (n >= 0). z : complex or float, array_like Argument of the Bessel function. derivative : bool, optional If True, the value of the derivative (rather than the function itself) is returned.\n##### Returns\n* **kn **: ndarray\n\n* **.. math**: \n\n* **.. versionadded**: \n\n* **.. [1] https**: //dlmf.nist.gov/10.47.E9\n\n* **.. [2] https**: //dlmf.nist.gov/10.51.E5\n\n"
},{
    "source file": "_spherical_voronoi39.py",
    "line number": "23",
    "func name": "calculate_solid_angles",
    "func arg": "(R)",
    "comments": "Calculates the solid angles of plane triangles. Implements the method of Van Oosterom and Strackee [VanOosterom]_ with some modifications. Assumes that input points have unit norm.\n\n\n"
},{
    "source file": "_stats_mstats_common40.py",
    "line number": "288",
    "func name": "siegelslopes",
    "func arg": "(y, x, method)",
    "comments": "Computes the Siegel estimator for a set of points (x, y).\n\n`siegelslopes` implements a method for robust linear regression using repeated medians (see [1]_) to fit a line to the points (x, y). The method is robust to outliers with an asymptotic breakdown point of 50%.\n\nParameters ---------- y : array_like Dependent variable. x : array_like or None, optional Independent variable. If None, use ``arange(len(y))`` instead. method : {'hierarchical', 'separate'} If 'hierarchical', estimate the intercept using the estimated slope ``medslope`` (default option). If 'separate', estimate the intercept independent of the estimated slope. See Notes for details.\n##### Returns\n* **medslope **: float\n    Estimate of the slope of the regression line.\n\n* **medintercept **: float\n    Estimate of the intercept of the regression line.\n\n* **theilslopes **: a similar technique without repeated medians\n\n* **The other approach estimates the intercept separately as follows**: for\n\n* **>>> y[11**: 15] += 10  # add outliers\n\n* **>>> y[-5**: ] -= 7\n\n* **least-squares fit with `linregress`**: \n\n"
},{
    "source file": "_testutils.py",
    "line number": "53",
    "func name": "assert_func_equal",
    "func arg": "(func, results, points, rtol, atol, param_filter, knownfailure, vectorized, dtype, nan_ok, ignore_inf_sign, distinguish_nan_and_inf)",
    "comments": ""
},{
    "source file": "_testutils41.py",
    "line number": "47",
    "func name": "assert_no_overwrite",
    "func arg": "(call, shapes, dtypes)",
    "comments": "Test that a call does not overwrite its input arguments\n\n\n"
},{
    "source file": "_testutils42.py",
    "line number": "120",
    "func name": "_get_mem_available",
    "func arg": "()",
    "comments": "Get information about memory available, not counting swap.\n\n\n"
},{
    "source file": "_threadsafety.py",
    "line number": "48",
    "func name": "non_reentrant",
    "func arg": "(err_msg)",
    "comments": "Decorate a function with a threading lock and prevent reentrant calls.\n\n\n"
},{
    "source file": "_tmpdirs.py",
    "line number": "58",
    "func name": "in_dir",
    "func arg": "(dir)",
    "comments": "Change directory to given directory for duration of ``with`` block\n\nUseful when you want to use `in_tempdir` for the final test, but you are still debugging. For example, you may want to do this in the end:\n\n>>> with in_tempdir() as tmpdir: ...\n\n\n\n # do something complicated which might break ...\n\n\n\n pass\n\nBut, indeed, the complicated thing does break, and meanwhile, the ``in_tempdir`` context manager wiped out the directory with the temporary files that you wanted for debugging. So, while debugging, you replace with something like:\n\n>>> with in_dir() as tmpdir: # Use working directory by default ...\n\n\n\n # do something complicated which might break ...\n\n\n\n pass\n\nYou can then look at the temporary file outputs to debug what is happening, fix, and finally replace ``in_dir`` with ``in_tempdir`` again.\n"
},{
    "source file": "_trustregion_dogleg.py",
    "line number": "9",
    "func name": "_minimize_dogleg",
    "func arg": "(fun, x0, args, jac, hess, **trust_region_options)",
    "comments": "Minimization of scalar function of one or more variables using the dog-leg trust-region algorithm.\n\nOptions ------- initial_trust_radius : float Initial trust-region radius. max_trust_radius : float Maximum value of the trust-region radius. No steps that are longer than this value will be proposed. eta : float Trust region related acceptance stringency for proposed steps. gtol : float Gradient norm must be less than `gtol` before successful termination.\n"
},{
    "source file": "_trustregion_exact.py",
    "line number": "144",
    "func name": "singular_leading_submatrix",
    "func arg": "(A, U, k)",
    "comments": "Compute term that makes the leading ``k`` by ``k`` submatrix from ``A`` singular.\n\nParameters ---------- A : ndarray Symmetric matrix that is not positive definite. U : ndarray Upper triangular matrix resulting of an incomplete Cholesky decomposition of matrix ``A``. k : int Positive integer such that the leading k by k submatrix from `A` is the first non-positive definite leading submatrix.\n##### Returns\n* **delta **: float\n    Amount that should be added to the element (k, k) of the\n    leading k by k submatrix of ``A`` to make it singular.\n\n* **v **: ndarray\n    A vector such that ``v.T B v = 0``. Where B is the matrix A after\n    ``delta`` is added to its element (k, k).\n\n"
},{
    "source file": "_trustregion_krylov.py",
    "line number": "6",
    "func name": "_minimize_trust_krylov",
    "func arg": "(fun, x0, args, jac, hess, hessp, inexact, **trust_region_options)",
    "comments": "Minimization of a scalar function of one or more variables using a nearly exact trust-region algorithm that only requires matrix vector products with the hessian matrix.\n\n.. versionadded:: 1.0.0\n\nOptions ------- inexact : bool, optional Accuracy to solve subproblems. If True requires less nonlinear iterations, but more vector products.\n"
},{
    "source file": "_trustregion_ncg.py",
    "line number": "11",
    "func name": "_minimize_trust_ncg",
    "func arg": "(fun, x0, args, jac, hess, hessp, **trust_region_options)",
    "comments": "Minimization of scalar function of one or more variables using the Newton conjugate gradient trust-region algorithm.\n\nOptions ------- initial_trust_radius : float Initial trust-region radius. max_trust_radius : float Maximum value of the trust-region radius. No steps that are longer than this value will be proposed. eta : float Trust region related acceptance stringency for proposed steps. gtol : float Gradient norm must be less than `gtol` before successful termination.\n"
},{
    "source file": "_trustregion.py",
    "line number": "100",
    "func name": "_minimize_trust_region",
    "func arg": "(fun, x0, args, jac, hess, hessp, subproblem, initial_trust_radius, max_trust_radius, eta, gtol, maxiter, disp, return_all, callback, inexact, **unknown_options)",
    "comments": "Minimization of scalar function of one or more variables using a trust-region algorithm.\n\nOptions for the trust-region algorithm are: initial_trust_radius : float Initial trust radius. max_trust_radius : float Never propose steps that are longer than this value. eta : float Trust region related acceptance stringency for proposed steps. gtol : float Gradient norm must be less than `gtol` before successful termination. maxiter : int Maximum number of iterations to perform. disp : bool If True, print convergence message. inexact : bool Accuracy to solve subproblems. If True requires less nonlinear iterations, but more vector products. Only effective for method trust-krylov.\n\nThis function is called by the `minimize` function. It is not supposed to be called directly.\n"
},{
    "source file": "_tstutils.py",
    "line number": "639",
    "func name": "get_tests",
    "func arg": "(collection, smoothness)",
    "comments": "Return the requested collection of test cases, as an array of dicts with subset-specific keys\n\nAllowed values of collection: 'original': The original benchmarking functions. Real-valued functions of real-valued inputs on an interval with a zero. f1, .., f3 are continuous and infinitely differentiable f4 has a single discontinuity at the root f5 has a root at 1 replacing a 1st order pole f6 is randomly positive on one side of the root, randomly negative on the other 'aps': The test problems in the TOMS \"Algorithm 748: Enclosing Zeros of Continuous Functions\" paper by Alefeld, Potra and Shi. Real-valued functions of real-valued inputs on an interval with a zero. Suitable for methods which start with an enclosing interval, and derivatives up to 2nd order. 'complex': Some complex-valued functions of complex-valued inputs. No enclosing bracket is provided. Suitable for methods which use one or more starting values, and derivatives up to 2nd order.\n\nThe dictionary keys will be a subset of [\"f\", \"fprime\", \"fprime2\", \"args\", \"bracket\", \"a\", b\", \"smoothness\", \"x0\", \"x1\", \"root\", \"ID\"]\n"
},{
    "source file": "_tukeylambda_stats43.py",
    "line number": "147",
    "func name": "tukeylambda_kurtosis",
    "func arg": "(lam)",
    "comments": "Kurtosis of the Tukey Lambda distribution.\n\nParameters ---------- lam : array_like The lambda values at which to compute the variance.\n##### Returns\n* **v **: ndarray\n    The variance.  For lam < -0.25, the variance is not defined, so\n    np.nan is returned.  For lam = 0.25, np.inf is returned.\n\n"
},{
    "source file": "_upfirdn44.py",
    "line number": "107",
    "func name": "upfirdn",
    "func arg": "(h, x, up, down, axis, mode, cval)",
    "comments": "Upsample, FIR filter, and downsample.\n\nParameters ---------- h : array_like 1-D FIR (finite-impulse response) filter coefficients. x : array_like Input signal array. up : int, optional Upsampling rate. Default is 1. down : int, optional Downsampling rate. Default is 1. axis : int, optional The axis of the input data array along which to apply the linear filter. The filter is applied to each subarray along this axis. Default is -1. mode : str, optional The signal extension mode to use. The set ``{\"constant\", \"symmetric\", \"reflect\", \"edge\", \"wrap\"}`` correspond to modes provided by `numpy.pad`. ``\"smooth\"`` implements a smooth extension by extending based on the slope of the last 2 points at each end of the array. ``\"antireflect\"`` and ``\"antisymmetric\"`` are anti-symmetric versions of ``\"reflect\"`` and ``\"symmetric\"``. The mode `\"line\"` extends the signal based on a linear trend defined by the first and last points along the ``axis``.\n\n.. versionadded:: 1.4.0 cval : float, optional The constant value to use when ``mode == \"constant\"``.\n\n.. versionadded:: 1.4.0\n##### Returns\n* **y **: ndarray\n    The output signal array. Dimensions will be the same as `x` except\n    for along `axis`, which will change size according to the `h`,\n    `up`,  and `down` parameters.\n\n* **.. versionadded**: \n\n* **Simple operations**: \n\n* **Apply a single filter to multiple signals**: \n\n* **Apply along the last dimension of ``x``**: \n\n* **Apply along the 0th dimension of ``x``**: \n\n"
},{
    "source file": "_util.py",
    "line number": "421",
    "func name": "rng_integers",
    "func arg": "(gen, low, high, size, dtype, endpoint)",
    "comments": "Return random integers from low (inclusive) to high (exclusive), or if endpoint=True, low (inclusive) to high (inclusive). Replaces `RandomState.randint` (with endpoint=False) and `RandomState.random_integers` (with endpoint=True).\n\nReturn random integers from the \"discrete uniform\" distribution of the specified dtype. If high is None (the default), then results are from 0 to low.\n\nParameters ---------- gen: {None, np.random.RandomState, np.random.Generator} Random number generator. If None, then the np.random.RandomState singleton is used. low: int or array-like of ints Lowest (signed) integers to be drawn from the distribution (unless high=None, in which case this parameter is 0 and this value is used for high). high: int or array-like of ints If provided, one above the largest (signed) integer to be drawn from the distribution (see above for behavior if high=None). If array-like, must contain integer values. size: None Output shape. If the given shape is, e.g., (m, n, k), then m * n * k samples are drawn. Default is None, in which case a single value is returned. dtype: {str, dtype}, optional Desired dtype of the result. All dtypes are determined by their name, i.e., 'int64', 'int', etc, so byteorder is not available and a specific precision may have different C types depending on the platform. The default value is np.int_. endpoint: bool, optional If True, sample from the interval [low, high] instead of the default [low, high) Defaults to False.\n##### Returns\n* **out**: int or ndarray of ints\n    size-shaped array of random integers from the appropriate distribution,\n    or a single such random int if size not provided.\n\n"
},{
    "source file": "_validation45.py",
    "line number": "9",
    "func name": "validate_graph",
    "func arg": "(csgraph, directed, dtype, csr_output, dense_output, copy_if_dense, copy_if_sparse, null_value_in, null_value_out, infinity_null, nan_null)",
    "comments": "Routine for validation and conversion of csgraph inputs\n\n\n"
},{
    "source file": "_wilcoxon_data46.py",
    "line number": "37",
    "func name": "_generate_wilcoxon_exact_table_fast",
    "func arg": "(N)",
    "comments": "Same functionality as _generate_wilcoxon_exact_table, but about 20% faster, but harder to follow.\n\n\n"
},{
    "source file": "add_newdocs.py",
    "line number": "18",
    "func name": "add_newdoc",
    "func arg": "(name, doc)",
    "comments": ""
},{
    "source file": "arffread.py",
    "line number": "890",
    "func name": "test_weka",
    "func arg": "(filename)",
    "comments": ""
},{
    "source file": "arpack47.py",
    "line number": "1727",
    "func name": "svds",
    "func arg": "(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors, solver)",
    "comments": "Compute the largest or smallest k singular values/vectors for a sparse matrix. The order of the singular values is not guaranteed.\n\nParameters ---------- A : {sparse matrix, LinearOperator} Array to compute the SVD on, of shape (M, N) k : int, optional Number of singular values and vectors to compute. Must be 1 <= k < min(A.shape). ncv : int, optional The number of Lanczos vectors generated ncv must be greater than k+1 and smaller than n; it is recommended that ncv > 2*k Default: ``min(n, max(2*k + 1, 20))`` tol : float, optional Tolerance for singular values. Zero (default) means machine precision. which : str, ['LM' | 'SM'], optional Which `k` singular values to find:\n\n- 'LM' : largest singular values\n\n- 'SM' : smallest singular values\n\n.. versionadded:: 0.12.0 v0 : ndarray, optional Starting vector for iteration, of length min(A.shape). Should be an (approximate) left singular vector if N > M and a right singular vector otherwise. Default: random\n\n.. versionadded:: 0.12.0 maxiter : int, optional Maximum number of iterations.\n\n.. versionadded:: 0.12.0 return_singular_vectors : bool or str, optional\n\n- True: return singular vectors (True) in addition to singular values.\n\n.. versionadded:: 0.12.0\n\n- \"u\": only return the u matrix, without computing vh (if N > M).\n\n- \"vh\": only return the vh matrix, without computing u (if N <= M).\n\n.. versionadded:: 0.16.0 solver : str, optional Eigenvalue solver to use. Should be 'arpack' or 'lobpcg'. Default: 'arpack'\n##### Returns\n* **u **: ndarray, shape=(M, k)\n    Unitary matrix having left singular vectors as columns.\n    If `return_singular_vectors` is \"vh\", this variable is not computed,\n    and None is returned instead.\n\n* **s **: ndarray, shape=(k,)\n    The singular values.\n\n* **vt **: ndarray, shape=(k, N)\n    Unitary matrix having right singular vectors as rows.\n    If `return_singular_vectors` is \"u\", this variable is not computed,\n    and None is returned instead.\n\n"
},{
    "source file": "authors.py",
    "line number": "127",
    "func name": "load_name_map",
    "func arg": "(filename)",
    "comments": ""
},{
    "source file": "base.py",
    "line number": "4",
    "func name": "check_arguments",
    "func arg": "(fun, y0, support_complex)",
    "comments": "Helper function for checking arguments common to all solvers.\n\n\n"
},{
    "source file": "base48.py",
    "line number": "1205",
    "func name": "isspmatrix",
    "func arg": "(x)",
    "comments": "Is x of a sparse matrix type?\n\nParameters ---------- x object to check for being a sparse matrix\n##### Returns\n"
},{
    "source file": "basic.py",
    "line number": "1476",
    "func name": "matrix_balance",
    "func arg": "(A, permute, scale, separate, overwrite_a)",
    "comments": "Compute a diagonal similarity transformation for row/column balancing.\n\nThe balancing tries to equalize the row and column 1-norms by applying a similarity transformation such that the magnitude variation of the matrix entries is reflected to the scaling matrices.\n\nMoreover, if enabled, the matrix is first permuted to isolate the upper triangular parts of the matrix and, again if scaling is also enabled, only the remaining subblocks are subjected to scaling.\n\nThe balanced matrix satisfies the following equality\n\n.. math::\n\nB = T^{-1} A T\n\nThe scaling coefficients are approximated to the nearest power of 2 to avoid round-off errors.\n\nParameters ---------- A : (n, n) array_like Square data matrix for the balancing. permute : bool, optional The selector to define whether permutation of A is also performed prior to scaling. scale : bool, optional The selector to turn on and off the scaling. If False, the matrix will not be scaled. separate : bool, optional This switches from returning a full matrix of the transformation to a tuple of two separate 1-D permutation and scaling arrays. overwrite_a : bool, optional This is passed to xGEBAL directly. Essentially, overwrites the result to the data. It might increase the space efficiency. See LAPACK manual for details. This is False by default.\n##### Returns\n* **B **: (n, n) ndarray\n    Balanced matrix\n\n* **T **: (n, n) ndarray\n    A possibly permuted diagonal matrix whose nonzero entries are\n    integer powers of 2 to avoid numerical truncation errors.\n\n* **scale, perm **: (n,) ndarray\n    If ``separate`` keyword is set to True then instead of the array\n    ``T`` above, the scaling and the permutation vectors are given\n    separately as a tuple without allocating the full array ``T``.\n\n* **.. versionadded**: \n\n* **.. [1] **: B.N. Parlett and C. Reinsch, \"Balancing a Matrix for\n   Calculation of Eigenvalues and Eigenvectors\", Numerische Mathematik,\n   Vol.13(4), 1969, DOI\n\n* **.. [2] **: R. James, J. Langou, B.R. Lowery, \"On matrix balancing and\n   eigenvector computation\", 2014, Available online\n\n* **.. [3] **: D.S. Watkins. A case where balancing is harmful.\n   Electron. Trans. Numer. Anal, Vol.23, 2006.\n\n"
},{
    "source file": "basic49.py",
    "line number": "397",
    "func name": "ifft2",
    "func arg": "(x, shape, axes, overwrite_x)",
    "comments": "2-D discrete inverse Fourier transform of real or complex sequence.\n\nReturn inverse 2-D discrete Fourier transform of arbitrary type sequence x.\n\nSee `ifft` for more information.\n\nSee also -------- fft2, ifft\n\nExamples -------- >>> from scipy.fftpack import fft2, ifft2 >>> y = np.mgrid[:5, :5][0] >>> y array([[0, 0, 0, 0, 0], [1, 1, 1, 1, 1], [2, 2, 2, 2, 2], [3, 3, 3, 3, 3], [4, 4, 4, 4, 4]]) >>> np.allclose(y, fft2(ifft2(y))) True\n"
},{
    "source file": "basic50.py",
    "line number": "272",
    "func name": "r2r_fftpack",
    "func arg": "(forward, x, n, axis, norm, overwrite_x)",
    "comments": "FFT of a real sequence, returning fftpack half complex format\n\n\n"
},{
    "source file": "bdf.py",
    "line number": "36",
    "func name": "solve_bdf_system",
    "func arg": "(fun, t_new, y_predict, c, psi, LU, solve_lu, scale, tol)",
    "comments": "Solve the algebraic system resulting from BDF method.\n\n\n"
},{
    "source file": "blas.py",
    "line number": "410",
    "func name": "get_blas_funcs",
    "func arg": "(names, arrays, dtype, ilp64)",
    "comments": "Return available BLAS function objects from names.\n\nArrays are used to determine the optimal prefix of BLAS routines.\n\nParameters ---------- names : str or sequence of str Name(s) of BLAS functions without type prefix.\n\narrays : sequence of ndarrays, optional Arrays can be given to determine optimal prefix of BLAS routines. If not given, double-precision routines will be used, otherwise the most generic type in arrays will be used.\n\ndtype : str or dtype, optional Data-type specifier. Not used if `arrays` is non-empty.\n\nilp64 : {True, False, 'preferred'}, optional Whether to return ILP64 routine variant. Choosing 'preferred' returns ILP64 routine if available, and otherwise the 32-bit routine. Default: False\n##### Returns\n* **funcs **: list\n    List containing the found function(s).\n\n"
},{
    "source file": "bsplines52.py",
    "line number": "601",
    "func name": "qspline1d_eval",
    "func arg": "(cj, newx, dx, x0)",
    "comments": "Evaluate a quadratic spline at the new set of points.\n\nParameters ---------- cj : ndarray Quadratic spline coefficients newx : ndarray New set of points. dx : float, optional Old sample-spacing, the default value is 1.0. x0 : int, optional Old origin, the default value is 0.\n##### Returns\n* **res **: ndarray\n    Evaluated a quadratic spline points.\n\n* **qspline1d **: Compute quadratic spline coefficients for rank-1 array.\n\n* **represent spline coefficients were at equally-spaced points of**: \n\n* **a quadratic spline**: \n\n"
},{
    "source file": "bsr53.py",
    "line number": "692",
    "func name": "isspmatrix_bsr",
    "func arg": "(x)",
    "comments": "Is x of a bsr_matrix type?\n\nParameters ---------- x object to check for being a bsr matrix\n##### Returns\n"
},{
    "source file": "bvls.py",
    "line number": "17",
    "func name": "bvls",
    "func arg": "(A, b, x_lsq, lb, ub, tol, max_iter, verbose)",
    "comments": ""
},{
    "source file": "byteordercodes.py",
    "line number": "20",
    "func name": "to_numpy_code",
    "func arg": "(code)",
    "comments": "Convert various order codings to NumPy format.\n\nParameters ---------- code : str The code to convert. It is converted to lower case before parsing. Legal values are: 'little', 'big', 'l', 'b', 'le', 'be', '<', '>', 'native', '=', 'swapped', 's'.\n##### Returns\n* **out_code **: {'<', '>'}\n    Here '<' is the numpy dtype code for little endian,\n    and '>' is the code for big endian.\n\n"
},{
    "source file": "canonical_constraint.py",
    "line number": "330",
    "func name": "initial_constraints_as_canonical",
    "func arg": "(n, prepared_constraints, sparse_jacobian)",
    "comments": "Convert initial values of the constraints to the canonical format.\n\nThe purpose to avoid one additional call to the constraints at the initial point. It takes saved values in `PreparedConstraint`, modififies and concatenates them to the the canonical constraint format.\n"
},{
    "source file": "cobyla.py",
    "line number": "183",
    "func name": "_minimize_cobyla",
    "func arg": "(fun, x0, args, constraints, rhobeg, tol, maxiter, disp, catol, **unknown_options)",
    "comments": "Minimize a scalar function of one or more variables using the Constrained Optimization BY Linear Approximation (COBYLA) algorithm.\n\nOptions ------- rhobeg : float Reasonable initial changes to the variables. tol : float Final accuracy in the optimization (not precisely guaranteed). This is a lower bound on the size of the trust region. disp : bool Set to True to print convergence messages. If False, `verbosity` is ignored as set to 0. maxiter : int Maximum number of function evaluations. catol : float Tolerance (absolute) for constraint violations\n"
},{
    "source file": "codata.py",
    "line number": "1647",
    "func name": "find",
    "func arg": "(sub, disp)",
    "comments": "Return list of physical_constant keys containing a given string.\n\nParameters ---------- sub : str, unicode Sub-string to search keys for. By default, return all keys. disp : bool If True, print the keys that are found and return None. Otherwise, return the list of keys without printing anything.\n##### Returns\n* **keys **: list or None\n    If `disp` is False, the list of keys is returned.\n    Otherwise, None is returned.\n\n* **Get the constant called 'Boltzmann constant in Hz/K'**: \n\n* **Find constants with 'radius' in the key**: \n\n"
},{
    "source file": "common_tests54.py",
    "line number": "312",
    "func name": "check_rvs_broadcast",
    "func arg": "(distfunc, distname, allargs, shape, shape_only, otype)",
    "comments": ""
},{
    "source file": "common.py",
    "line number": "135",
    "func name": "with_attributes",
    "func arg": "(**attrs)",
    "comments": ""
},{
    "source file": "common55.py",
    "line number": "232",
    "func name": "electrocardiogram",
    "func arg": "()",
    "comments": "Load an electrocardiogram as an example for a 1-D signal.\n\nThe returned signal is a 5 minute long electrocardiogram (ECG), a medical recording of the heart's electrical activity, sampled at 360 Hz.\n##### Returns\n* **ecg **: ndarray\n    The electrocardiogram in millivolt (mV) sampled at 360 Hz.\n\n* **The provided signal is an excerpt (19**: 35 to 24\n\n* **.. _record 208**: https\n\n* **.. versionadded**: \n\n* **.. [1] Moody GB, Mark RG. The impact of the MIT-BIH Arrhythmia Database.\n       IEEE Eng in Med and Biol 20(3)**: 45-50 (May-June 2001).\n       (PMID\n\n* **.. [2] Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh,\n       Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. PhysioBank,\n       PhysioToolkit, and PhysioNet**: Components of a New Research Resource\n       for Complex Physiologic Signals. Circulation 101(23)\n\n* **At several points large artifacts disturb the recording, e.g.**: \n\n"
},{
    "source file": "common56.py",
    "line number": "365",
    "func name": "_sparse_num_jac",
    "func arg": "(fun, t, y, f, h, factor, y_scale, structure, groups)",
    "comments": ""
},{
    "source file": "common57.py",
    "line number": "723",
    "func name": "scale_for_robust_loss_function",
    "func arg": "(J, f, rho)",
    "comments": "Scale Jacobian and residuals for a robust loss function.\n\nArrays are modified in place.\n"
},{
    "source file": "compiler_helper58.py",
    "line number": "87",
    "func name": "set_cxx_flags_clib_hook",
    "func arg": "(build_clib, build_info)",
    "comments": ""
},{
    "source file": "compressed59.py",
    "line number": "1273",
    "func name": "_process_slice",
    "func arg": "(sl, num)",
    "comments": ""
},{
    "source file": "conf.py",
    "line number": "441",
    "func name": "linkcode_resolve",
    "func arg": "(domain, info)",
    "comments": "Determine the URL corresponding to Python object\n\n\n"
},{
    "source file": "conftest.py",
    "line number": "44",
    "func name": "check_fpu_mode",
    "func arg": "(request)",
    "comments": "Check FPU mode was not changed during the test.\n\n\n"
},{
    "source file": "constants.py",
    "line number": "279",
    "func name": "nu2lambda",
    "func arg": "(nu)",
    "comments": "Convert optical frequency to wavelength.\n\nParameters ---------- nu : array_like Optical frequency to be converted.\n##### Returns\n* **lambda **: float or array of floats\n    Equivalent wavelength(s).\n\n"
},{
    "source file": "construct60.py",
    "line number": "815",
    "func name": "rand",
    "func arg": "(m, n, density, format, dtype, random_state)",
    "comments": "Generate a sparse matrix of the given shape and density with uniformly distributed values.\n\nParameters ---------- m, n : int shape of the matrix density : real, optional density of the generated matrix: density equal to one means a full matrix, density of 0 means a matrix with no non-zero items. format : str, optional sparse matrix format. dtype : dtype, optional type of the returned matrix values. random_state : {numpy.random.RandomState, int, np.random.Generator}, optional Random number generator or random seed. If not given, the singleton numpy.random will be used.\n##### Returns\n* **res **: sparse matrix\n\n* **scipy.sparse.random **: Similar function that allows a user-specified random\n    data source.\n\n"
},{
    "source file": "contingency61.py",
    "line number": "110",
    "func name": "chi2_contingency",
    "func arg": "(observed, correction, lambda_)",
    "comments": "Chi-square test of independence of variables in a contingency table.\n\nThis function computes the chi-square statistic and p-value for the hypothesis test of independence of the observed frequencies in the contingency table [1]_ `observed`.\n\nThe expected frequencies are computed based on the marginal sums under the assumption of independence; see `scipy.stats.contingency.expected_freq`.\n\nThe number of degrees of freedom is (expressed using numpy functions and attributes)::\n\ndof = observed.size\n\n- sum(observed.shape) + observed.ndim\n\n- 1\n\n Parameters ---------- observed : array_like The contingency table. The table contains the observed frequencies (i.e. number of occurrences) in each category.\n\nIn the two-dimensional case, the table is often described as an \"R x C table\". correction : bool, optional If True, *and* the degrees of freedom is 1, apply Yates' correction for continuity.\n\nThe effect of the correction is to adjust each observed value by 0.5 towards the corresponding expected value. lambda_ : float or str, optional. By default, the statistic computed in this test is Pearson's chi-squared statistic [2]_.\n\n`lambda_` allows a statistic from the Cressie-Read power divergence family [3]_ to be used instead.\n\nSee `power_divergence` for details.\n##### Returns\n* **chi2 **: float\n    The test statistic.\n\n* **p **: float\n    The p-value of the test\n\n* **dof **: int\n    Degrees of freedom\n\n* **expected **: ndarray, same shape as `observed`\n    The expected frequencies, based on the marginal sums of the table.\n\n* **required, one could use stats.chisquare.  That is, if one calls**: \n\n* **then the following is true**: \n\n* **.. [1] \"Contingency table\",\n       https**: //en.wikipedia.org/wiki/Contingency_table\n\n* **.. [2] \"Pearson's chi-squared test\",\n       https**: //en.wikipedia.org/wiki/Pearson%27s_chi-squared_test\n\n* **A two-way example (2 x 3)**: \n\n* **A four-way example (2 x 2 x 2 x 2)**: \n\n"
},{
    "source file": "convert62.py",
    "line number": "179",
    "func name": "dump_datasets",
    "func arg": "(filename)",
    "comments": ""
},{
    "source file": "coo63.py",
    "line number": "595",
    "func name": "isspmatrix_coo",
    "func arg": "(x)",
    "comments": "Is x of coo_matrix type?\n\nParameters ---------- x object to check for being a coo matrix\n##### Returns\n"
},{
    "source file": "csc64.py",
    "line number": "236",
    "func name": "isspmatrix_csc",
    "func arg": "(x)",
    "comments": "Is x of csc_matrix type?\n\nParameters ---------- x object to check for being a csc matrix\n##### Returns\n"
},{
    "source file": "csr65.py",
    "line number": "335",
    "func name": "isspmatrix_csr",
    "func arg": "(x)",
    "comments": "Is x of csr_matrix type?\n\nParameters ---------- x object to check for being a csr matrix\n##### Returns\n"
},{
    "source file": "cythonize.py",
    "line number": "296",
    "func name": "main",
    "func arg": "()",
    "comments": ""
},{
    "source file": "data66.py",
    "line number": "145",
    "func name": "_find_missing_index",
    "func arg": "(ind, n)",
    "comments": ""
},{
    "source file": "datafunc67.py",
    "line number": "32",
    "func name": "run_test",
    "func arg": "(filename, funcs, args)",
    "comments": ""
},{
    "source file": "decomp_cholesky.py",
    "line number": "288",
    "func name": "cho_solve_banded",
    "func arg": "(cb_and_lower, b, overwrite_b, check_finite)",
    "comments": "Solve the linear equations ``A x = b``, given the Cholesky factorization of the banded Hermitian ``A``.\n\nParameters ---------- (cb, lower) : tuple, (ndarray, bool) `cb` is the Cholesky factorization of A, as given by cholesky_banded. `lower` must be the same value that was given to cholesky_banded. b : array_like Right-hand side overwrite_b : bool, optional If True, the function will overwrite the values in `b`. check_finite : bool, optional Whether to check that the input matrices contain only finite numbers. Disabling may give a performance gain, but may result in problems (crashes, non-termination) if the inputs do contain infinities or NaNs.\n##### Returns\n* **x **: array\n    The solution to the system A x = b\n\n* **cholesky_banded **: Cholesky factorization of a banded matrix\n\n* **.. versionadded**: \n\n* **>>> A = np.diag(Ab[0,2**: ], k=2) + np.diag(Ab[1,1\n\n* **>>> A = A + A.conj().T + np.diag(Ab[2, **: ])\n\n"
},{
    "source file": "decomp_lu.py",
    "line number": "151",
    "func name": "lu",
    "func arg": "(a, permute_l, overwrite_a, check_finite)",
    "comments": "Compute pivoted LU decomposition of a matrix.\n\nThe decomposition is::\n\nA = P L U\n\nwhere P is a permutation matrix, L lower triangular with unit diagonal elements, and U upper triangular.\n\nParameters ---------- a : (M, N) array_like Array to decompose permute_l : bool, optional Perform the multiplication P*L (Default: do not permute) overwrite_a : bool, optional Whether to overwrite data in a (may improve performance) check_finite : bool, optional Whether to check that the input matrix contains only finite numbers. Disabling may give a performance gain, but may result in problems (crashes, non-termination) if the inputs do contain infinities or NaNs.\n##### Returns\n* **p **: (M, M) ndarray\n    Permutation matrix\n\n* **l **: (M, K) ndarray\n    Lower triangular or trapezoidal matrix with unit diagonal.\n    K = min(M, N)\n\n* **u **: (K, N) ndarray\n    Upper triangular or trapezoidal matrix\n\n* **pl **: (M, K) ndarray\n    Permuted L matrix.\n    K = min(M, N)\n\n"
},{
    "source file": "decomp_qr.py",
    "line number": "323",
    "func name": "rq",
    "func arg": "(a, overwrite_a, lwork, mode, check_finite)",
    "comments": "Compute RQ decomposition of a matrix.\n\nCalculate the decomposition ``A = R Q`` where Q is unitary/orthogonal and R upper triangular.\n\nParameters ---------- a : (M, N) array_like Matrix to be decomposed overwrite_a : bool, optional Whether data in a is overwritten (may improve performance) lwork : int, optional Work array size, lwork >= a.shape[1]. If None or -1, an optimal size is computed. mode : {'full', 'r', 'economic'}, optional Determines what information is to be returned: either both Q and R ('full', default), only R ('r') or both Q and R but computed in economy-size ('economic', see Notes). check_finite : bool, optional Whether to check that the input matrix contains only finite numbers. Disabling may give a performance gain, but may result in problems (crashes, non-termination) if the inputs do contain infinities or NaNs.\n##### Returns\n* **R **: float or complex ndarray\n    Of shape (M, N) or (M, K) for ``mode='economic'``. ``K = min(M, N)``.\n\n* **Q **: float or complex ndarray\n    Of shape (N, N) or (K, N) for ``mode='economic'``. Not returned\n    if ``mode='r'``.\n\n"
},{
    "source file": "decomp_schur.py",
    "line number": "210",
    "func name": "rsf2csf",
    "func arg": "(T, Z, check_finite)",
    "comments": "Convert real Schur form to complex Schur form.\n\nConvert a quasi-diagonal real-valued Schur form to the upper-triangular complex-valued Schur form.\n\nParameters ---------- T : (M, M) array_like Real Schur form of the original array Z : (M, M) array_like Schur transformation matrix check_finite : bool, optional Whether to check that the input arrays contain only finite numbers. Disabling may give a performance gain, but may result in problems (crashes, non-termination) if the inputs do contain infinities or NaNs.\n##### Returns\n* **T **: (M, M) ndarray\n    Complex Schur form of the original array\n\n* **Z **: (M, M) ndarray\n    Schur transformation matrix corresponding to the complex form\n\n* **schur **: Schur decomposition of an array\n\n"
},{
    "source file": "decomp_svd.py",
    "line number": "391",
    "func name": "subspace_angles",
    "func arg": "(A, B)",
    "comments": "Compute the subspace angles between two matrices.\n\nParameters ---------- A : (M, N) array_like The first input array. B : (M, K) array_like The second input array.\n##### Returns\n* **angles **: ndarray, shape (min(N, K),)\n    The subspace angles between the column spaces of `A` and `B` in\n    descending order.\n\n* **.. versionadded**: \n\n* **.. [1] Knyazev A, Argentati M (2002) Principal Angles between Subspaces\n       in an A-Based Scalar Product**: Algorithms and Perturbation\n       Estimates. SIAM J. Sci. Comput. 23\n\n* **the suspace angle to be **: math\n\n* **>>> np.rad2deg(subspace_angles(H[**: ,\n\n* **And the subspace angle of a matrix to itself should be zero**: \n\n* **>>> subspace_angles(H[**: ,\n\n* **The angles between non-orthogonal subspaces are in between these extremes**: \n\n* **>>> np.rad2deg(subspace_angles(x[**: ,\n\n"
},{
    "source file": "decomp.py",
    "line number": "1436",
    "func name": "cdf2rdf",
    "func arg": "(w, v)",
    "comments": "Converts complex eigenvalues ``w`` and eigenvectors ``v`` to real eigenvalues in a block diagonal form ``wr`` and the associated real eigenvectors ``vr``, such that\n\nvr @ wr = X @ vr\n\ncontinues to hold, where ``X`` is the original array for which ``w`` and ``v`` are the eigenvalues and eigenvectors.\n\n.. versionadded:: 1.1.0\n\nParameters ---------- w : (..., M) array_like Complex or real eigenvalues, an array or stack of arrays\n\nConjugate pairs must not be interleaved, else the wrong result will be produced. So ``[1+1j, 1, 1-1j]`` will give a correct result, but ``[1+1j, 2+1j, 1-1j, 2-1j]`` will not.\n\nv : (..., M, M) array_like Complex or real eigenvectors, a square array or stack of square arrays.\n##### Returns\n* **wr **: (..., M, M) ndarray\n    Real diagonal block form of eigenvalues\n\n* **vr **: (..., M, M) ndarray\n    Real eigenvectors associated with ``wr``\n\n* **eig **: Eigenvalues and right eigenvectors for non-symmetric arrays\n\n* **rsf2csf **: Convert real Schur form to complex Schur form\n\n* **.. versionadded**: \n\n"
},{
    "source file": "decorator.py",
    "line number": "321",
    "func name": "dispatch_on",
    "func arg": "()",
    "comments": "Factory of decorators turning a function into a generic function dispatching on the given arguments.\n\n\n"
},{
    "source file": "demo_lgmres68.py",
    "line number": "23",
    "func name": "matvec",
    "func arg": "(v)",
    "comments": ""
},{
    "source file": "deprecation.py",
    "line number": "46",
    "func name": "deprecate_cython_api",
    "func arg": "(module, routine_name, new_name, message)",
    "comments": "Deprecate an exported cdef function in a public Cython API module.\n\nOnly functions can be deprecated; typedefs etc. cannot.\n\nParameters ---------- module : module Public Cython API module (e.g. scipy.linalg.cython_blas). routine_name : str Name of the routine to deprecate. May also be a fused-type routine (in which case its all specializations are deprecated). new_name : str New name to include in the deprecation warning message message : str Additional text in the deprecation warning message\n\nExamples -------- Usually, this function would be used in the top-level of the module ``.pyx`` file:\n\n>>> from scipy._lib.deprecation import deprecate_cython_api >>> import scipy.linalg.cython_blas as mod >>> deprecate_cython_api(mod, \"dgemm\", \"dgemm_new\", ...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmessage=\"Deprecated in Scipy 1.5.0\") >>> del deprecate_cython_api, mod\n\nAfter this, Cython modules that use the deprecated function emit a deprecation warning when they are imported.\n"
},{
    "source file": "dia69.py",
    "line number": "408",
    "func name": "isspmatrix_dia",
    "func arg": "(x)",
    "comments": "Is x of dia_matrix type?\n\nParameters ---------- x object to check for being a dia matrix\n##### Returns\n"
},{
    "source file": "distance70.py",
    "line number": "2402",
    "func name": "cdist",
    "func arg": "(XA, XB, metric, **kwargs)",
    "comments": "Compute distance between each pair of the two collections of inputs.\n\nSee Notes for common calling conventions.\n\nParameters ---------- XA : ndarray An :math:`m_A` by :math:`n` array of :math:`m_A` original observations in an :math:`n`-dimensional space. Inputs are converted to float type. XB : ndarray An :math:`m_B` by :math:`n` array of :math:`m_B` original observations in an :math:`n`-dimensional space. Inputs are converted to float type. metric : str or callable, optional The distance metric to use.\n\nIf a string, the distance function can be 'braycurtis', 'canberra', 'chebyshev', 'cityblock', 'correlation', 'cosine', 'dice', 'euclidean', 'hamming', 'jaccard', 'jensenshannon', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'wminkowski', 'yule'. *args : tuple. Deprecated. Additional arguments should be passed as keyword arguments **kwargs : dict, optional Extra arguments to `metric`: refer to each metric documentation for a list of all possible arguments.\n\nSome possible arguments:\n\np : scalar The p-norm to apply for Minkowski, weighted and unweighted. Default: 2.\n\nw : ndarray The weight vector for metrics that support weights (e.g., Minkowski).\n\nV : ndarray The variance vector for standardized Euclidean. Default: var(vstack([XA, XB]), axis=0, ddof=1)\n\nVI : ndarray The inverse of the covariance matrix for Mahalanobis. Default: inv(cov(vstack([XA, XB].T))).T\n\nout : ndarray The output array If not None, the distance matrix Y is stored in this array. Note: metric independent, it will become a regular keyword arg in a future scipy version\n##### Returns\n* **Y **: ndarray\n    A\n\n"
},{
    "source file": "doccer.py",
    "line number": "50",
    "func name": "unindent_string",
    "func arg": "(docstring)",
    "comments": ""
},{
    "source file": "doccer72.py",
    "line number": "251",
    "func name": "doc_replace",
    "func arg": "(obj, oldval, newval)",
    "comments": "Decorator to take the docstring from obj, with oldval replaced by newval\n\nEquivalent to ``func.__doc__ = obj.__doc__.replace(oldval, newval)``\n\nParameters ---------- obj: object The object to take the docstring from. oldval: string The string to replace from the original docstring. newval: string The string to replace ``oldval`` with.\n"
},{
    "source file": "dogbox.py",
    "line number": "149",
    "func name": "dogbox",
    "func arg": "(fun, jac, x0, f0, J0, lb, ub, ftol, xtol, gtol, max_nfev, x_scale, loss_function, tr_solver, tr_options, verbose)",
    "comments": ""
},{
    "source file": "doi_role.py",
    "line number": "50",
    "func name": "setup",
    "func arg": "(app)",
    "comments": ""
},{
    "source file": "dok73.py",
    "line number": "430",
    "func name": "isspmatrix_dok",
    "func arg": "(x)",
    "comments": "Is x of dok_matrix type?\n\nParameters ---------- x object to check for being a dok matrix\n##### Returns\n"
},{
    "source file": "download-wheels.py",
    "line number": "41",
    "func name": "download_wheels",
    "func arg": "(version, wheelhouse)",
    "comments": "Download release wheels.\n\nThe release wheels for the given SciPy version are downloaded into the given directory.\n\nParameters ---------- version : str The release version. For instance, \"1.5.0\". wheelhouse : str Directory in which to download the wheels.\n"
},{
    "source file": "equality_constrained_sqp.py",
    "line number": "17",
    "func name": "equality_constrained_sqp",
    "func arg": "(fun_and_constr, grad_and_jac, lagr_hess, x0, fun0, grad0, constr0, jac0, stop_criteria, state, initial_penalty, initial_trust_radius, factorization_method, trust_lb, trust_ub, scaling)",
    "comments": "Solve nonlinear equality-constrained problem using trust-region SQP.\n\nSolve optimization problem:\n\nminimize fun(x) subject to: constr(x) = 0\n\nusing Byrd-Omojokun Trust-Region SQP method described in [1]_. Several implementation details are based on [2]_ and [3]_, p. 549.\n\nReferences ---------- .. [1] Lalee, Marucha, Jorge Nocedal, and Todd Plantenga. \"On the implementation of an algorithm for large-scale equality constrained optimization.\" SIAM Journal on Optimization 8.3 (1998): 682-706. .. [2] Byrd, Richard H., Mary E. Hribar, and Jorge Nocedal. \"An interior point algorithm for large-scale nonlinear programming.\" SIAM Journal on Optimization 9.4 (1999): 877-900. .. [3] Nocedal, Jorge, and Stephen J. Wright. \"Numerical optimization\" Second Edition (2006).\n"
},{
    "source file": "example.py",
    "line number": "11",
    "func name": "function",
    "func arg": "(x)",
    "comments": ""
},{
    "source file": "expn_asy.py",
    "line number": "34",
    "func name": "main",
    "func arg": "()",
    "comments": ""
},{
    "source file": "extract74.py",
    "line number": "165",
    "func name": "_masked_coo",
    "func arg": "(A, mask)",
    "comments": ""
},{
    "source file": "fft_basic.py",
    "line number": "66",
    "func name": "get_module",
    "func arg": "(mod_name)",
    "comments": ""
},{
    "source file": "fftpack_pseudo_diffs.py",
    "line number": "49",
    "func name": "direct_shift",
    "func arg": "(x, a, period)",
    "comments": ""
},{
    "source file": "filter_design75.py",
    "line number": "4879",
    "func name": "gammatone",
    "func arg": "(freq, ftype, order, numtaps, fs)",
    "comments": "Gammatone filter design.\n\nThis function computes the coefficients of an FIR or IIR gammatone digital filter [1]_.\n\nParameters ---------- freq : float Center frequency of the filter (expressed in the same units as `fs`). ftype : {'fir', 'iir'} The type of filter the function generates. If 'fir', the function will generate an Nth order FIR gammatone filter. If 'iir', the function will generate an 8th order digital IIR filter, modeled as as 4th order gammatone filter. order : int, optional The order of the filter. Only used when ``ftype='fir'``. Default is 4 to model the human auditory system. Must be between 0 and 24. numtaps : int, optional Length of the filter. Only used when ``ftype='fir'``. Default is ``fs*0.015`` if `fs` is greater than 1000, 15 if `fs` is less than or equal to 1000. fs : float, optional The sampling frequency of the signal. `freq` must be between 0 and ``fs/2``. Default is 2.\n##### Returns\n* **b, a **: ndarray, ndarray\n    Numerator (``b``) and denominator (``a``) polynomials of the filter.\n\n"
},{
    "source file": "filters.py",
    "line number": "1449",
    "func name": "generic_filter",
    "func arg": "(input, function, size, footprint, output, mode, cval, origin, extra_arguments, extra_keywords)",
    "comments": "Calculate a multidimensional filter using the given function.\n\nAt each element the provided function is called. The input values within the filter footprint at that element are passed to the function as a 1-D array of double values.\n\nParameters ---------- %(input)s function : {callable, scipy.LowLevelCallable} Function to apply at each element. %(size_foot)s %(output)s %(mode_reflect)s %(cval)s %(origin_multiple)s %(extra_arguments)s %(extra_keywords)s\n\nNotes ----- This function also accepts low-level callback functions with one of the following signatures and wrapped in `scipy.LowLevelCallable`:\n\n.. code:: c\n\nint callback(double *buffer, npy_intp filter_size, double *return_value, void *user_data) int callback(double *buffer, intptr_t filter_size, double *return_value, void *user_data)\n\nThe calling function iterates over the elements of the input and output arrays, calling the callback function at each element. The elements within the footprint of the filter at the current element are passed through the ``buffer`` parameter, and the number of elements within the footprint through ``filter_size``. The calculated value is returned in ``return_value``. ``user_data`` is the data pointer provided to `scipy.LowLevelCallable` as-is.\n\nThe callback function must return an integer error status that is zero if something went wrong and one otherwise. If an error occurs, you should normally set the python error status with an informative message before returning, otherwise a default error message is set by the calling function.\n\nIn addition, some other low-level function pointer specifications are accepted, but these are for backward compatibility only and should not be used in new code.\n"
},{
    "source file": "fir_filter_design76.py",
    "line number": "1091",
    "func name": "minimum_phase",
    "func arg": "(h, method, n_fft)",
    "comments": "Convert a linear-phase FIR filter to minimum phase\n\nParameters ---------- h : array Linear-phase FIR filter coefficients. method : {'hilbert', 'homomorphic'} The method to use:\n\n'homomorphic' (default) This method [4]_ [5]_ works best with filters with an odd number of taps, and the resulting minimum phase filter will have a magnitude response that approximates the square root of the the original filter's magnitude response.\n\n'hilbert' This method [1]_ is designed to be used with equiripple filters (e.g., from `remez`) with unity or zero gain regions.\n\nn_fft : int The number of points to use for the FFT. Should be at least a few times larger than the signal length (see Notes).\n##### Returns\n* **h_minimum **: array\n    The minimum-phase version of the filter, with length\n    ``(length(h) + 1) // 2``.\n\n* **``n_stop`` and FFT length ``n_fft`` as**: \n\n* **length to be the next power of 2 that satisfies ``epsilon=0.01`` as**: \n\n* **For more information, see**: http\n\n* **Create an optimal linear-phase filter, then convert it to minimum phase**: \n\n* **Convert it to minimum phase**: \n\n* **Compare the three filters**: \n\n* **...                            ('-', '-', '--'), ('k', 'r', 'c'))**: \n\n* **>>> for ax in axs**: \n\n* **...     ax.fill_between(freq[1**: 3], *ax.get_ylim(), color='#ffeeaa', zorder=1)\n\n* **>>> for ax, ylim in zip(axs[1**: ], ([0, 1.1], [-150, 10], [-60, 60]))\n\n* **.. [1] N. Damera-Venkata and B. L. Evans, \"Optimal design of real and\n       complex minimum phase digital FIR filters,\" Acoustics, Speech,\n       and Signal Processing, 1999. Proceedings., 1999 IEEE International\n       Conference on, Phoenix, AZ, 1999, pp. 1145-1148 vol.3.\n       doi**: 10.1109/ICASSP.1999.756179\n\n* **.. [3] T. Saramaki, \"Finite Impulse Response Filter Design,\" in\n       Handbook for Digital Signal Processing, chapter 4,\n       New York**: Wiley-Interscience, 1993.\n\n* **.. [4] J. S. Lim, Advanced Topics in Signal Processing.\n       Englewood Cliffs, N.J.**: Prentice Hall, 1988.\n\n* **.. [5] A. V. Oppenheim, R. W. Schafer, and J. R. Buck,\n       \"Discrete-Time Signal Processing,\" 2nd edition.\n       Upper Saddle River, N.J.**: Prentice Hall, 1999.\n\n"
},{
    "source file": "fitpack77.py",
    "line number": "659",
    "func name": "splantider",
    "func arg": "(tck, n)",
    "comments": "Compute the spline for the antiderivative (integral) of a given spline.\n\nParameters ---------- tck : BSpline instance or a tuple of (t, c, k) Spline whose antiderivative to compute n : int, optional Order of antiderivative to evaluate. Default: 1\n##### Returns\n* **.. versionadded**: \n\n* **although some floating point error accumulates**: \n\n* **Antiderivative can be used to evaluate definite integrals**: \n\n* ****: math\n\n"
},{
    "source file": "flinalg.py",
    "line number": "27",
    "func name": "get_flinalg_funcs",
    "func arg": "(names, arrays, debug)",
    "comments": "Return optimal available _flinalg function objects with names. Arrays are used to determine optimal prefix.\n\n\n"
},{
    "source file": "fourier.py",
    "line number": "251",
    "func name": "fourier_shift",
    "func arg": "(input, shift, n, axis, output)",
    "comments": "Multidimensional Fourier shift filter.\n\nThe array is multiplied with the Fourier transform of a shift operation.\n\nParameters ---------- input : array_like The input array. shift : float or sequence The size of the box used for filtering. If a float, `shift` is the same for all axes. If a sequence, `shift` has to contain one value for each axis. n : int, optional If `n` is negative (default), then the input is assumed to be the result of a complex fft. If `n` is larger than or equal to zero, the input is assumed to be the result of a real fft, and `n` gives the length of the array before transformation along the real transform direction. axis : int, optional The axis of the real transform. output : ndarray, optional If given, the result of shifting the input is placed in this array. None is returned in this case.\n##### Returns\n* **fourier_shift **: ndarray\n    The shifted input.\n\n"
},{
    "source file": "gammainc_asy.py",
    "line number": "93",
    "func name": "main",
    "func arg": "()",
    "comments": ""
},{
    "source file": "gammainc_data.py",
    "line number": "89",
    "func name": "main",
    "func arg": "()",
    "comments": ""
},{
    "source file": "gen_fftw_ref79.py",
    "line number": "8",
    "func name": "gen_data",
    "func arg": "(dt)",
    "comments": ""
},{
    "source file": "generate_label_testvectors.py",
    "line number": "5",
    "func name": "generate_test_vecs",
    "func arg": "(infile, strelfile, resultfile)",
    "comments": "test label with different structuring element neighborhoods\n\n\n"
},{
    "source file": "generate_sparsetools81.py",
    "line number": "424",
    "func name": "write_autogen_blurb",
    "func arg": "(stream)",
    "comments": ""
},{
    "source file": "gh_lists.py",
    "line number": "84",
    "func name": "get_issues",
    "func arg": "(getter, project, milestone)",
    "comments": ""
},{
    "source file": "hb.py",
    "line number": "518",
    "func name": "hb_write",
    "func arg": "(path_or_open_file, m, hb_info)",
    "comments": "Write HB-format file.\n\nParameters ---------- path_or_open_file : path-like or file-like If a file-like object, it is used as-is. Otherwise, it is opened before writing. m : sparse-matrix the sparse matrix to write hb_info : HBInfo contains the meta-data for write\n##### Returns\n* **features are**: - assembled, non-symmetric, real matrices\n    - integer for pointer/indices\n    - exponential format for float values, and int format\n\n* **We can read and write a harwell-boeing format file**: \n\n"
},{
    "source file": "helper82.py",
    "line number": "99",
    "func name": "_good_shape",
    "func arg": "(x, shape, axes)",
    "comments": "Ensure that shape argument is valid for scipy.fftpack\n\nscipy.fftpack does not support len(shape) < x.ndim when axes is not given.\n"
},{
    "source file": "helper83.py",
    "line number": "201",
    "func name": "get_workers",
    "func arg": "()",
    "comments": "Returns the default number of workers within the current context\n\nExamples -------- >>> from scipy import fft >>> fft.get_workers() 1 >>> with fft.set_workers(4): ...\n\n\n\n fft.get_workers() 4\n"
},{
    "source file": "hierarchy.py",
    "line number": "4039",
    "func name": "leaders",
    "func arg": "(Z, T)",
    "comments": "Return the root nodes in a hierarchical clustering.\n\n\n##### Returns\n* **L **: ndarray\n    The leader linkage node id's stored as a k-element 1-D array,\n    where ``k`` is the number of flat clusters found in ``T``.\n    ``L[j]=i`` is the linkage cluster node id that is the\n    leader of flat cluster with id M[j]. If ``i < n``, ``i``\n    corresponds to an original observation, otherwise it\n    corresponds to a non-singleton cluster.\n\n* **M **: ndarray\n    The leader linkage node id's stored as a k-element 1-D array, where\n    ``k`` is the number of flat clusters found in ``T``. This allows the\n    set of flat cluster ids to be any arbitrary set of ``k`` integers.\n    For example\n\n* **fcluster**: for the creation of flat cluster assignments.\n\n* **to a dataset ``X`` - and a flat cluster assignment array ``T``**: \n\n* **in the dendrogram that are the leaders of each flat cluster**: \n\n* **the flat clusters in ``T``**: \n\n"
},{
    "source file": "idl.py",
    "line number": "663",
    "func name": "readsav",
    "func arg": "(file_name, idict, python_dict, uncompressed_file_name, verbose)",
    "comments": "Read an IDL .sav file.\n\nParameters ---------- file_name : str Name of the IDL save file. idict : dict, optional Dictionary in which to insert .sav file variables. python_dict : bool, optional By default, the object return is not a Python dictionary, but a case-insensitive dictionary with item, attribute, and call access to variables. To get a standard Python dictionary, set this option to True. uncompressed_file_name : str, optional This option only has an effect for .sav files written with the /compress option. If a file name is specified, compressed .sav files are uncompressed to this file. Otherwise, readsav will use the `tempfile` module to determine a temporary filename automatically, and will remove the temporary file upon successfully reading it in. verbose : bool, optional Whether to print out information about the save file, including the records read, and available variables.\n##### Returns\n* **idl_dict **: AttrDict or dict\n    If `python_dict` is set to False (default), this function returns a\n    case-insensitive dictionary with item, attribute, and call access\n    to variables. If `python_dict` is set to True, this function\n    returns a Python dictionary with all variable names in lowercase.\n    If `idict` was specified, then variables are written to the\n    dictionary specified, and the updated dictionary is returned.\n\n"
},{
    "source file": "interface84.py",
    "line number": "773",
    "func name": "aslinearoperator",
    "func arg": "(A)",
    "comments": "Return A as a LinearOperator.\n\n'A' may be any of the following types:\n\n- ndarray\n\n- matrix\n\n- sparse matrix (e.g. csr_matrix, lil_matrix, etc.)\n\n- LinearOperator\n\n- An object with .shape and .matvec attributes\n\nSee the LinearOperator documentation for additional information.\n\nNotes ----- If 'A' has no .dtype attribute, the data type is determined by calling :func:`LinearOperator.matvec()`\n\n- set the .dtype attribute to prevent this call upon the linear operator creation.\n\nExamples -------- >>> from scipy.sparse.linalg import aslinearoperator >>> M = np.array([[1,2,3],[4,5,6]], dtype=np.int32) >>> aslinearoperator(M) <2x3 MatrixLinearOperator with dtype=int32>\n"
},{
    "source file": "interpnd_info85.py",
    "line number": "9",
    "func name": "_estimate_gradients_2d_global",
    "func arg": "()",
    "comments": ""
},{
    "source file": "interpolate86.py",
    "line number": "2549",
    "func name": "interpn",
    "func arg": "(points, values, xi, method, bounds_error, fill_value)",
    "comments": "Multidimensional interpolation on regular grids.\n\nParameters ---------- points : tuple of ndarray of float, with shapes (m1, ), ..., (mn, ) The points defining the regular grid in n dimensions.\n\nvalues : array_like, shape (m1, ..., mn, ...) The data on the regular grid in n dimensions.\n\nxi : ndarray of shape (..., ndim) The coordinates to sample the gridded data at\n\nmethod : str, optional The method of interpolation to perform. Supported are \"linear\" and \"nearest\", and \"splinef2d\". \"splinef2d\" is only supported for 2-dimensional data.\n\nbounds_error : bool, optional If True, when interpolated values are requested outside of the domain of the input data, a ValueError is raised. If False, then `fill_value` is used.\n\nfill_value : number, optional If provided, the value to use for points outside of the interpolation domain. If None, values outside the domain are extrapolated.\n\nExtrapolation is not supported by method \"splinef2d\".\n##### Returns\n* **values_x **: ndarray, shape xi.shape[\n\n* **.. versionadded**: \n\n* **Evaluate a simple example function on the points of a regular 3-D grid**: \n\n* **>>> def value_func_3d(x, y, z)**: \n\n* **NearestNDInterpolator **: Nearest neighbor interpolation on unstructured\n                        data in N dimensions\n\n* **LinearNDInterpolator **: Piecewise linear interpolant on unstructured data\n                       in N dimensions\n\n* **RegularGridInterpolator **: Linear and nearest-neighbor Interpolation on a\n                          regular grid in arbitrary dimensions\n\n* **RectBivariateSpline **: Bivariate spline approximation over a rectangular mesh\n\n"
},{
    "source file": "interpolation.py",
    "line number": "653",
    "func name": "rotate",
    "func arg": "(input, angle, axes, reshape, output, order, mode, cval, prefilter)",
    "comments": "Rotate an array.\n\nThe array is rotated in the plane defined by the two axes given by the `axes` parameter using spline interpolation of the requested order.\n\nParameters ---------- %(input)s angle : float The rotation angle in degrees. axes : tuple of 2 ints, optional The two axes that define the plane of rotation. Default is the first two axes. reshape : bool, optional If `reshape` is true, the output shape is adapted so that the input array is contained completely in the output. Default is True. %(output)s order : int, optional The order of the spline interpolation, default is 3. The order has to be in the range 0-5. %(mode_constant)s %(cval)s %(prefilter)s\n##### Returns\n* **rotate **: ndarray\n    The rotated input.\n\n"
},{
    "source file": "interpolative.py",
    "line number": "920",
    "func name": "estimate_rank",
    "func arg": "(A, eps)",
    "comments": "Estimate matrix rank to a specified relative precision using randomized methods.\n\nThe matrix `A` can be given as either a :class:`numpy.ndarray` or a :class:`scipy.sparse.linalg.LinearOperator`, with different algorithms used for each case. If `A` is of type :class:`numpy.ndarray`, then the output rank is typically about 8 higher than the actual numerical rank.\n\n..\n\nThis function automatically detects the form of the input parameters and passes them to the appropriate backend. For details, see :func:`backend.idd_estrank`, :func:`backend.idd_findrank`, :func:`backend.idz_estrank`, and :func:`backend.idz_findrank`.\n\nParameters ---------- A : :class:`numpy.ndarray` or :class:`scipy.sparse.linalg.LinearOperator` Matrix whose rank is to be estimated, given as either a :class:`numpy.ndarray` or a :class:`scipy.sparse.linalg.LinearOperator` with the `rmatvec` method (to apply the matrix adjoint). eps : float Relative error for numerical rank definition.\n##### Returns\n"
},{
    "source file": "iterative87.py",
    "line number": "665",
    "func name": "qmr",
    "func arg": "(A, b, x0, tol, maxiter, M1, M2, callback, atol)",
    "comments": "Use Quasi-Minimal Residual iteration to solve ``Ax = b``.\n\nParameters ---------- A : {sparse matrix, dense matrix, LinearOperator} The real-valued N-by-N matrix of the linear system. Alternatively, ``A`` can be a linear operator which can produce ``Ax`` and ``A^T x`` using, e.g., ``scipy.sparse.linalg.LinearOperator``. b : {array, matrix} Right hand side of the linear system. Has shape (N,) or (N,1).\n##### Returns\n* **x **: {array, matrix}\n    The converged solution.\n\n* **info **: integer\n    Provides convergence information\n\n* **x0  **: {array, matrix}\n    Starting guess for the solution.\n\n* **tol, atol **: float, optional\n    Tolerances for convergence, ``norm(residual) <= max(tol*norm(b), atol)``.\n    The default for ``atol`` is ``'legacy'``, which emulates\n    a different legacy behavior.\n    .. warning\n\n* **maxiter **: integer\n    Maximum number of iterations.  Iteration will stop after maxiter\n    steps even if the specified tolerance has not been achieved.\n\n* **M1 **: {sparse matrix, dense matrix, LinearOperator}\n    Left preconditioner for A.\n\n* **M2 **: {sparse matrix, dense matrix, LinearOperator}\n    Right preconditioner for A. Used together with the left\n    preconditioner M1.  The matrix M1*A*M2 should have better\n    conditioned than A alone.\n\n* **callback **: function\n    User-supplied function to call after each iteration.  It is called\n    as callback(xk), where xk is the current solution vector.\n\n"
},{
    "source file": "ivp.py",
    "line number": "156",
    "func name": "solve_ivp",
    "func arg": "(fun, t_span, y0, method, t_eval, dense_output, events, vectorized, args, **options)",
    "comments": "Solve an initial value problem for a system of ODEs.\n\nThis function numerically integrates a system of ordinary differential equations given an initial value::\n\ndy / dt = f(t, y) y(t0) = y0\n\nHere t is a 1-D independent variable (time), y(t) is an N-D vector-valued function (state), and an N-D vector-valued function f(t, y) determines the differential equations. The goal is to find y(t) approximately satisfying the differential equations, given an initial value y(t0)=y0.\n\nSome of the solvers support integration in the complex domain, but note that for stiff ODE solvers, the right-hand side must be complex-differentiable (satisfy Cauchy-Riemann equations [11]_). To solve a problem in the complex domain, pass y0 with a complex data type. Another option always available is to rewrite your problem for real and imaginary parts separately.\n\nParameters ---------- fun : callable Right-hand side of the system. The calling signature is ``fun(t, y)``. Here `t` is a scalar, and there are two options for the ndarray `y`: It can either have shape (n,); then `fun` must return array_like with shape (n,). Alternatively, it can have shape (n, k); then `fun` must return an array_like with shape (n, k), i.e., each column corresponds to a single column in `y`. The choice between the two options is determined by `vectorized` argument (see below). The vectorized implementation allows a faster approximation of the Jacobian by finite differences (required for stiff solvers). t_span : 2-tuple of floats Interval of integration (t0, tf). The solver starts with t=t0 and integrates until it reaches t=tf. y0 : array_like, shape (n,) Initial state. For problems in the complex domain, pass `y0` with a complex data type (even if the initial value is purely real). method : string or `OdeSolver`, optional Integration method to use:\n\n* 'RK45' (default): Explicit Runge-Kutta method of order 5(4) [1]_. The error is controlled assuming accuracy of the fourth-order method, but steps are taken using the fifth-order accurate formula (local extrapolation is done). A quartic interpolation polynomial is used for the dense output [2]_. Can be applied in the complex domain. * 'RK23': Explicit Runge-Kutta method of order 3(2) [3]_. The error is controlled assuming accuracy of the second-order method, but steps are taken using the third-order accurate formula (local extrapolation is done). A cubic Hermite polynomial is used for the dense output. Can be applied in the complex domain. * 'DOP853': Explicit Runge-Kutta method of order 8 [13]_. Python implementation of the \"DOP853\" algorithm originally written in Fortran [14]_. A 7-th order interpolation polynomial accurate to 7-th order is used for the dense output. Can be applied in the complex domain. * 'Radau': Implicit Runge-Kutta method of the Radau IIA family of order 5 [4]_. The error is controlled with a third-order accurate embedded formula. A cubic polynomial which satisfies the collocation conditions is used for the dense output. * 'BDF': Implicit multi-step variable-order (1 to 5) method based on a backward differentiation formula for the derivative approximation [5]_. The implementation follows the one described in [6]_. A quasi-constant step scheme is used and accuracy is enhanced using the NDF modification. Can be applied in the complex domain. * 'LSODA': Adams/BDF method with automatic stiffness detection and switching [7]_, [8]_. This is a wrapper of the Fortran solver from ODEPACK.\n\nExplicit Runge-Kutta methods ('RK23', 'RK45', 'DOP853') should be used for non-stiff problems and implicit methods ('Radau', 'BDF') for stiff problems [9]_. Among Runge-Kutta methods, 'DOP853' is recommended for solving with high precision (low values of `rtol` and `atol`).\n\nIf not sure, first try to run 'RK45'. If it makes unusually many iterations, diverges, or fails, your problem is likely to be stiff and you should use 'Radau' or 'BDF'. 'LSODA' can also be a good universal choice, but it might be somewhat less convenient to work with as it wraps old Fortran code.\n\nYou can also pass an arbitrary class derived from `OdeSolver` which implements the solver. t_eval : array_like or None, optional Times at which to store the computed solution, must be sorted and lie within `t_span`. If None (default), use points selected by the solver. dense_output : bool, optional Whether to compute a continuous solution. Default is False. events : callable, or list of callables, optional Events to track. If None (default), no events will be tracked. Each event occurs at the zeros of a continuous function of time and state. Each function must have the signature ``event(t, y)`` and return a float. The solver will find an accurate value of `t` at which ``event(t, y(t)) = 0`` using a root-finding algorithm. By default, all zeros will be found. The solver looks for a sign change over each step, so if multiple zero crossings occur within one step, events may be missed. Additionally each `event` function might have the following attributes:\n\nterminal: bool, optional Whether to terminate integration if this event occurs. Implicitly False if not assigned. direction: float, optional Direction of a zero crossing. If `direction` is positive, `event` will only trigger when going from negative to positive, and vice versa if `direction` is negative. If 0, then either direction will trigger event. Implicitly 0 if not assigned.\n\nYou can assign attributes like ``event.terminal = True`` to any function in Python. vectorized : bool, optional Whether `fun` is implemented in a vectorized fashion. Default is False. args : tuple, optional Additional arguments to pass to the user-defined functions.\n\nIf given, the additional arguments are passed to all user-defined functions. So if, for example, `fun` has the signature ``fun(t, y, a, b, c)``, then `jac` (if given) and any event functions must have the same signature, and `args` must be a tuple of length 3. options Options passed to a chosen solver. All options available for already implemented solvers are listed below. first_step : float or None, optional Initial step size. Default is `None` which means that the algorithm should choose. max_step : float, optional Maximum allowed step size. Default is np.inf, i.e., the step size is not bounded and determined solely by the solver. rtol, atol : float or array_like, optional Relative and absolute tolerances. The solver keeps the local error estimates less than ``atol + rtol * abs(y)``. Here `rtol` controls a relative accuracy (number of correct digits). But if a component of `y` is approximately below `atol`, the error only needs to fall within the same `atol` threshold, and the number of correct digits is not guaranteed. If components of y have different scales, it might be beneficial to set different `atol` values for different components by passing array_like with shape (n,) for `atol`. Default values are 1e-3 for `rtol` and 1e-6 for `atol`. jac : array_like, sparse_matrix, callable or None, optional Jacobian matrix of the right-hand side of the system with respect to y, required by the 'Radau', 'BDF' and 'LSODA' method. The Jacobian matrix has shape (n, n) and its element (i, j) is equal to ``d f_i / d y_j``.\n\nThere are three ways to define the Jacobian:\n\n* If array_like or sparse_matrix, the Jacobian is assumed to be constant. Not supported by 'LSODA'. * If callable, the Jacobian is assumed to depend on both t and y; it will be called as ``jac(t, y)``, as necessary. For 'Radau' and 'BDF' methods, the return value might be a sparse matrix. * If None (default), the Jacobian will be approximated by finite differences.\n\nIt is generally recommended to provide the Jacobian rather than relying on a finite-difference approximation. jac_sparsity : array_like, sparse matrix or None, optional Defines a sparsity structure of the Jacobian matrix for a finite- difference approximation. Its shape must be (n, n). This argument is ignored if `jac` is not `None`. If the Jacobian has only few non-zero elements in *each* row, providing the sparsity structure will greatly speed up the computations [10]_. A zero entry means that a corresponding element in the Jacobian is always zero. If None (default), the Jacobian is assumed to be dense. Not supported by 'LSODA', see `lband` and `uband` instead. lband, uband : int or None, optional Parameters defining the bandwidth of the Jacobian for the 'LSODA' method, i.e., ``jac[i, j] != 0 only for i\n\n- lband <= j <= i + uband``. Default is None. Setting these requires your jac routine to return the Jacobian in the packed format: the returned array must have ``n`` columns and ``uband + lband + 1`` rows in which Jacobian diagonals are written. Specifically ``jac_packed[uband + i\n\n- j , j] = jac[i, j]``. The same format is used in `scipy.linalg.solve_banded` (check for an illustration).\n\nThese parameters can be also used with ``jac=None`` to reduce the number of Jacobian elements estimated by finite differences. min_step : float, optional The minimum allowed step size for 'LSODA' method. By default `min_step` is zero.\n##### Returns\n* **Bunch object with the following fields defined**: \n\n* **t **: ndarray, shape (n_points,)\n    Time points.\n\n* **y **: ndarray, shape (n, n_points)\n    Values of the solution at `t`.\n\n* **sol **: `OdeSolution` or None\n    Found solution as `OdeSolution` instance; None if `dense_output` was\n    set to False.\n\n* **t_events **: list of ndarray or None\n    Contains for each event type a list of arrays at which an event of\n    that type event was detected. None if `events` was None.\n\n* **y_events **: list of ndarray or None\n    For each value of `t_events`, the corresponding value of the solution.\n    None if `events` was None.\n\n* **nfev **: int\n    Number of evaluations of the right-hand side.\n\n* **njev **: int\n    Number of evaluations of the Jacobian.\n\n* **nlu **: int\n    Number of LU decompositions.\n\n* **status **: int\n    Reason for algorithm termination\n\n* **message **: string\n    Human-readable description of the termination reason.\n\n* **success **: bool\n    True if the solver reached the interval end or a termination event\n    occurred (``status >= 0``).\n\n* **.. [4] E. Hairer, G. Wanner, \"Solving Ordinary Differential Equations II**: Stiff and Differential-Algebraic Problems\", Sec. IV.8.\n\n* **.. [5] `Backward Differentiation Formula\n        <https**: //en.wikipedia.org/wiki/Backward_differentiation_formula>`_\n        on Wikipedia.\n\n* **.. [9] `Stiff equation <https**: //en.wikipedia.org/wiki/Stiff_equation>`_ on\n       Wikipedia.\n\n* **.. [11] `Cauchy-Riemann equations\n         <https**: //en.wikipedia.org/wiki/Cauchy-Riemann_equations>`_ on\n         Wikipedia.\n\n* **.. [12] `Lotka-Volterra equations\n        <https**: //en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations>`_\n        on Wikipedia.\n\n* **.. [13] E. Hairer, S. P. Norsett G. Wanner, \"Solving Ordinary Differential\n        Equations I**: Nonstiff Problems\", Sec. II.\n\n* **.. [14] `Page with original Fortran code of DOP853\n        <http**: //www.unige.ch/~hairer/software.html>`_.\n\n* **>>> def exponential_decay(t, y)**: return -0.5 * y\n\n* **>>> def upward_cannon(t, y)**: return [y[1], -0.5]\n\n* **>>> def hit_ground(t, y)**: return y[0]\n\n* **>>> def apex(t, y)**: return y[1]\n\n* **>>> def lotkavolterra(t, z, a, b, c, d)**: \n\n"
},{
    "source file": "kde_plot2.py",
    "line number": "10",
    "func name": "my_kde_bandwidth",
    "func arg": "(obj, fac)",
    "comments": "We use Scott's Rule, multiplied by a constant factor.\n\n\n"
},{
    "source file": "kde_plot4.py",
    "line number": "8",
    "func name": "my_kde_bandwidth",
    "func arg": "(obj, fac)",
    "comments": "We use Scott's Rule, multiplied by a constant factor.\n\n\n"
},{
    "source file": "kde_plot5.py",
    "line number": "6",
    "func name": "measure",
    "func arg": "(n)",
    "comments": "Measurement model, return two coupled measurements.\n\n\n"
},{
    "source file": "kdtree89.py",
    "line number": "1039",
    "func name": "distance_matrix",
    "func arg": "(x, y, p, threshold)",
    "comments": "Compute the distance matrix.\n\n\n##### Returns\n* **result **: (M, N) ndarray\n    Matrix containing the distance from every vector in `x` to every vector\n    in `y`.\n\n"
},{
    "source file": "lambertw.py",
    "line number": "21",
    "func name": "main",
    "func arg": "()",
    "comments": ""
},{
    "source file": "lapack.py",
    "line number": "991",
    "func name": "_check_work_float",
    "func arg": "(value, dtype, int_dtype)",
    "comments": "Convert LAPACK-returned work array size float to integer, carefully for single-precision types.\n\n\n"
},{
    "source file": "lbfgsb.py",
    "line number": "210",
    "func name": "_minimize_lbfgsb",
    "func arg": "(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)",
    "comments": "Minimize a scalar function of one or more variables using the L-BFGS-B algorithm.\n\nOptions ------- disp : None or int If `disp is None` (the default), then the supplied version of `iprint` is used. If `disp is not None`, then it overrides the supplied version of `iprint` with the behaviour you outlined. maxcor : int The maximum number of variable metric corrections used to define the limited memory matrix. (The limited memory BFGS method does not store the full hessian but uses this many terms in an approximation to it.) ftol : float The iteration stops when ``(f^k\n\n- f^{k+1})/max{|f^k|,|f^{k+1}|,1} <= ftol``. gtol : float The iteration will stop when ``max{|proj g_i | i = 1, ..., n} <= gtol`` where ``pg_i`` is the i-th component of the projected gradient. eps : float or ndarray If `jac is None` the absolute step size used for numerical approximation of the jacobian via forward differences. maxfun : int Maximum number of function evaluations. maxiter : int Maximum number of iterations. iprint : int, optional Controls the frequency of output. ``iprint < 0`` means no output; ``iprint = 0``\n\n\n\nprint only one line at the last iteration; ``0 < iprint < 99`` print also f and ``|proj g|`` every iprint iterations; ``iprint = 99``\n\n print details of every iteration except n-vectors; ``iprint = 100``\n\nprint also the changes of active set and final x; ``iprint > 100``\n\nprint details of every iteration including x and g. callback : callable, optional Called after each iteration, as ``callback(xk)``, where ``xk`` is the current parameter vector. maxls : int, optional Maximum number of line search steps (per iteration). Default is 20. finite_diff_rel_step : None or array_like, optional If `jac in ['2-point', '3-point', 'cs']` the relative step size to use for numerical approximation of the jacobian. The absolute step size is computed as ``h = rel_step * sign(x0) * max(1, abs(x0))``, possibly adjusted to fit into the bounds. For ``method='3-point'`` the sign of `h` is ignored. If None (default) then step is selected automatically.\n\nNotes ----- The option `ftol` is exposed via the `scipy.optimize.minimize` interface, but calling `scipy.optimize.fmin_l_bfgs_b` directly exposes `factr`. The relationship between the two is ``ftol = factr * numpy.finfo(float).eps``. I.e., `factr` multiplies the default machine floating-point precision to arrive at `ftol`.\n"
},{
    "source file": "least_squares.py",
    "line number": "240",
    "func name": "least_squares",
    "func arg": "(fun, x0, jac, bounds, method, ftol, xtol, gtol, x_scale, loss, f_scale, diff_step, tr_solver, tr_options, jac_sparsity, max_nfev, verbose, args, kwargs)",
    "comments": "Solve a nonlinear least-squares problem with bounds on the variables.\n\nGiven the residuals f(x) (an m-D real function of n real variables) and the loss function rho(s) (a scalar function), `least_squares` finds a local minimum of the cost function F(x)::\n\nminimize F(x) = 0.5 * sum(rho(f_i(x)**2), i = 0, ..., m\n\n- 1) subject to lb <= x <= ub\n\nThe purpose of the loss function rho(s) is to reduce the influence of outliers on the solution.\n\nParameters ---------- fun : callable Function which computes the vector of residuals, with the signature ``fun(x, *args, **kwargs)``, i.e., the minimization proceeds with respect to its first argument. The argument ``x`` passed to this function is an ndarray of shape (n,) (never a scalar, even for n=1). It must allocate and return a 1-D array_like of shape (m,) or a scalar. If the argument ``x`` is complex or the function ``fun`` returns complex residuals, it must be wrapped in a real function of real arguments, as shown at the end of the Examples section. x0 : array_like with shape (n,) or float Initial guess on independent variables. If float, it will be treated as a 1-D array with one element. jac : {'2-point', '3-point', 'cs', callable}, optional Method of computing the Jacobian matrix (an m-by-n matrix, where element (i, j) is the partial derivative of f[i] with respect to x[j]). The keywords select a finite difference scheme for numerical estimation. The scheme '3-point' is more accurate, but requires twice as many operations as '2-point' (default). The scheme 'cs' uses complex steps, and while potentially the most accurate, it is applicable only when `fun` correctly handles complex inputs and can be analytically continued to the complex plane. Method 'lm' always uses the '2-point' scheme. If callable, it is used as ``jac(x, *args, **kwargs)`` and should return a good approximation (or the exact value) for the Jacobian as an array_like (np.atleast_2d is applied), a sparse matrix (csr_matrix preferred for performance) or a `scipy.sparse.linalg.LinearOperator`. bounds : 2-tuple of array_like, optional Lower and upper bounds on independent variables. Defaults to no bounds. Each array must match the size of `x0` or be a scalar, in the latter case a bound will be the same for all variables. Use ``np.inf`` with an appropriate sign to disable bounds on all or some variables. method : {'trf', 'dogbox', 'lm'}, optional Algorithm to perform minimization.\n\n* 'trf' : Trust Region Reflective algorithm, particularly suitable for large sparse problems with bounds. Generally robust method. * 'dogbox' : dogleg algorithm with rectangular trust regions, typical use case is small problems with bounds. Not recommended for problems with rank-deficient Jacobian. * 'lm' : Levenberg-Marquardt algorithm as implemented in MINPACK. Doesn't handle bounds and sparse Jacobians. Usually the most efficient method for small unconstrained problems.\n\nDefault is 'trf'. See Notes for more information. ftol : float or None, optional Tolerance for termination by the change of the cost function. Default is 1e-8. The optimization process is stopped when ``dF < ftol * F``, and there was an adequate agreement between a local quadratic model and the true model in the last step. If None, the termination by this condition is disabled. xtol : float or None, optional Tolerance for termination by the change of the independent variables. Default is 1e-8. The exact condition depends on the `method` used:\n\n* For 'trf' and 'dogbox' : ``norm(dx) < xtol * (xtol + norm(x))``. * For 'lm' : ``Delta < xtol * norm(xs)``, where ``Delta`` is a trust-region radius and ``xs`` is the value of ``x`` scaled according to `x_scale` parameter (see below).\n\nIf None, the termination by this condition is disabled. gtol : float or None, optional Tolerance for termination by the norm of the gradient. Default is 1e-8. The exact condition depends on a `method` used:\n\n* For 'trf' : ``norm(g_scaled, ord=np.inf) < gtol``, where ``g_scaled`` is the value of the gradient scaled to account for the presence of the bounds [STIR]_. * For 'dogbox' : ``norm(g_free, ord=np.inf) < gtol``, where ``g_free`` is the gradient with respect to the variables which are not in the optimal state on the boundary. * For 'lm' : the maximum absolute value of the cosine of angles between columns of the Jacobian and the residual vector is less than `gtol`, or the residual vector is zero.\n\nIf None, the termination by this condition is disabled. x_scale : array_like or 'jac', optional Characteristic scale of each variable. Setting `x_scale` is equivalent to reformulating the problem in scaled variables ``xs = x / x_scale``. An alternative view is that the size of a trust region along jth dimension is proportional to ``x_scale[j]``. Improved convergence may be achieved by setting `x_scale` such that a step of a given size along any of the scaled variables has a similar effect on the cost function. If set to 'jac', the scale is iteratively updated using the inverse norms of the columns of the Jacobian matrix (as described in [JJMore]_). loss : str or callable, optional Determines the loss function. The following keyword values are allowed:\n\n* 'linear' (default) : ``rho(z) = z``. Gives a standard least-squares problem. * 'soft_l1' : ``rho(z) = 2 * ((1 + z)**0.5\n\n- 1)``. The smooth approximation of l1 (absolute value) loss. Usually a good choice for robust least squares. * 'huber' : ``rho(z) = z if z <= 1 else 2*z**0.5\n\n- 1``. Works similarly to 'soft_l1'. * 'cauchy' : ``rho(z) = ln(1 + z)``. Severely weakens outliers influence, but may cause difficulties in optimization process. * 'arctan' : ``rho(z) = arctan(z)``. Limits a maximum loss on a single residual, has properties similar to 'cauchy'.\n\nIf callable, it must take a 1-D ndarray ``z=f**2`` and return an array_like with shape (3, m) where row 0 contains function values, row 1 contains first derivatives and row 2 contains second derivatives. Method 'lm' supports only 'linear' loss. f_scale : float, optional Value of soft margin between inlier and outlier residuals, default is 1.0. The loss function is evaluated as follows ``rho_(f**2) = C**2 * rho(f**2 / C**2)``, where ``C`` is `f_scale`, and ``rho`` is determined by `loss` parameter. This parameter has no effect with ``loss='linear'``, but for other `loss` values it is of crucial importance. max_nfev : None or int, optional Maximum number of function evaluations before the termination. If None (default), the value is chosen automatically:\n\n* For 'trf' and 'dogbox' : 100 * n. * For 'lm' :\n\n100 * n if `jac` is callable and 100 * n * (n + 1) otherwise (because 'lm' counts function calls in Jacobian estimation).\n\ndiff_step : None or array_like, optional Determines the relative step size for the finite difference approximation of the Jacobian. The actual step is computed as ``x * diff_step``. If None (default), then `diff_step` is taken to be a conventional \"optimal\" power of machine epsilon for the finite difference scheme used [NR]_. tr_solver : {None, 'exact', 'lsmr'}, optional Method for solving trust-region subproblems, relevant only for 'trf' and 'dogbox' methods.\n\n* 'exact' is suitable for not very large problems with dense Jacobian matrices. The computational complexity per iteration is comparable to a singular value decomposition of the Jacobian matrix. * 'lsmr' is suitable for problems with sparse and large Jacobian matrices. It uses the iterative procedure `scipy.sparse.linalg.lsmr` for finding a solution of a linear least-squares problem and only requires matrix-vector product evaluations.\n\nIf None (default), the solver is chosen based on the type of Jacobian returned on the first iteration. tr_options : dict, optional Keyword options passed to trust-region solver.\n\n* ``tr_solver='exact'``: `tr_options` are ignored. * ``tr_solver='lsmr'``: options for `scipy.sparse.linalg.lsmr`. Additionally,\n\n``method='trf'`` supports\n\n'regularize' option (bool, default is True), which adds a regularization term to the normal equation, which improves convergence if the Jacobian is rank-deficient [Byrd]_ (eq. 3.4).\n\njac_sparsity : {None, array_like, sparse matrix}, optional Defines the sparsity structure of the Jacobian matrix for finite difference estimation, its shape must be (m, n). If the Jacobian has only few non-zero elements in *each* row, providing the sparsity structure will greatly speed up the computations [Curtis]_. A zero entry means that a corresponding element in the Jacobian is identically zero. If provided, forces the use of 'lsmr' trust-region solver. If None (default), then dense differencing will be used. Has no effect for 'lm' method. verbose : {0, 1, 2}, optional Level of algorithm's verbosity:\n\n* 0 (default) : work silently. * 1 : display a termination report. * 2 : display progress during iterations (not supported by 'lm' method).\n\nargs, kwargs : tuple and dict, optional Additional arguments passed to `fun` and `jac`. Both empty by default. The calling signature is ``fun(x, *args, **kwargs)`` and the same for `jac`.\n##### Returns\n* **`OptimizeResult` with the following fields defined**: \n\n* **x **: ndarray, shape (n,)\n    Solution found.\n\n* **cost **: float\n    Value of the cost function at the solution.\n\n* **fun **: ndarray, shape (m,)\n    Vector of residuals at the solution.\n\n* **jac **: ndarray, sparse matrix or LinearOperator, shape (m, n)\n    Modified Jacobian matrix at the solution, in the sense that J^T J\n    is a Gauss-Newton approximation of the Hessian of the cost function.\n    The type is the same as the one used by the algorithm.\n\n* **grad **: ndarray, shape (m,)\n    Gradient of the cost function at the solution.\n\n* **optimality **: float\n    First-order optimality measure. In unconstrained problems, it is always\n    the uniform norm of the gradient. In constrained problems, it is the\n    quantity which was compared with `gtol` during iterations.\n\n* **active_mask **: ndarray of int, shape (n,)\n    Each component shows whether a corresponding constraint is active\n    (that is, whether a variable is at the bound)\n\n* **nfev **: int\n    Number of function evaluations done. Methods 'trf' and 'dogbox' do not\n    count function calls for numerical Jacobian approximation, as opposed\n    to 'lm' method.\n\n* **njev **: int or None\n    Number of Jacobian evaluations done. If numerical Jacobian\n    approximation is used in 'lm' method, it is set to None.\n\n* **status **: int\n    The reason for algorithm termination\n\n* **message **: str\n    Verbal description of the termination reason.\n\n* **success **: bool\n    True if one of the convergence criteria is satisfied (`status` > 0).\n\n* **leastsq **: A legacy wrapper for the MINPACK implementation of the\n          Levenberg-Marquadt algorithm.\n\n* **curve_fit **: Least-squares minimization applied to a curve-fitting problem.\n\n* **.. versionadded**: \n\n* **.. [JJMore] J. J. More, \"The Levenberg-Marquardt Algorithm**: Implementation\n            and Theory,\" Numerical Analysis, ed. G. A. Watson, Lecture\n            Notes in Mathematics 630, Springer Verlag, pp. 105-116, 1977.\n\n* **.. [BA] B. Triggs et. al., \"Bundle Adjustment - A Modern Synthesis\",\n        Proceedings of the International Workshop on Vision Algorithms**: Theory and Practice, pp. 298-372, 1999.\n\n* **>>> def fun_rosenbrock(x)**: \n\n* **We also provide the analytic Jacobian**: \n\n* **>>> def jac_rosenbrock(x)**: \n\n* **Putting this all together, we see that the new solution lies on the bound**: \n\n* **variables**: \n\n* **>>> def fun_broyden(x)**: \n\n* **...     f[1**: ] -= x[\n\n* **...     f[**: -1] -= 2 * x[1\n\n* **>>> def sparsity_broyden(n)**: \n\n* **outliers, define the model parameters, and generate data**: \n\n* **>>> def gen_data(t, a, b, c, noise=0, n_outliers=0, random_state=0)**: \n\n* **>>> def fun(x, t, y)**: \n\n* **Compute a standard least-squares solution**: \n\n* **following function**: \n\n* **>>> def f(z)**: \n\n* **by simply handling the real and imaginary parts as independent variables**: \n\n* **>>> def f_wrap(x)**: \n\n* **variables we optimize a 2m-D real function of 2n real variables**: \n\n"
},{
    "source file": "lgmres90.py",
    "line number": "15",
    "func name": "lgmres",
    "func arg": "(A, b, x0, tol, maxiter, M, callback, inner_m, outer_k, outer_v, store_outer_Av, prepend_outer_v, atol)",
    "comments": "Solve a matrix equation using the LGMRES algorithm.\n\nThe LGMRES algorithm [1]_ [2]_ is designed to avoid some problems in the convergence in restarted GMRES, and often converges in fewer iterations.\n\nParameters ---------- A : {sparse matrix, dense matrix, LinearOperator} The real or complex N-by-N matrix of the linear system. Alternatively, ``A`` can be a linear operator which can produce ``Ax`` using, e.g., ``scipy.sparse.linalg.LinearOperator``. b : {array, matrix} Right hand side of the linear system. Has shape (N,) or (N,1). x0\n\n: {array, matrix} Starting guess for the solution. tol, atol : float, optional Tolerances for convergence, ``norm(residual) <= max(tol*norm(b), atol)``. The default for ``atol`` is `tol`.\n\n.. warning::\n\nThe default value for `atol` will be changed in a future release. For future compatibility, specify `atol` explicitly. maxiter : int, optional Maximum number of iterations.\n\nIteration will stop after maxiter steps even if the specified tolerance has not been achieved. M : {sparse matrix, dense matrix, LinearOperator}, optional Preconditioner for A.\n\nThe preconditioner should approximate the inverse of A.\n\nEffective preconditioning dramatically improves the rate of convergence, which implies that fewer iterations are needed to reach a given error tolerance. callback : function, optional User-supplied function to call after each iteration.\n\nIt is called as callback(xk), where xk is the current solution vector. inner_m : int, optional Number of inner GMRES iterations per each outer iteration. outer_k : int, optional Number of vectors to carry between inner GMRES iterations. According to [1]_, good values are in the range of 1...3. However, note that if you want to use the additional vectors to accelerate solving multiple similar problems, larger values may be beneficial. outer_v : list of tuples, optional List containing tuples ``(v, Av)`` of vectors and corresponding matrix-vector products, used to augment the Krylov subspace, and carried between inner GMRES iterations. The element ``Av`` can be `None` if the matrix-vector product should be re-evaluated. This parameter is modified in-place by `lgmres`, and can be used to pass \"guess\" vectors in and out of the algorithm when solving similar problems. store_outer_Av : bool, optional Whether LGMRES should store also A*v in addition to vectors `v` in the `outer_v` list. Default is True. prepend_outer_v : bool, optional Whether to put outer_v augmentation vectors before Krylov iterates. In standard LGMRES, prepend_outer_v=False.\n##### Returns\n* **x **: array or matrix\n    The converged solution.\n\n* **info **: int\n    Provides convergence information\n\n"
},{
    "source file": "lil91.py",
    "line number": "527",
    "func name": "isspmatrix_lil",
    "func arg": "(x)",
    "comments": "Is x of lil_matrix type?\n\nParameters ---------- x object to check for being a lil matrix\n##### Returns\n"
},{
    "source file": "linalg.py",
    "line number": "17",
    "func name": "random",
    "func arg": "(size)",
    "comments": ""
},{
    "source file": "linesearch.py",
    "line number": "823",
    "func name": "_nonmonotone_line_search_cheng",
    "func arg": "(f, x_k, d, f_k, C, Q, eta, gamma, tau_min, tau_max, nu)",
    "comments": "Nonmonotone line search from [1]\n\nParameters ---------- f : callable Function returning a tuple ``(f, F)`` where ``f`` is the value of a merit function and ``F`` the residual. x_k : ndarray Initial position. d : ndarray Search direction. f_k : float Initial merit function value. C, Q : float Control parameters. On the first iteration, give values Q=1.0, C=f_k eta : float Allowed merit function increase, see [1]_ nu, gamma, tau_min, tau_max : float, optional Search parameters, see [1]_\n##### Returns\n* **alpha **: float\n    Step length\n\n* **xp **: ndarray\n    Next position\n\n* **fp **: float\n    Merit function value at next position\n\n* **Fp **: ndarray\n    Residual at next position\n\n* **C **: float\n    New value for the control parameter C\n\n* **Q **: float\n    New value for the control parameter Q\n\n"
},{
    "source file": "linsolve92.py",
    "line number": "491",
    "func name": "spsolve_triangular",
    "func arg": "(A, b, lower, overwrite_A, overwrite_b, unit_diagonal)",
    "comments": "Solve the equation `A x = b` for `x`, assuming A is a triangular matrix.\n\nParameters ---------- A : (M, M) sparse matrix A sparse square triangular matrix. Should be in CSR format. b : (M,) or (M, N) array_like Right-hand side matrix in `A x = b` lower : bool, optional Whether `A` is a lower or upper triangular matrix. Default is lower triangular matrix. overwrite_A : bool, optional Allow changing `A`. The indices of `A` are going to be sorted and zero entries are going to be removed. Enabling gives a performance gain. Default is False. overwrite_b : bool, optional Allow overwriting data in `b`. Enabling gives a performance gain. Default is False. If `overwrite_b` is True, it should be ensured that `b` has an appropriate dtype to be able to store the result. unit_diagonal : bool, optional If True, diagonal elements of `a` are assumed to be 1 and will not be referenced.\n\n.. versionadded:: 1.4.0\n##### Returns\n* **x **: (M,) or (M, N) ndarray\n    Solution to the system `A x = b`. Shape of return matches shape of `b`.\n\n"
},{
    "source file": "lint_diff.py",
    "line number": "76",
    "func name": "main",
    "func arg": "()",
    "comments": ""
},{
    "source file": "lobpcg93.py",
    "line number": "127",
    "func name": "lobpcg",
    "func arg": "(A, X, B, M, Y, tol, maxiter, largest, verbosityLevel, retLambdaHistory, retResidualNormsHistory)",
    "comments": "Locally Optimal Block Preconditioned Conjugate Gradient Method (LOBPCG)\n\nLOBPCG is a preconditioned eigensolver for large symmetric positive definite (SPD) generalized eigenproblems.\n\nParameters ---------- A : {sparse matrix, dense matrix, LinearOperator} The symmetric linear operator of the problem, usually a sparse matrix.\n\nOften called the \"stiffness matrix\". X : ndarray, float32 or float64 Initial approximation to the ``k`` eigenvectors (non-sparse). If `A` has ``shape=(n,n)`` then `X` should have shape ``shape=(n,k)``. B : {dense matrix, sparse matrix, LinearOperator}, optional The right hand side operator in a generalized eigenproblem. By default, ``B = Identity``.\n\nOften called the \"mass matrix\". M : {dense matrix, sparse matrix, LinearOperator}, optional Preconditioner to `A`; by default ``M = Identity``. `M` should approximate the inverse of `A`. Y : ndarray, float32 or float64, optional n-by-sizeY matrix of constraints (non-sparse), sizeY < n The iterations will be performed in the B-orthogonal complement of the column-space of Y. Y must be full rank. tol : scalar, optional Solver tolerance (stopping criterion). The default is ``tol=n*sqrt(eps)``. maxiter : int, optional Maximum number of iterations.\n\nThe default is ``maxiter = 20``. largest : bool, optional When True, solve for the largest eigenvalues, otherwise the smallest. verbosityLevel : int, optional Controls solver output.\n\nThe default is ``verbosityLevel=0``. retLambdaHistory : bool, optional Whether to return eigenvalue history.\n\nDefault is False. retResidualNormsHistory : bool, optional Whether to return history of residual norms.\n\nDefault is False.\n##### Returns\n* **w **: ndarray\n    Array of ``k`` eigenvalues\n\n* **v **: ndarray\n    An array of ``k`` eigenvectors.  `v` has the same shape as `X`.\n\n* **lambdas **: list of ndarray, optional\n    The eigenvalue history, if `retLambdaHistory` is True.\n\n* **rnorms **: list of ndarray, optional\n    The history of residual norms, if `retResidualNormsHistory` is True.\n\n* **https**: //arxiv.org/abs/0705.2626\n\n* **The convergence speed depends basically on two factors**: \n\n* **.. [1] A. V. Knyazev (2001),\n       Toward the Optimal Preconditioned Eigensolver**: Locally Optimal\n       Block Preconditioned Conjugate Gradient Method.\n       SIAM Journal on Scientific Computing 23, no. 2,\n       pp. 517-541. http\n\n* **.. [2] A. V. Knyazev, I. Lashuk, M. E. Argentati, and E. Ovchinnikov\n       (2007), Block Locally Optimal Preconditioned Eigenvalue Xolvers\n       (BLOPEX) in hypre and PETSc. https**: //arxiv.org/abs/0705.2626\n\n* **.. [3] A. V. Knyazev's C and MATLAB implementations**: https\n\n* **Constraints**: \n\n* **Preconditioner in the inverse of A in this example**: \n\n* **The preconditiner must be defined by a function**: \n\n* **>>> def precond( x )**: \n\n* **The preconditioner function is passed to lobpcg as a `LinearOperator`**: \n\n* **Let us now solve the eigenvalue problem for the matrix A**: \n\n"
},{
    "source file": "loggamma.py",
    "line number": "25",
    "func name": "main",
    "func arg": "()",
    "comments": ""
},{
    "source file": "lsmr94.py",
    "line number": "29",
    "func name": "lsmr",
    "func arg": "(A, b, damp, atol, btol, conlim, maxiter, show, x0)",
    "comments": "Iterative solver for least-squares problems.\n\nlsmr solves the system of linear equations ``Ax = b``. If the system is inconsistent, it solves the least-squares problem ``min ||b\n\n- Ax||_2``. A is a rectangular matrix of dimension m-by-n, where all cases are allowed: m = n, m > n, or m < n. B is a vector of length m. The matrix A may be dense or sparse (usually sparse).\n\nParameters ---------- A : {matrix, sparse matrix, ndarray, LinearOperator} Matrix A in the linear system. Alternatively, ``A`` can be a linear operator which can produce ``Ax`` and ``A^H x`` using, e.g., ``scipy.sparse.linalg.LinearOperator``. b : array_like, shape (m,) Vector b in the linear system. damp : float Damping factor for regularized least-squares. `lsmr` solves the regularized least-squares problem::\n\nmin ||(b)\n\n- (\n\nA\n\n )x|| ||(0)\n\n (damp*I) ||_2\n\nwhere damp is a scalar.\n\nIf damp is None or 0, the system is solved without regularization. atol, btol : float, optional Stopping tolerances. `lsmr` continues iterations until a certain backward error estimate is smaller than some quantity depending on atol and btol.\n\nLet ``r = b\n\n- Ax`` be the residual vector for the current approximate solution ``x``. If ``Ax = b`` seems to be consistent, ``lsmr`` terminates when ``norm(r) <= atol * norm(A) * norm(x) + btol * norm(b)``. Otherwise, lsmr terminates when ``norm(A^H r) <= atol * norm(A) * norm(r)``.\n\nIf both tolerances are 1.0e-6 (say), the final ``norm(r)`` should be accurate to about 6 digits. (The final x will usually have fewer correct digits, depending on ``cond(A)`` and the size of LAMBDA.)\n\nIf `atol` or `btol` is None, a default value of 1.0e-6 will be used. Ideally, they should be estimates of the relative error in the entries of A and B respectively.\n\nFor example, if the entries of `A` have 7 correct digits, set atol = 1e-7. This prevents the algorithm from doing unnecessary work beyond the uncertainty of the input data. conlim : float, optional `lsmr` terminates if an estimate of ``cond(A)`` exceeds `conlim`.\n\nFor compatible systems ``Ax = b``, conlim could be as large as 1.0e+12 (say).\n\nFor least-squares problems, `conlim` should be less than 1.0e+8. If `conlim` is None, the default value is 1e+8.\n\nMaximum precision can be obtained by setting ``atol = btol = conlim = 0``, but the number of iterations may then be excessive. maxiter : int, optional `lsmr` terminates if the number of iterations reaches `maxiter`.\n\nThe default is ``maxiter = min(m, n)``.\n\nFor ill-conditioned systems, a larger value of `maxiter` may be needed. show : bool, optional Print iterations logs if ``show=True``. x0 : array_like, shape (n,), optional Initial guess of x, if None zeros are used.\n\n.. versionadded:: 1.0.0\n##### Returns\n* **x **: ndarray of float\n    Least-square solution returned.\n\n* **istop **: int\n    istop gives the reason for stopping\n\n* **itn **: int\n    Number of iterations used.\n\n* **normr **: float\n    ``norm(b-Ax)``\n\n* **normar **: float\n    ``norm(A^H (b - Ax))``\n\n* **norma **: float\n    ``norm(A)``\n\n* **conda **: float\n    Condition number of A.\n\n* **normx **: float\n    ``norm(x)``\n\n* **.. versionadded**: \n\n* **.. [1] D. C.-L. Fong and M. A. Saunders,\n       \"LSMR**: An iterative algorithm for sparse least-squares problems\",\n       SIAM J. Sci. Comput., vol. 33, pp. 2950-2971, 2011.\n       https\n\n* **.. [2] LSMR Software, https**: //web.stanford.edu/group/SOL/software/lsmr/\n\n* **>>> x, istop, itn, normr = lsmr(A, b)[**: 4]\n\n* **The next example has a non-trivial solution**: \n\n* **solution for the equation**: \n\n"
},{
    "source file": "lsq_linear.py",
    "line number": "34",
    "func name": "lsq_linear",
    "func arg": "(A, b, bounds, method, tol, lsq_solver, lsmr_tol, max_iter, verbose)",
    "comments": "Solve a linear least-squares problem with bounds on the variables.\n\nGiven a m-by-n design matrix A and a target vector b with m elements, `lsq_linear` solves the following optimization problem::\n\nminimize 0.5 * ||A x\n\n- b||**2 subject to lb <= x <= ub\n\nThis optimization problem is convex, hence a found minimum (if iterations have converged) is guaranteed to be global.\n\nParameters ---------- A : array_like, sparse matrix of LinearOperator, shape (m, n) Design matrix. Can be `scipy.sparse.linalg.LinearOperator`. b : array_like, shape (m,) Target vector. bounds : 2-tuple of array_like, optional Lower and upper bounds on independent variables. Defaults to no bounds. Each array must have shape (n,) or be a scalar, in the latter case a bound will be the same for all variables. Use ``np.inf`` with an appropriate sign to disable bounds on all or some variables. method : 'trf' or 'bvls', optional Method to perform minimization.\n\n* 'trf' : Trust Region Reflective algorithm adapted for a linear least-squares problem. This is an interior-point-like method and the required number of iterations is weakly correlated with the number of variables. * 'bvls' : Bounded-variable least-squares algorithm. This is an active set method, which requires the number of iterations comparable to the number of variables. Can't be used when `A` is sparse or LinearOperator.\n\nDefault is 'trf'. tol : float, optional Tolerance parameter. The algorithm terminates if a relative change of the cost function is less than `tol` on the last iteration. Additionally, the first-order optimality measure is considered:\n\n* ``method='trf'`` terminates if the uniform norm of the gradient, scaled to account for the presence of the bounds, is less than `tol`. * ``method='bvls'`` terminates if Karush-Kuhn-Tucker conditions are satisfied within `tol` tolerance.\n\nlsq_solver : {None, 'exact', 'lsmr'}, optional Method of solving unbounded least-squares problems throughout iterations:\n\n* 'exact' : Use dense QR or SVD decomposition approach. Can't be used when `A` is sparse or LinearOperator. * 'lsmr' : Use `scipy.sparse.linalg.lsmr` iterative procedure which requires only matrix-vector product evaluations. Can't be used with ``method='bvls'``.\n\nIf None (default), the solver is chosen based on type of `A`. lsmr_tol : None, float or 'auto', optional Tolerance parameters 'atol' and 'btol' for `scipy.sparse.linalg.lsmr` If None (default), it is set to ``1e-2 * tol``. If 'auto', the tolerance will be adjusted based on the optimality of the current iterate, which can speed up the optimization process, but is not always reliable. max_iter : None or int, optional Maximum number of iterations before termination. If None (default), it is set to 100 for ``method='trf'`` or to the number of variables for ``method='bvls'`` (not counting iterations for 'bvls' initialization). verbose : {0, 1, 2}, optional Level of algorithm's verbosity:\n\n* 0 : work silently (default). * 1 : display a termination report. * 2 : display progress during iterations.\n##### Returns\n* **OptimizeResult with the following fields defined**: \n\n* **x **: ndarray, shape (n,)\n    Solution found.\n\n* **cost **: float\n    Value of the cost function at the solution.\n\n* **fun **: ndarray, shape (m,)\n    Vector of residuals at the solution.\n\n* **optimality **: float\n    First-order optimality measure. The exact meaning depends on `method`,\n    refer to the description of `tol` parameter.\n\n* **active_mask **: ndarray of int, shape (n,)\n    Each component shows whether a corresponding constraint is active\n    (that is, whether a variable is at the bound)\n\n* **nit **: int\n    Number of iterations. Zero if the unconstrained solution is optimal.\n\n* **status **: int\n    Reason for algorithm termination\n\n* **message **: str\n    Verbal description of the termination reason.\n\n* **success **: bool\n    True if one of the convergence criteria is satisfied (`status` > 0).\n\n* **nnls **: Linear least squares with non-negativity constraint.\n\n* **least_squares **: Nonlinear least squares with bounds on the variables.\n\n* **.. [BVLS] P. B. Start and R. L. Parker, \"Bounded-Variable Least-Squares**: an Algorithm and Applications\", Computational Statistics, 10,\n          129-141, 1995.\n\n"
},{
    "source file": "lsq_problems.py",
    "line number": "467",
    "func name": "extract_lsq_problems",
    "func arg": "()",
    "comments": "Extract all least squares problems in this file for benchmarking.\n\n\n##### Returns\n"
},{
    "source file": "lsqr95.py",
    "line number": "96",
    "func name": "lsqr",
    "func arg": "(A, b, damp, atol, btol, conlim, iter_lim, show, calc_var, x0)",
    "comments": "Find the least-squares solution to a large, sparse, linear system of equations.\n\nThe function solves ``Ax = b``\n\nor\n\n``min ||Ax\n\n- b||^2`` or ``min ||Ax\n\n- b||^2 + d^2 ||x||^2``.\n\nThe matrix A may be square or rectangular (over-determined or under-determined), and may have any rank.\n\n::\n\n1. Unsymmetric equations --\n\n\n\nsolve\n\nA*x = b\n\n2. Linear least squares\n\n--\n\n\n\nsolve\n\nA*x = b in the least-squares sense\n\n3. Damped least squares\n\n--\n\n\n\nsolve\n\n(\n\n A\n\n\n\n)*x = ( b ) ( damp*I )\n\n\n\n ( 0 ) in the least-squares sense\n\nParameters ---------- A : {sparse matrix, ndarray, LinearOperator} Representation of an m-by-n matrix. Alternatively, ``A`` can be a linear operator which can produce ``Ax`` and ``A^T x`` using, e.g., ``scipy.sparse.linalg.LinearOperator``. b : array_like, shape (m,) Right-hand side vector ``b``. damp : float Damping coefficient. atol, btol : float, optional Stopping tolerances. If both are 1.0e-9 (say), the final residual norm should be accurate to about 9 digits.\n\n(The final x will usually have fewer correct digits, depending on cond(A) and the size of damp.) conlim : float, optional Another stopping tolerance.\n\nlsqr terminates if an estimate of ``cond(A)`` exceeds `conlim`.\n\nFor compatible systems ``Ax = b``, `conlim` could be as large as 1.0e+12 (say).\n\nFor least-squares problems, conlim should be less than 1.0e+8. Maximum precision can be obtained by setting ``atol = btol = conlim = zero``, but the number of iterations may then be excessive. iter_lim : int, optional Explicit limitation on number of iterations (for safety). show : bool, optional Display an iteration log. calc_var : bool, optional Whether to estimate diagonals of ``(A'A + damp^2*I)^{-1}``. x0 : array_like, shape (n,), optional Initial guess of x, if None zeros are used.\n\n.. versionadded:: 1.0.0\n##### Returns\n* **x **: ndarray of float\n    The final solution.\n\n* **istop **: int\n    Gives the reason for termination.\n    1 means x is an approximate solution to Ax = b.\n    2 means x approximately solves the least-squares problem.\n\n* **itn **: int\n    Iteration number upon termination.\n\n* **r1norm **: float\n    ``norm(r)``, where ``r = b - Ax``.\n\n* **r2norm **: float\n    ``sqrt( norm(r)^2  +  damp^2 * norm(x)^2 )``.  Equal to `r1norm` if\n    ``damp == 0``.\n\n* **anorm **: float\n    Estimate of Frobenius norm of ``Abar = [[A]; [damp*I]]``.\n\n* **acond **: float\n    Estimate of ``cond(Abar)``.\n\n* **arnorm **: float\n    Estimate of ``norm(A'*r - damp^2*x)``.\n\n* **xnorm **: float\n    ``norm(x)``\n\n* **var **: ndarray of float\n    If ``calc_var`` is True, estimates all diagonals of\n    ``(A'A)^{-1}`` (if ``damp == 0``) or more generally ``(A'A +\n    damp^2*I)^{-1}``.  This is well defined if A has full column\n    rank or ``damp > 0``.  (Not sure what var means if ``rank(A)\n    < n`` and ``damp = 0.``)\n\n* **one could proceed as follows**: 1. Compute a residual vector ``r0 = b - A*x0``.\n  2. Use LSQR to solve the system  ``A*dx = r0``.\n  3. Add the correction dx to obtain a final solution ``x = x0 + dx``.\n\n* **.. [1] C. C. Paige and M. A. Saunders (1982a).\n       \"LSQR**: An algorithm for sparse linear equations and\n       sparse least squares\", ACM TOMS 8(1), 43-71.\n\n* **.. [2] C. C. Paige and M. A. Saunders (1982b).\n       \"Algorithm 583.  LSQR**: Sparse linear equations and least\n       squares problems\", ACM TOMS 8(2), 195-209.\n\n* **>>> x, istop, itn, normr = lsqr(A, b)[**: 4]\n\n* **The next example has a non-trivial solution**: \n\n* **>>> x, istop, itn, r1norm = lsqr(A, b)[**: 4]\n\n* **solution for the equation**: \n\n"
},{
    "source file": "lti_conversion96.py",
    "line number": "335",
    "func name": "cont2discrete",
    "func arg": "(system, dt, method, alpha)",
    "comments": "Transform a continuous to a discrete state-space system.\n\nParameters ---------- system : a tuple describing the system or an instance of `lti` The following gives the number of elements in the tuple and the interpretation:\n\n* 1: (instance of `lti`) * 2: (num, den) * 3: (zeros, poles, gain) * 4: (A, B, C, D)\n\ndt : float The discretization time step. method : str, optional Which method to use:\n\n* gbt: generalized bilinear transformation * bilinear: Tustin's approximation (\"gbt\" with alpha=0.5) * euler: Euler (or forward differencing) method (\"gbt\" with alpha=0) * backward_diff: Backwards differencing (\"gbt\" with alpha=1.0) * zoh: zero-order hold (default) * foh: first-order hold (*versionadded: 1.3.0*) * impulse: equivalent impulse response (*versionadded: 1.3.0*)\n\nalpha : float within [0, 1], optional The generalized bilinear transformation weighting parameter, which should only be specified with method=\"gbt\", and is ignored otherwise\n##### Returns\n* **sysd **: tuple containing the discrete system\n    Based on the input type, the output will be of the form\n    * (num, den, dt)   for transfer function input\n    * (zeros, poles, gain, dt)   for zeros-poles-gain input\n    * (A, B, C, D, dt) for state-space system input\n\n* **.. [1] https**: //en.wikipedia.org/wiki/Discretization#Discretization_of_linear_state_space_models\n\n* **.. [2] http**: //techteach.no/publications/discretetime_signals_systems/discrete.pdf\n\n* **.. [3] G. Zhang, X. Chen, and T. Chen, Digital redesign via the generalized\n    bilinear transformation, Int. J. Control, vol. 82, no. 4, pp. 741-754,\n    2009.\n    (https**: //www.mypolyuweb.hk/~magzhang/Research/ZCC09_IJC.pdf)\n\n* **.. [4] G. F. Franklin, J. D. Powell, and M. L. Workman, Digital control\n    of dynamic systems, 3rd ed. Menlo Park, Calif**: Addison-Wesley,\n    pp. 204-206, 1998.\n\n"
},{
    "source file": "ltisys97.py",
    "line number": "3771",
    "func name": "dbode",
    "func arg": "(system, w, n)",
    "comments": "Calculate Bode magnitude and phase data of a discrete-time system.\n\nParameters ---------- system : an instance of the LTI class or a tuple describing the system. The following gives the number of elements in the tuple and the interpretation:\n\n* 1 (instance of `dlti`) * 2 (num, den, dt) * 3 (zeros, poles, gain, dt) * 4 (A, B, C, D, dt)\n\nw : array_like, optional Array of frequencies (in radians/sample). Magnitude and phase data is calculated for every value in this array. If not given a reasonable set will be calculated. n : int, optional Number of frequency points to compute if `w` is not given. The `n` frequencies are logarithmically spaced in an interval chosen to include the influence of the poles and zeros of the system.\n##### Returns\n* **w **: 1D ndarray\n    Frequency array [rad/time_unit]\n\n* **mag **: 1D ndarray\n    Magnitude array [dB]\n\n* **phase **: 1D ndarray\n    Phase array [deg]\n\n* **.. versionadded**: \n\n* **Transfer function**: H(z) = 1 / (z^2 + 2z + 3)\n\n* **Equivalent**: sys.bode()\n\n"
},{
    "source file": "makenpz98.py",
    "line number": "15",
    "func name": "main",
    "func arg": "()",
    "comments": ""
},{
    "source file": "matfuncs.py",
    "line number": "672",
    "func name": "khatri_rao",
    "func arg": "(a, b)",
    "comments": "Khatri-rao product\n\nA column-wise Kronecker product of two matrices\n\nParameters ---------- a:\n\n(n, k) array_like Input array b:\n\n(m, k) array_like Input array\n##### Returns\n* **c**: (n*m, k) ndarray\n    Khatri-rao product of `a` and `b`.\n\n* **The mathematical definition of the Khatri-Rao product is**: \n\n* **.. math**: \n\n* **which is the Kronecker product of every column of A and B, e.g.**: \n\n* **kron **: Kronecker product\n\n"
},{
    "source file": "matfuncs99.py",
    "line number": "821",
    "func name": "_ell",
    "func arg": "(A, m)",
    "comments": "A helper function for expm_2009.\n\nParameters ---------- A : linear operator A linear operator whose norm of power we care about. m : int The power of the linear operator\n##### Returns\n* **value **: int\n    A value related to a bound.\n\n"
},{
    "source file": "measurements.py",
    "line number": "1471",
    "func name": "watershed_ift",
    "func arg": "(input, markers, structure, output)",
    "comments": "Apply watershed from markers using image foresting transform algorithm.\n\nParameters ---------- input : array_like Input. markers : array_like Markers are points within each watershed that form the beginning of the process. Negative markers are considered background markers which are processed after the other markers. structure : structure element, optional A structuring element defining the connectivity of the object can be provided. If None, an element is generated with a squared connectivity equal to one. output : ndarray, optional An output array can optionally be provided. The same shape as input.\n##### Returns\n* **watershed_ift **: ndarray\n    Output.  Same shape as `input`.\n\n* **.. [1] A.X. Falcao, J. Stolfi and R. de Alencar Lotufo, \"The image\n       foresting transform**: theory, algorithms, and applications\",\n       Pattern Analysis and Machine Intelligence, vol. 26, pp. 19-29, 2004.\n\n"
},{
    "source file": "mgc_plot1.py",
    "line number": "5",
    "func name": "mgc_plot",
    "func arg": "(x, y, sim_name)",
    "comments": "Plot sim and MGC-plot\n\n\n"
},{
    "source file": "mgc_plot2.py",
    "line number": "6",
    "func name": "mgc_plot",
    "func arg": "(x, y, mgc_dict)",
    "comments": "Plot sim and MGC-plot\n\n\n"
},{
    "source file": "mgc_plot3.py",
    "line number": "5",
    "func name": "mgc_plot",
    "func arg": "(x, y, sim_name)",
    "comments": "Plot sim and MGC-plot\n\n\n"
},{
    "source file": "mgc_plot4.py",
    "line number": "6",
    "func name": "mgc_plot",
    "func arg": "(x, y, mgc_dict)",
    "comments": "Plot sim and MGC-plot\n\n\n"
},{
    "source file": "minimize_trustregion_constr.py",
    "line number": "114",
    "func name": "_minimize_trustregion_constr",
    "func arg": "(fun, x0, args, grad, hess, hessp, bounds, constraints, xtol, gtol, barrier_tol, sparse_jacobian, callback, maxiter, verbose, finite_diff_rel_step, initial_constr_penalty, initial_tr_radius, initial_barrier_parameter, initial_barrier_tolerance, factorization_method, disp)",
    "comments": "Minimize a scalar function subject to constraints.\n\nParameters ---------- gtol : float, optional Tolerance for termination by the norm of the Lagrangian gradient. The algorithm will terminate when both the infinity norm (i.e., max abs value) of the Lagrangian gradient and the constraint violation are smaller than ``gtol``. Default is 1e-8. xtol : float, optional Tolerance for termination by the change of the independent variable. The algorithm will terminate when ``tr_radius < xtol``, where ``tr_radius`` is the radius of the trust region used in the algorithm. Default is 1e-8. barrier_tol : float, optional Threshold on the barrier parameter for the algorithm termination. When inequality constraints are present, the algorithm will terminate only when the barrier parameter is less than `barrier_tol`. Default is 1e-8. sparse_jacobian : {bool, None}, optional Determines how to represent Jacobians of the constraints. If bool, then Jacobians of all the constraints will be converted to the corresponding format. If None (default), then Jacobians won't be converted, but the algorithm can proceed only if they all have the same format. initial_tr_radius: float, optional Initial trust radius. The trust radius gives the maximum distance between solution points in consecutive iterations. It reflects the trust the algorithm puts in the local approximation of the optimization problem. For an accurate local approximation the trust-region should be large and for an\n\napproximation valid only close to the current point it should be a small one. The trust radius is automatically updated throughout the optimization process, with ``initial_tr_radius`` being its initial value. Default is 1 (recommended in [1]_, p. 19). initial_constr_penalty : float, optional Initial constraints penalty parameter. The penalty parameter is used for balancing the requirements of decreasing the objective function and satisfying the constraints. It is used for defining the merit function: ``merit_function(x) = fun(x) + constr_penalty * constr_norm_l2(x)``, where ``constr_norm_l2(x)`` is the l2 norm of a vector containing all the constraints. The merit function is used for accepting or rejecting trial points and ``constr_penalty`` weights the two conflicting goals of reducing objective function and constraints. The penalty is automatically updated throughout the optimization\n\nprocess, with ``initial_constr_penalty`` being its\n\ninitial value. Default is 1 (recommended in [1]_, p 19). initial_barrier_parameter, initial_barrier_tolerance: float, optional Initial barrier parameter and initial tolerance for the barrier subproblem. Both are used only when inequality constraints are present. For dealing with optimization problems ``min_x f(x)`` subject to inequality constraints ``c(x) <= 0`` the algorithm introduces slack variables, solving the problem ``min_(x,s) f(x) + barrier_parameter*sum(ln(s))`` subject to the equality constraints\n\n``c(x) + s = 0`` instead of the original problem. This subproblem is solved for decreasing values of ``barrier_parameter`` and with decreasing tolerances for the termination, starting with ``initial_barrier_parameter`` for the barrier parameter and ``initial_barrier_tolerance`` for the barrier tolerance. Default is 0.1 for both values (recommended in [1]_ p. 19). Also note that ``barrier_parameter`` and ``barrier_tolerance`` are updated with the same prefactor. factorization_method : string or None, optional Method to factorize the Jacobian of the constraints. Use None (default) for the auto selection or one of:\n\n- 'NormalEquation' (requires scikit-sparse)\n\n- 'AugmentedSystem'\n\n- 'QRFactorization'\n\n- 'SVDFactorization'\n\nThe methods 'NormalEquation' and 'AugmentedSystem' can be used only with sparse constraints. The projections required by the algorithm will be computed using, respectively, the the normal equation\n\nand the augmented system approaches explained in [1]_. 'NormalEquation' computes the Cholesky factorization of ``A A.T`` and 'AugmentedSystem' performs the LU factorization of an augmented system. They usually provide similar results. 'AugmentedSystem' is used by default for sparse matrices.\n\nThe methods 'QRFactorization' and 'SVDFactorization' can be used only with dense constraints. They compute the required projections using, respectively, QR and SVD factorizations. The 'SVDFactorization' method can cope with Jacobian matrices with deficient row rank and will be used whenever other factorization methods fail (which may imply the conversion of sparse matrices to a dense format when required). By default, 'QRFactorization' is used for dense matrices. finite_diff_rel_step : None or array_like, optional Relative step size for the finite difference approximation. maxiter : int, optional Maximum number of algorithm iterations. Default is 1000. verbose : {0, 1, 2}, optional Level of algorithm's verbosity:\n\n* 0 (default) : work silently. * 1 : display a termination report. * 2 : display progress during iterations. * 3 : display progress during iterations (more complete report).\n\ndisp : bool, optional If True (default), then `verbose` will be set to 1 if it was 0.\n##### Returns\n* **`OptimizeResult` with the fields documented below. Note the following**: 1. All values corresponding to the constraints are ordered as they\n       were passed to the solver. And values corresponding to `bounds`\n       constraints are put *after* other constraints.\n    2. All numbers of function, Jacobian or Hessian evaluations correspond\n       to numbers of actual Python function calls. It means, for example,\n       that if a Jacobian is estimated by finite differences, then the\n       number of Jacobian evaluations will be zero and the number of\n       function evaluations will be incremented by all calls during the\n       finite difference estimation.\n\n* **x **: ndarray, shape (n,)\n    Solution found.\n\n* **optimality **: float\n    Infinity norm of the Lagrangian gradient at the solution.\n\n* **constr_violation **: float\n    Maximum constraint violation at the solution.\n\n* **fun **: float\n    Objective function at the solution.\n\n* **grad **: ndarray, shape (n,)\n    Gradient of the objective function at the solution.\n\n* **lagrangian_grad **: ndarray, shape (n,)\n    Gradient of the Lagrangian function at the solution.\n\n* **nit **: int\n    Total number of iterations.\n\n* **nfev **: integer\n    Number of the objective function evaluations.\n\n* **njev **: integer\n    Number of the objective function gradient evaluations.\n\n* **nhev **: integer\n    Number of the objective function Hessian evaluations.\n\n* **cg_niter **: int\n    Total number of the conjugate gradient method iterations.\n\n* **method **: {'equality_constrained_sqp', 'tr_interior_point'}\n    Optimization method used.\n\n* **constr **: list of ndarray\n    List of constraint values at the solution.\n\n* **jac **: list of {ndarray, sparse matrix}\n    List of the Jacobian matrices of the constraints at the solution.\n\n* **v **: list of ndarray\n    List of the Lagrange multipliers for the constraints at the solution.\n    For an inequality constraint a positive multiplier means that the upper\n    bound is active, a negative multiplier means that the lower bound is\n    active and if a multiplier is zero it means the constraint is not\n    active.\n\n* **constr_nfev **: list of int\n    Number of constraint evaluations for each of the constraints.\n\n* **constr_njev **: list of int\n    Number of Jacobian matrix evaluations for each of the constraints.\n\n* **constr_nhev **: list of int\n    Number of Hessian evaluations for each of the constraints.\n\n* **tr_radius **: float\n    Radius of the trust region at the last iteration.\n\n* **constr_penalty **: float\n    Penalty parameter at the last iteration, see `initial_constr_penalty`.\n\n* **barrier_tolerance **: float\n    Tolerance for the barrier subproblem at the last iteration.\n    Only for problems with inequality constraints.\n\n* **barrier_parameter **: float\n    Barrier parameter at the last iteration. Only for problems\n    with inequality constraints.\n\n* **execution_time **: float\n    Total execution time.\n\n* **message **: str\n    Termination message.\n\n* **status **: {0, 1, 2, 3}\n    Termination status\n\n* **cg_stop_cond **: int\n    Reason for CG subproblem termination at the last iteration\n\n"
},{
    "source file": "minpack.py",
    "line number": "894",
    "func name": "fixed_point",
    "func arg": "(func, x0, args, xtol, maxiter, method)",
    "comments": "Find a fixed point of the function.\n\nGiven a function of one or more variables and a starting point, find a fixed point of the function: i.e., where ``func(x0) == x0``.\n\nParameters ---------- func : function Function to evaluate. x0 : array_like Fixed point of function. args : tuple, optional Extra arguments to `func`. xtol : float, optional Convergence tolerance, defaults to 1e-08. maxiter : int, optional Maximum number of iterations, defaults to 500. method : {\"del2\", \"iteration\"}, optional Method of finding the fixed-point, defaults to \"del2\", which uses Steffensen's Method with Aitken's ``Del^2`` convergence acceleration [1]_. The \"iteration\" method simply iterates the function until convergence is detected, without attempting to accelerate the convergence.\n\nReferences ---------- .. [1] Burden, Faires, \"Numerical Analysis\", 5th edition, pg. 80\n\nExamples -------- >>> from scipy import optimize >>> def func(x, c1, c2): ...\n\n\n\nreturn np.sqrt(c1/(x+c2)) >>> c1 = np.array([10,12.]) >>> c2 = np.array([3, 5.]) >>> optimize.fixed_point(func, [1.2, 1.3], args=(c1,c2)) array([ 1.4920333 ,\n\n1.37228132])\n"
},{
    "source file": "minres100.py",
    "line number": "9",
    "func name": "minres",
    "func arg": "(A, b, x0, shift, tol, maxiter, M, callback, show, check)",
    "comments": "Use MINimum RESidual iteration to solve Ax=b\n\nMINRES minimizes norm(A*x\n\n- b) for a real symmetric matrix A.\n\nUnlike the Conjugate Gradient method, A can be indefinite or singular.\n\nIf shift != 0 then the method solves (A\n\n- shift*I)x = b\n\nParameters ---------- A : {sparse matrix, dense matrix, LinearOperator} The real symmetric N-by-N matrix of the linear system Alternatively, ``A`` can be a linear operator which can produce ``Ax`` using, e.g., ``scipy.sparse.linalg.LinearOperator``. b : {array, matrix} Right hand side of the linear system. Has shape (N,) or (N,1).\n##### Returns\n* **x **: {array, matrix}\n    The converged solution.\n\n* **info **: integer\n    Provides convergence information\n\n* **x0  **: {array, matrix}\n    Starting guess for the solution.\n\n* **tol **: float\n    Tolerance to achieve. The algorithm terminates when the relative\n    residual is below `tol`.\n\n* **maxiter **: integer\n    Maximum number of iterations.  Iteration will stop after maxiter\n    steps even if the specified tolerance has not been achieved.\n\n* **M **: {sparse matrix, dense matrix, LinearOperator}\n    Preconditioner for A.  The preconditioner should approximate the\n    inverse of A.  Effective preconditioning dramatically improves the\n    rate of convergence, which implies that fewer iterations are needed\n    to reach a given error tolerance.\n\n* **callback **: function\n    User-supplied function to call after each iteration.  It is called\n    as callback(xk), where xk is the current solution vector.\n\n* **Solution of sparse indefinite systems of linear equations,\n    C. C. Paige and M. A. Saunders (1975),\n    SIAM J. Numer. Anal. 12(4), pp. 617-629.\n    https**: //web.stanford.edu/group/SOL/software/minres/\n\n* **This file is a translation of the following MATLAB implementation**: https\n\n"
},{
    "source file": "mio.py",
    "line number": "302",
    "func name": "whosmat",
    "func arg": "(file_name, appendmat, **kwargs)",
    "comments": "List variables inside a MATLAB file.\n\nParameters ---------- %(file_arg)s %(append_arg)s %(load_args)s %(struct_arg)s\n##### Returns\n* **variables **: list of tuples\n    A list of tuples, where each tuple holds the matrix name (a string),\n    its shape (tuple of ints), and its data class (a string).\n    Possible data classes are\n\n* **.. versionadded**: \n\n"
},{
    "source file": "mio4.py",
    "line number": "421",
    "func name": "arr_to_2d",
    "func arg": "(arr, oned_as)",
    "comments": "Make ``arr`` exactly two dimensional\n\nIf `arr` has more than 2 dimensions, raise a ValueError\n\nParameters ---------- arr : array oned_as : {'row', 'column'}, optional Whether to reshape 1-D vectors as row vectors or column vectors. See documentation for ``matdims`` for more detail\n##### Returns\n* **arr2d **: array\n   2-D version of the array\n\n"
},{
    "source file": "mio5_params.py",
    "line number": "169",
    "func name": "_convert_codecs",
    "func arg": "(template, byte_order)",
    "comments": "Convert codec template mapping to byte order\n\nSet codecs not on this system to None\n\nParameters ---------- template : mapping key, value are respectively codec name, and root name for codec (without byte order suffix) byte_order : {'<', '>'} code for little or big endian\n##### Returns\n* **codecs **: dict\n   key, value are name, codec (as in .encode(codec))\n\n"
},{
    "source file": "mio5.py",
    "line number": "451",
    "func name": "to_writeable",
    "func arg": "(source)",
    "comments": "Convert input object ``source`` to something we can write\n\nParameters ---------- source : object\n##### Returns\n* **arr **: None or ndarray or EmptyStructMarker\n    If `source` cannot be converted to something we can write to a matfile,\n    return None.  If `source` is equivalent to an empty dictionary, return\n    ``EmptyStructMarker``.  Otherwise return `source` converted to an\n    ndarray with contents for writing to matfile.\n\n"
},{
    "source file": "miobase.py",
    "line number": "395",
    "func name": "arr_to_chars",
    "func arg": "(arr)",
    "comments": "Convert string array to char array\n\n\n"
},{
    "source file": "misc.py",
    "line number": "182",
    "func name": "_datacopied",
    "func arg": "(arr, original)",
    "comments": "Strict check for `arr` not sharing any data with `original`, under the assumption that arr = asarray(original)\n\n\n"
},{
    "source file": "mmio.py",
    "line number": "811",
    "func name": "_is_fromfile_compatible",
    "func arg": "(stream)",
    "comments": "Check whether `stream` is compatible with numpy.fromfile.\n\nPassing a gzipped file object to ``fromfile/fromstring`` doesn't work with Python 3.\n"
},{
    "source file": "mock_backend101.py",
    "line number": "53",
    "func name": "__ua_function__",
    "func arg": "(method, args, kwargs)",
    "comments": ""
},{
    "source file": "models.py",
    "line number": "243",
    "func name": "_quad_est",
    "func arg": "(data)",
    "comments": ""
},{
    "source file": "morestats102.py",
    "line number": "3457",
    "func name": "circstd",
    "func arg": "(samples, high, low, axis, nan_policy)",
    "comments": "Compute the circular standard deviation for samples assumed to be in the range [low to high].\n\nParameters ---------- samples : array_like Input array. high : float or int, optional High boundary for circular standard deviation range. Default is ``2*pi``. low : float or int, optional Low boundary for circular standard deviation range.\n\nDefault is 0. axis : int, optional Axis along which standard deviations are computed.\n\nThe default is to compute the standard deviation of the flattened array. nan_policy : {'propagate', 'raise', 'omit'}, optional Defines how to handle when input contains nan. 'propagate' returns nan, 'raise' throws an error, 'omit' performs the calculations ignoring nan values. Default is 'propagate'.\n##### Returns\n* **circstd **: float\n    Circular standard deviation.\n\n"
},{
    "source file": "morphology.py",
    "line number": "2071",
    "func name": "distance_transform_edt",
    "func arg": "(input, sampling, return_distances, return_indices, distances, indices)",
    "comments": "Exact Euclidean distance transform.\n\nIn addition to the distance transform, the feature transform can be calculated. In this case the index of the closest background element is returned along the first axis of the result.\n\nParameters ---------- input : array_like Input data to transform. Can be any type but will be converted into binary: 1 wherever input equates to True, 0 elsewhere. sampling : float or int, or sequence of same, optional Spacing of elements along each dimension. If a sequence, must be of length equal to the input rank; if a single number, this is used for all axes. If not specified, a grid spacing of unity is implied. return_distances : bool, optional Whether to return distance matrix. At least one of return_distances/return_indices must be True. Default is True. return_indices : bool, optional Whether to return indices matrix. Default is False. distances : ndarray, optional Used for output of distance array, must be of type float64. indices : ndarray, optional Used for output of indices, must be of type int32.\n##### Returns\n* **distance_transform_edt **: ndarray or list of ndarrays\n    Either distance matrix, index matrix, or a list of the two,\n    depending on `return_x` flags and `distance` and `indices`\n    input parameters.\n\n* **distance**: \n\n* **With a sampling of 2 units along x, 1 along y**: \n\n* **Asking for indices as well**: \n\n* **With arrays provided for inplace outputs**: \n\n"
},{
    "source file": "mpsig103.py",
    "line number": "101",
    "func name": "zpkfreqz",
    "func arg": "(z, p, k, worN)",
    "comments": "Frequency response of a filter in zpk format, using mpmath.\n\nThis is the same calculation as scipy.signal.freqz, but the input is in zpk format, the calculation is performed using mpath, and the results are returned in lists instead of NumPy arrays.\n"
},{
    "source file": "mstats_basic104.py",
    "line number": "2973",
    "func name": "brunnermunzel",
    "func arg": "(x, y, alternative, distribution)",
    "comments": "Computes the Brunner-Munzel test on samples x and y\n\nMissing values in `x` and/or `y` are discarded.\n\nParameters ---------- x, y : array_like Array of samples, should be one-dimensional. alternative :\n\n'less', 'two-sided', or 'greater', optional Whether to get the p-value for the one-sided hypothesis ('less' or 'greater') or for the two-sided hypothesis ('two-sided'). Defaults value is 'two-sided' . distribution: 't' or 'normal', optional Whether to get the p-value by t-distribution or by standard normal distribution. Defaults value is 't' .\n##### Returns\n* **statistic **: float\n    The Brunner-Munzer W statistic.\n\n* **pvalue **: float\n    p-value assuming an t distribution. One-sided or\n    two-sided, depending on the choice of `alternative` and `distribution`.\n\n* **mannwhitneyu **: Mann-Whitney rank test on two samples.\n\n"
},{
    "source file": "mstats_extras105.py",
    "line number": "444",
    "func name": "rsh",
    "func arg": "(data, points)",
    "comments": "Evaluates Rosenblatt's shifted histogram estimators for each data point.\n\nRosenblatt's estimator is a centered finite-difference approximation to the derivative of the empirical cumulative distribution function.\n\nParameters ---------- data : sequence Input data, should be 1-D. Masked values are ignored. points : sequence or None, optional Sequence of points where to evaluate Rosenblatt shifted histogram. If None, use the data.\n"
},{
    "source file": "ndgriddata107.py",
    "line number": "86",
    "func name": "griddata",
    "func arg": "(points, values, xi, method, fill_value, rescale)",
    "comments": "Interpolate unstructured D-D data.\n\nParameters ---------- points : 2-D ndarray of floats with shape (n, D), or length D tuple of 1-D ndarrays with shape (n,). Data point coordinates. values : ndarray of float or complex, shape (n,) Data values. xi : 2-D ndarray of floats with shape (m, D), or length D tuple of ndarrays broadcastable to the same shape. Points at which to interpolate data. method : {'linear', 'nearest', 'cubic'}, optional Method of interpolation. One of\n\n``nearest`` return the value at the data point closest to the point of interpolation. See `NearestNDInterpolator` for more details.\n\n``linear`` tessellate the input point set to N-D simplices, and interpolate linearly on each simplex. See `LinearNDInterpolator` for more details.\n\n``cubic`` (1-D) return the value determined from a cubic spline.\n\n``cubic`` (2-D) return the value determined from a piecewise cubic, continuously differentiable (C1), and approximately curvature-minimizing polynomial surface. See `CloughTocher2DInterpolator` for more details. fill_value : float, optional Value used to fill in for requested points outside of the convex hull of the input points. If not provided, then the default is ``nan``. This option has no effect for the 'nearest' method. rescale : bool, optional Rescale points to unit cube before performing interpolation. This is useful if some of the input dimensions have incommensurable units and differ by many orders of magnitude.\n\n.. versionadded:: 0.14.0\n##### Returns\n* **.. versionadded**: \n\n* **>>> def func(x, y)**: \n\n* **>>> grid_x, grid_y = np.mgrid[0**: 1\n\n* **but we only know its values at 1000 data points**: \n\n* **>>> values = func(points[**: ,0], points[\n\n* **interpolation methods**: \n\n* **cubic interpolant gives the best results**: \n\n* **>>> plt.plot(points[**: ,0], points[\n\n"
},{
    "source file": "newton_krylov_preconditioning.py",
    "line number": "80",
    "func name": "main",
    "func arg": "()",
    "comments": ""
},{
    "source file": "nonlin.py",
    "line number": "1534",
    "func name": "_nonlin_wrapper",
    "func arg": "(name, jac)",
    "comments": "Construct a solver wrapper with given name and Jacobian approx.\n\nIt inspects the keyword arguments of ``jac.__init__``, and allows to use the same arguments in the wrapper function, in addition to the keyword arguments of `nonlin_solve`\n"
},{
    "source file": "odepack.py",
    "line number": "28",
    "func name": "odeint",
    "func arg": "(func, y0, t, args, Dfun, col_deriv, full_output, ml, mu, rtol, atol, tcrit, h0, hmax, hmin, ixpr, mxstep, mxhnil, mxordn, mxords, printmessg, tfirst)",
    "comments": "Integrate a system of ordinary differential equations.\n\n.. note:: For new code, use `scipy.integrate.solve_ivp` to solve a differential equation.\n\nSolve a system of ordinary differential equations using lsoda from the FORTRAN library odepack.\n\nSolves the initial value problem for stiff or non-stiff systems of first order ode-s::\n\ndy/dt = func(y, t, ...)\n\n[or func(t, y, ...)]\n\nwhere y can be a vector.\n\n.. note:: By default, the required order of the first two arguments of `func` are in the opposite order of the arguments in the system definition function used by the `scipy.integrate.ode` class and the function `scipy.integrate.solve_ivp`. To use a function with the signature ``func(t, y, ...)``, the argument `tfirst` must be set to ``True``.\n\nParameters ---------- func : callable(y, t, ...) or callable(t, y, ...) Computes the derivative of y at t. If the signature is ``callable(t, y, ...)``, then the argument `tfirst` must be set ``True``. y0 : array Initial condition on y (can be a vector). t : array A sequence of time points for which to solve for y. The initial value point should be the first element of this sequence. This sequence must be monotonically increasing or monotonically decreasing; repeated values are allowed. args : tuple, optional Extra arguments to pass to function. Dfun : callable(y, t, ...) or callable(t, y, ...) Gradient (Jacobian) of `func`. If the signature is ``callable(t, y, ...)``, then the argument `tfirst` must be set ``True``. col_deriv : bool, optional True if `Dfun` defines derivatives down columns (faster), otherwise `Dfun` should define derivatives across rows. full_output : bool, optional True if to return a dictionary of optional outputs as the second output printmessg : bool, optional Whether to print the convergence message tfirst: bool, optional If True, the first two arguments of `func` (and `Dfun`, if given) must ``t, y`` instead of the default ``y, t``.\n\n.. versionadded:: 1.1.0\n##### Returns\n* **y **: array, shape (len(t), len(y0))\n    Array containing the value of y for each desired time in t,\n    with the initial value `y0` in the first row.\n\n* **infodict **: dict, only returned if full_output == True\n    Dictionary containing additional output information\n    =======  ============================================================\n    key      meaning\n    =======  ============================================================\n    'hu'     vector of step sizes successfully used for each time step\n    'tcur'   vector with the value of t reached for each time step\n             (will always be at least as large as the input times)\n    'tolsf'  vector of tolerance scale factors, greater than 1.0,\n             computed when a request for too much accuracy was detected\n    'tsw'    value of t at the time of the last method switch\n             (given for each time step)\n    'nst'    cumulative number of time steps\n    'nfe'    cumulative number of function evaluations for each time step\n    'nje'    cumulative number of jacobian evaluations for each time step\n    'nqu'    a vector of method orders for each successful step\n    'imxer'  index of the component of largest magnitude in the\n             weighted local error vector (e / ewt) on an error return, -1\n             otherwise\n    'lenrw'  the length of the double work array required\n    'leniw'  the length of integer work array required\n    'mused'  a vector of method indicators for each successful time step\n\n* **ml, mu **: int, optional\n    If either of these are not None or non-negative, then the\n    Jacobian is assumed to be banded. These give the number of\n    lower and upper non-zero diagonals in this banded matrix.\n    For the banded case, `Dfun` should return a matrix whose\n    rows contain the non-zero bands (starting with the lowest diagonal).\n    Thus, the return matrix `jac` from `Dfun` should have shape\n    ``(ml + mu + 1, len(y0))`` when ``ml >=0`` or ``mu >=0``.\n    The data in `jac` must be stored such that ``jac[i - j + mu, j]``\n    holds the derivative of the `i`th equation with respect to the `j`th\n    state variable.  If `col_deriv` is True, the transpose of this\n    `jac` must be returned.\n\n* **rtol, atol **: float, optional\n    The input parameters `rtol` and `atol` determine the error\n    control performed by the solver.  The solver will control the\n    vector, e, of estimated local errors in y, according to an\n    inequality of the form ``max-norm of (e / ewt) <= 1``,\n    where ewt is a vector of positive error weights computed as\n    ``ewt = rtol * abs(y) + atol``.\n    rtol and atol can be either vectors the same length as y or scalars.\n    Defaults to 1.49012e-8.\n\n* **tcrit **: ndarray, optional\n    Vector of critical points (e.g., singularities) where integration\n    care should be taken.\n\n* **h0 **: float, (0\n\n* **hmax **: float, (0\n\n* **hmin **: float, (0\n\n* **ixpr **: bool, optional\n    Whether to generate extra printing at method switches.\n\n* **mxstep **: int, (0\n\n* **mxhnil **: int, (0\n\n* **mxordn **: int, (0\n\n* **mxords **: int, (0\n\n* **solve_ivp **: solve an initial value problem for a system of ODEs\n\n* **ode **: a more object-oriented integrator based on VODE\n\n* **quad **: for finding the area under a curve\n\n* **pendulum acted on by gravity with friction can be written**: \n\n* **velocity ``omega(t) = theta'(t)``, we obtain the system**: \n\n* **in Python as**: \n\n* **>>> def pend(y, t, b, c)**: \n\n* **We assume the constants are `b` = 0.25 and `c` = 5.0**: \n\n* **0 <= `t` <= 10.  So our array of times is**: \n\n* **>>> plt.plot(t, sol[**: , 1], 'g', label='omega(t)')\n\n"
},{
    "source file": "odrpack.py",
    "line number": "103",
    "func name": "_report_error",
    "func arg": "(info)",
    "comments": "Interprets the return code of the odr routine.\n\nParameters ---------- info : int The return code of the odr routine.\n##### Returns\n* **problems **: list(str)\n    A list of messages about why the odr() routine stopped.\n\n"
},{
    "source file": "openblas_support.py",
    "line number": "261",
    "func name": "test_version",
    "func arg": "(expected_version, ilp64)",
    "comments": "Assert that expected OpenBLAS version is actually available via SciPy\n\n\n"
},{
    "source file": "optimize_global_1.py",
    "line number": "32",
    "func name": "plot_point",
    "func arg": "(res, marker, color)",
    "comments": ""
},{
    "source file": "optimize_global_2.py",
    "line number": "5",
    "func name": "eggholder",
    "func arg": "(x)",
    "comments": ""
},{
    "source file": "optimize_lap.py",
    "line number": "27",
    "func name": "random_spatial",
    "func arg": "(shape)",
    "comments": ""
},{
    "source file": "optimize_linprog.py",
    "line number": "82",
    "func name": "klee_minty",
    "func arg": "(D)",
    "comments": ""
},{
    "source file": "optimize.py",
    "line number": "3489",
    "func name": "main",
    "func arg": "()",
    "comments": ""
},{
    "source file": "orthogonal.py",
    "line number": "2135",
    "func name": "sh_legendre",
    "func arg": "(n, monic)",
    "comments": "Shifted Legendre polynomial.\n\nDefined as :math:`P^*_n(x) = P_n(2x\n\n- 1)` for :math:`P_n` the nth Legendre polynomial.\n\nParameters ---------- n : int Degree of the polynomial. monic : bool, optional If `True`, scale the leading coefficient to be 1. Default is `False`.\n##### Returns\n* **P **: orthopoly1d\n    Shifted Legendre polynomial.\n\n* **The polynomials **: math\n\n"
},{
    "source file": "pavement.py",
    "line number": "285",
    "func name": "write_release_and_log",
    "func arg": "(options)",
    "comments": ""
},{
    "source file": "polyint109.py",
    "line number": "649",
    "func name": "barycentric_interpolate",
    "func arg": "(xi, yi, x, axis)",
    "comments": "Convenience function for polynomial interpolation.\n\nConstructs a polynomial that passes through a given set of points, then evaluates the polynomial. For reasons of numerical stability, this function does not compute the coefficients of the polynomial.\n\nThis function uses a \"barycentric interpolation\" method that treats the problem as a special case of rational function interpolation. This algorithm is quite stable, numerically, but even in a world of exact computation, unless the `x` coordinates are chosen very carefully\n\n- Chebyshev zeros (e.g., cos(i*pi/n)) are a good choice\n\n- polynomial interpolation itself is a very ill-conditioned process due to the Runge phenomenon.\n\nParameters ---------- xi : array_like 1-D array of x coordinates of the points the polynomial should pass through yi : array_like The y coordinates of the points the polynomial should pass through. x : scalar or array_like Points to evaluate the interpolator at. axis : int, optional Axis in the yi array corresponding to the x-coordinate values.\n##### Returns\n* **y **: scalar or array_like\n    Interpolated values. Shape is determined by replacing\n    the interpolation axis in the original array with the shape of x.\n\n* **BarycentricInterpolator **: Bary centric interpolator\n\n* **We can interpolate 2D observed data using barycentric interpolation**: \n\n"
},{
    "source file": "postprocess.py",
    "line number": "41",
    "func name": "process_tex",
    "func arg": "(lines)",
    "comments": "Fix autosummary LaTeX bug in Sphinx < 1.7.3 (cf https://github.com/sphinx-doc/sphinx/issues/4790)\n\n\n"
},{
    "source file": "projections.py",
    "line number": "289",
    "func name": "projections",
    "func arg": "(A, method, orth_tol, max_refin, tol)",
    "comments": "Return three linear operators related with a given matrix A.\n\nParameters ---------- A : sparse matrix (or ndarray), shape (m, n) Matrix ``A`` used in the projection. method : string, optional Method used for compute the given linear operators. Should be one of:\n\n- 'NormalEquation': The operators will be computed using the so-called normal equation approach explained in [1]_. In order to do so the Cholesky factorization of ``(A A.T)`` is computed. Exclusive for sparse matrices.\n\n- 'AugmentedSystem': The operators will be computed using the so-called augmented system approach explained in [1]_. Exclusive for sparse matrices.\n\n- 'QRFactorization': Compute projections using QR factorization. Exclusive for dense matrices.\n\n- 'SVDFactorization': Compute projections using SVD factorization. Exclusive for dense matrices.\n\north_tol : float, optional Tolerance for iterative refinements. max_refin : int, optional Maximum number of iterative refinements. tol : float, optional Tolerance for singular values.\n##### Returns\n* **Z **: LinearOperator, shape (n, n)\n    Null-space operator. For a given vector ``x``,\n    the null space operator is equivalent to apply\n    a projection matrix ``P = I - A.T inv(A A.T) A``\n    to the vector. It can be shown that this is\n    equivalent to project ``x`` into the null space\n    of A.\n\n* **LS **: LinearOperator, shape (m, n)\n    Least-squares operator. For a given vector ``x``,\n    the least-squares operator is equivalent to apply a\n    pseudoinverse matrix ``pinv(A.T) = inv(A A.T) A``\n    to the vector. It can be shown that this vector\n    ``pinv(A.T) x`` is the least_square solution to\n    ``A.T y = x``.\n\n* **Y **: LinearOperator, shape (n, m)\n    Row-space operator. For a given vector ``x``,\n    the row-space operator is equivalent to apply a\n    projection matrix ``Q = A.T inv(A A.T)``\n    to the vector.  It can be shown that this\n    vector ``y = Q x``  the minimum norm solution\n    of ``A y = x``.\n\n* **.. [1] Gould, Nicholas IM, Mary E. Hribar, and Jorge Nocedal.\n    \"On the solution of equality constrained quadratic\n    programming problems arising in optimization.\"\n    SIAM Journal on Scientific Computing 23.4 (2001)**: 1376-1395.\n\n"
},{
    "source file": "pseudo_diffs110.py",
    "line number": "504",
    "func name": "shift",
    "func arg": "(x, a, period, _cache)",
    "comments": "Shift periodic sequence x by a: y(u) = x(u+a).\n\nIf x_j and y_j are Fourier coefficients of periodic functions x and y, respectively, then::\n\ny_j = exp(j*a*2*pi/period*sqrt(-1)) * x_f\n\nParameters ---------- x : array_like The array to take the pseudo-derivative from. a : float Defines the parameters of the sinh/sinh pseudo-differential period : float, optional The period of the sequences x and y. Default period is ``2*pi``.\n"
},{
    "source file": "qp_subproblem.py",
    "line number": "411",
    "func name": "projected_cg",
    "func arg": "(H, c, Z, Y, b, trust_radius, lb, ub, tol, max_iter, max_infeasible_iter, return_all)",
    "comments": "Solve EQP problem with projected CG method.\n\nSolve equality-constrained quadratic programming problem ``min 1/2 x.T H x + x.t c``\n\nsubject to ``A x + b = 0`` and, possibly, to trust region constraints ``||x|| < trust_radius`` and box constraints ``lb <= x <= ub``.\n\nParameters ---------- H : LinearOperator (or sparse matrix or ndarray), shape (n, n) Operator for computing ``H v``. c : array_like, shape (n,) Gradient of the quadratic objective function. Z : LinearOperator (or sparse matrix or ndarray), shape (n, n) Operator for projecting ``x`` into the null space of A. Y : LinearOperator,\n\nsparse matrix, ndarray, shape (n, m) Operator that, for a given a vector ``b``, compute smallest norm solution of ``A x + b = 0``. b : array_like, shape (m,) Right-hand side of the constraint equation. trust_radius : float, optional Trust radius to be considered. By default, uses ``trust_radius=inf``, which means no trust radius at all. lb : array_like, shape (n,), optional Lower bounds to each one of the components of ``x``. If ``lb[i] = -Inf`` the lower bound for the i-th component is just ignored (default). ub : array_like, shape (n, ), optional Upper bounds to each one of the components of ``x``. If ``ub[i] = Inf`` the upper bound for the i-th component is just ignored (default). tol : float, optional Tolerance used to interrupt the algorithm. max_iter : int, optional Maximum algorithm iterations. Where ``max_inter <= n-m``. By default, uses ``max_iter = n-m``. max_infeasible_iter : int, optional Maximum infeasible (regarding box constraints) iterations the algorithm is allowed to take. By default, uses ``max_infeasible_iter = n-m``. return_all : bool, optional When ``true``, return the list of all vectors through the iterations.\n##### Returns\n* **x **: array_like, shape (n,)\n    Solution of the EQP problem.\n\n* **info **: Dict\n    Dictionary containing the following\n\n* **.. [1] Gould, Nicholas IM, Mary E. Hribar, and Jorge Nocedal.\n       \"On the solution of equality constrained quadratic\n        programming problems arising in optimization.\"\n        SIAM Journal on Scientific Computing 23.4 (2001)**: 1376-1395.\n\n"
},{
    "source file": "quadpack.py",
    "line number": "694",
    "func name": "nquad",
    "func arg": "(func, ranges, args, opts, full_output)",
    "comments": "Integration over multiple variables.\n\nWraps `quad` to enable integration over multiple variables. Various options allow improved integration of discontinuous functions, as well as the use of weighted integration, and generally finer control of the integration process.\n\nParameters ---------- func : {callable, scipy.LowLevelCallable} The function to be integrated. Has arguments of ``x0, ... xn``, ``t0, ... tm``, where integration is carried out over ``x0, ... xn``, which must be floats.\n\nWhere ```t0, ... tm``` are extra arguments passed in args. Function signature should be ``func(x0, x1, ..., xn, t0, t1, ..., tm)``. Integration is carried out in order.\n\nThat is, integration over ``x0`` is the innermost integral, and ``xn`` is the outermost.\n\nIf the user desires improved integration performance, then `f` may be a `scipy.LowLevelCallable` with one of the signatures::\n\ndouble func(int n, double *xx) double func(int n, double *xx, void *user_data)\n\nwhere ``n`` is the number of variables and args.\n\nThe ``xx`` array contains the coordinates and extra arguments. ``user_data`` is the data contained in the `scipy.LowLevelCallable`. ranges : iterable object Each element of ranges may be either a sequence\n\nof 2 numbers, or else a callable that returns such a sequence. ``ranges[0]`` corresponds to integration over x0, and so on. If an element of ranges is a callable, then it will be called with all of the integration arguments available, as well as any parametric arguments. e.g., if ``func = f(x0, x1, x2, t0, t1)``, then ``ranges[0]`` may be defined as either ``(a, b)`` or else as ``(a, b) = range0(x1, x2, t0, t1)``. args : iterable object, optional Additional arguments ``t0, ..., tn``, required by `func`, `ranges`, and ``opts``. opts : iterable object or dict, optional Options to be passed to `quad`. May be empty, a dict, or a sequence of dicts or functions that return a dict. If empty, the default options from scipy.integrate.quad are used. If a dict, the same options are used for all levels of integraion. If a sequence, then each element of the sequence corresponds to a particular integration. e.g., opts[0] corresponds to integration over x0, and so on. If a callable, the signature must be the same as for ``ranges``. The available options together with their default values are:\n\n- epsabs = 1.49e-08\n\n- epsrel = 1.49e-08\n\n- limit\n\n= 50\n\n- points = None\n\n- weight = None\n\n- wvar\n\n = None\n\n- wopts\n\n= None\n\nFor more information on these options, see `quad` and `quad_explain`.\n\nfull_output : bool, optional Partial implementation of ``full_output`` from scipy.integrate.quad. The number of integrand function evaluations ``neval`` can be obtained by setting ``full_output=True`` when calling nquad.\n##### Returns\n* **result **: float\n    The result of the integration.\n\n* **abserr **: float\n    The maximum of the estimates of the absolute error in the various\n    integration results.\n\n* **out_dict **: dict, optional\n    A dict containing additional information on the integration.\n\n* **quad **: 1-D numerical integration\n\n* **dblquad, tplquad **: double and triple integrals\n\n* **fixed_quad **: fixed-order Gaussian quadrature\n\n* **quadrature **: adaptive Gaussian quadrature\n\n* **>>> func = lambda x0,x1,x2,x3 **: x0**2 + x1*x2 - x3**3 + np.sin(x0) + (\n\n* **>>> def opts0(*args, **kwargs)**: \n\n* **...     return {'points'**: [0.2*args[2] + 0.5 + 0.25*args[0]]}\n\n* **(1.5267454070738633, 2.9437360001402324e-14, {'neval'**: 388962})\n\n* **>>> def func2(x0, x1, x2, x3, t0, t1)**: \n\n* **>>> def lim0(x1, x2, x3, t0, t1)**: \n\n* **>>> def lim1(x2, x3, t0, t1)**: \n\n* **>>> def lim2(x3, t0, t1)**: \n\n* **>>> def lim3(t0, t1)**: \n\n* **>>> def opts0(x1, x2, x3, t0, t1)**: \n\n* **...     return {'points' **: [t0 - t1*x1]}\n\n* **>>> def opts1(x2, x3, t0, t1)**: \n\n* **>>> def opts2(x3, t0, t1)**: \n\n* **>>> def opts3(t0, t1)**: \n\n"
},{
    "source file": "radau.py",
    "line number": "139",
    "func name": "predict_factor",
    "func arg": "(h_abs, h_abs_old, error_norm, error_norm_old)",
    "comments": "Predict by which factor to increase/decrease the step size.\n\nThe algorithm is described in [1]_.\n\nParameters ---------- h_abs, h_abs_old : float Current and previous values of the step size, `h_abs_old` can be None (see Notes). error_norm, error_norm_old : float Current and previous values of the error norm, `error_norm_old` can be None (see Notes).\n##### Returns\n* **factor **: float\n    Predicted factor.\n\n* **.. [1] E. Hairer, S. P. Norsett G. Wanner, \"Solving Ordinary Differential\n       Equations II**: Stiff and Differential-Algebraic Problems\", Sec. IV.8.\n\n"
},{
    "source file": "realtransforms112.py",
    "line number": "545",
    "func name": "idst",
    "func arg": "(x, type, n, axis, norm, overwrite_x)",
    "comments": "Return the Inverse Discrete Sine Transform of an arbitrary type sequence.\n\nParameters ---------- x : array_like The input array. type : {1, 2, 3, 4}, optional Type of the DST (see Notes). Default type is 2. n : int, optional Length of the transform.\n\nIf ``n < x.shape[axis]``, `x` is truncated. If ``n > x.shape[axis]``, `x` is zero-padded. The default results in ``n = x.shape[axis]``. axis : int, optional Axis along which the idst is computed; the default is over the last axis (i.e., ``axis=-1``). norm : {None, 'ortho'}, optional Normalization mode (see Notes). Default is None. overwrite_x : bool, optional If True, the contents of `x` can be destroyed; the default is False.\n##### Returns\n* **idst **: ndarray of real\n    The transformed input array.\n\n* **dst **: Forward DST\n\n* **.. versionadded**: \n\n"
},{
    "source file": "realtransforms113.py",
    "line number": "60",
    "func name": "_r2rn",
    "func arg": "(forward, transform, x, type, s, axes, norm, overwrite_x, workers)",
    "comments": "Forward or backward nd DCT/DST\n\nParameters ---------- forward: bool Transform direction (determines type and normalisation) transform: {pypocketfft.dct, pypocketfft.dst} The transform to perform\n"
},{
    "source file": "refguide_check.py",
    "line number": "823",
    "func name": "main",
    "func arg": "(argv)",
    "comments": ""
},{
    "source file": "refguide_summaries.py",
    "line number": "43",
    "func name": "main",
    "func arg": "()",
    "comments": ""
},{
    "source file": "rk.py",
    "line number": "14",
    "func name": "rk_step",
    "func arg": "(fun, t, y, f, h, A, B, C, K)",
    "comments": "Perform a single Runge-Kutta step.\n\nThis function computes a prediction of an explicit Runge-Kutta method and also estimates the error of a less accurate method.\n\nNotation for Butcher tableau is as in [1]_.\n\nParameters ---------- fun : callable Right-hand side of the system. t : float Current time. y : ndarray, shape (n,) Current state. f : ndarray, shape (n,) Current value of the derivative, i.e., ``fun(x, y)``. h : float Step to use. A : ndarray, shape (n_stages, n_stages) Coefficients for combining previous RK stages to compute the next stage. For explicit methods the coefficients at and above the main diagonal are zeros. B : ndarray, shape (n_stages,) Coefficients for combining RK stages for computing the final prediction. C : ndarray, shape (n_stages,) Coefficients for incrementing time for consecutive RK stages. The value for the first stage is always zero. K : ndarray, shape (n_stages + 1, n) Storage array for putting RK stages here. Stages are stored in rows. The last row is a linear combination of the previous rows with coefficients\n##### Returns\n* **y_new **: ndarray, shape (n,)\n    Solution at t + h computed with a higher accuracy.\n\n* **f_new **: ndarray, shape (n,)\n    Derivative ``fun(t + h, y_new)``.\n\n* **.. [1] E. Hairer, S. P. Norsett G. Wanner, \"Solving Ordinary Differential\n       Equations I**: Nonstiff Problems\", Sec. II.4.\n\n"
},{
    "source file": "run.py",
    "line number": "82",
    "func name": "drop_bad_flags",
    "func arg": "(flags)",
    "comments": "Drop flags that are problematic for compiling old scipy versions\n\n\n"
},{
    "source file": "runtests.py",
    "line number": "497",
    "func name": "run_mypy",
    "func arg": "(args)",
    "comments": ""
},{
    "source file": "scipyoptdoc.py",
    "line number": "72",
    "func name": "wrap_mangling_directive",
    "func arg": "(base_directive)",
    "comments": ""
},{
    "source file": "setup.py",
    "line number": "16",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup114.py",
    "line number": "6",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup115.py",
    "line number": "2",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup116.py",
    "line number": "4",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup117.py",
    "line number": "4",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup118.py",
    "line number": "2",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup119.py",
    "line number": "2",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup120.py",
    "line number": "2",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup121.py",
    "line number": "2",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup122.py",
    "line number": "5",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup123.py",
    "line number": "2",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup124.py",
    "line number": "4",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup125.py",
    "line number": "500",
    "func name": "setup_package",
    "func arg": "()",
    "comments": ""
},{
    "source file": "setup126.py",
    "line number": "4",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup127.py",
    "line number": "2",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup128.py",
    "line number": "9",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup129.py",
    "line number": "1",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup130.py",
    "line number": "4",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup131.py",
    "line number": "5",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup132.py",
    "line number": "7",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup133.py",
    "line number": "2",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup134.py",
    "line number": "2",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup135.py",
    "line number": "2",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup136.py",
    "line number": "2",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup137.py",
    "line number": "4",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup138.py",
    "line number": "16",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup139.py",
    "line number": "3",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup140.py",
    "line number": "4",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup141.py",
    "line number": "4",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup142.py",
    "line number": "2",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup143.py",
    "line number": "29",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup144.py",
    "line number": "6",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup145.py",
    "line number": "2",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup146.py",
    "line number": "2",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup147.py",
    "line number": "2",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup148.py",
    "line number": "7",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup149.py",
    "line number": "1",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup150.py",
    "line number": "2",
    "func name": "configuration",
    "func arg": "(parent_package, top_path)",
    "comments": ""
},{
    "source file": "setup151.py",
    "line number": "2",
    "func name": "configuration",
    "func arg": "(parent_name, top_path)",
    "comments": ""
},{
    "source file": "signaltools152.py",
    "line number": "4326",
    "func name": "decimate",
    "func arg": "(x, q, n, ftype, axis, zero_phase)",
    "comments": "Downsample the signal after applying an anti-aliasing filter.\n\nBy default, an order 8 Chebyshev type I filter is used. A 30 point FIR filter with Hamming window is used if `ftype` is 'fir'.\n\nParameters ---------- x : array_like The signal to be downsampled, as an N-dimensional array. q : int The downsampling factor. When using IIR downsampling, it is recommended to call `decimate` multiple times for downsampling factors higher than 13. n : int, optional The order of the filter (1 less than the length for 'fir'). Defaults to 8 for 'iir' and 20 times the downsampling factor for 'fir'. ftype : str {'iir', 'fir'} or ``dlti`` instance, optional If 'iir' or 'fir', specifies the type of lowpass filter. If an instance of an `dlti` object, uses that object to filter before downsampling. axis : int, optional The axis along which to decimate. zero_phase : bool, optional Prevent phase shift by filtering with `filtfilt` instead of `lfilter` when using an IIR filter, and shifting the outputs back by the filter's group delay when using an FIR filter. The default value of ``True`` is recommended, since a phase shift is generally not desired.\n\n.. versionadded:: 0.18.0\n##### Returns\n* **y **: ndarray\n    The down-sampled signal.\n\n* **resample **: Resample up or down using the FFT method.\n\n* **resample_poly **: Resample using polyphase filtering and an FIR filter.\n\n"
},{
    "source file": "slsqp.py",
    "line number": "477",
    "func name": "_eval_con_normals",
    "func arg": "(x, cons, la, n, m, meq, mieq)",
    "comments": ""
},{
    "source file": "sparse_linalg_expm.py",
    "line number": "24",
    "func name": "random_sparse_csc",
    "func arg": "(m, n, nnz_per_row)",
    "comments": ""
},{
    "source file": "sparse_linalg_lobpcg.py",
    "line number": "55",
    "func name": "_precond",
    "func arg": "(LorU, lower, x)",
    "comments": ""
},{
    "source file": "sparse_linalg_solve.py",
    "line number": "34",
    "func name": "_create_sparse_poisson2d",
    "func arg": "(n)",
    "comments": ""
},{
    "source file": "sparse.py",
    "line number": "34",
    "func name": "poisson2d",
    "func arg": "(N, dtype, format)",
    "comments": "Return a sparse matrix for the 2D Poisson problem with standard 5-point finite difference stencil on a square N-by-N grid.\n\n\n"
},{
    "source file": "sparsetools153.py",
    "line number": "14",
    "func name": "_deprecated",
    "func arg": "()",
    "comments": ""
},{
    "source file": "spatial.py",
    "line number": "293",
    "func name": "generate_spherical_points",
    "func arg": "(num_points)",
    "comments": ""
},{
    "source file": "special_matrices.py",
    "line number": "1195",
    "func name": "convolution_matrix",
    "func arg": "(a, n, mode)",
    "comments": "Construct a convolution matrix.\n\nConstructs the Toeplitz matrix representing one-dimensional convolution [1]_.\n\nSee the notes below for details.\n\nParameters ---------- a : (m,) array_like The 1-D array to convolve. n : int The number of columns in the resulting matrix.\n\nIt gives the length of the input to be convolved with `a`.\n\nThis is analogous to the length of `v` in ``numpy.convolve(a, v)``. mode : str This is analogous to `mode` in ``numpy.convolve(v, a, mode)``. It must be one of ('full', 'valid', 'same'). See below for how `mode` determines the shape of the result.\n##### Returns\n* **A **: (k, n) ndarray\n    The convolution matrix whose row count `k` depends on `mode`\n\n* **toeplitz **: Toeplitz matrix\n\n* **The code**: \n\n* **In the default 'full' mode, the entries of `A` are given by**: \n\n* **``[x, y, z]``.  The convolution matrix has the form**: \n\n* **In 'valid' mode, the entries of `A` are given by**: \n\n* **row.  For input ``[x, y, z]``, this array looks like**: \n\n* **In the 'same' mode, the entries of `A` are given by**: \n\n* **For input ``[x, y, z]``, this array looks like**: \n\n* **.. versionadded**: \n\n* **.. [1] \"Convolution\", https**: //en.wikipedia.org/wiki/Convolution\n\n"
},{
    "source file": "spectral154.py",
    "line number": "1981",
    "func name": "_median_bias",
    "func arg": "(n)",
    "comments": "Returns the bias of the median of a set of periodograms relative to the mean.\n\nSee arXiv:gr-qc/0509116 Appendix B for details.\n\nParameters ---------- n : int Numbers of periodograms being averaged.\n##### Returns\n* **bias **: float\n    Calculated bias.\n\n"
},{
    "source file": "spfun_stats.py",
    "line number": "42",
    "func name": "multigammaln",
    "func arg": "(a, d)",
    "comments": "Returns the log of multivariate gamma, also sometimes called the generalized gamma.\n\nParameters ---------- a : ndarray The multivariate gamma is computed for each item of `a`. d : int The dimension of the space of integration.\n##### Returns\n* **res **: ndarray\n    The values of the log multivariate gamma at the given points `a`.\n\n* **.. math**: \n\n* **with the condition **: math\n\n* **scalar**: the integrand only is multivariate, the argument is not (the\n\n"
},{
    "source file": "spfuncs155.py",
    "line number": "84",
    "func name": "count_blocks",
    "func arg": "(A, blocksize)",
    "comments": "For a given blocksize=(r,c) count the number of occupied blocks in a sparse matrix A\n\n\n"
},{
    "source file": "sputils156.py",
    "line number": "351",
    "func name": "asmatrix",
    "func arg": "(data, dtype)",
    "comments": ""
},{
    "source file": "stats157.py",
    "line number": "7954",
    "func name": "rankdata",
    "func arg": "(a, method)",
    "comments": "Assign ranks to data, dealing with ties appropriately.\n\nBy default (``axis=None``), the data array is first flattened, and a flat array of ranks is returned. Separately reshape the rank array to the shape of the data array if desired (see Examples).\n\nRanks begin at 1.\n\nThe `method` argument controls how ranks are assigned to equal values.\n\nSee [1]_ for further discussion of ranking methods.\n\nParameters ---------- a : array_like The array of values to be ranked. method : {'average', 'min', 'max', 'dense', 'ordinal'}, optional The method used to assign ranks to tied elements. The following methods are available (default is 'average'):\n\n* 'average': The average of the ranks that would have been assigned to all the tied values is assigned to each value. * 'min': The minimum of the ranks that would have been assigned to all the tied values is assigned to each value.\n\n(This is also referred to as \"competition\" ranking.) * 'max': The maximum of the ranks that would have been assigned to all the tied values is assigned to each value. * 'dense': Like 'min', but the rank of the next highest element is assigned the rank immediately after those assigned to the tied elements. * 'ordinal': All values are given a distinct rank, corresponding to the order that the values occur in `a`. axis : {None, int}, optional Axis along which to perform the ranking. If ``None``, the data array is first flattened.\n##### Returns\n* **ranks **: ndarray\n     An array of size equal to the size of `a`, containing rank\n     scores.\n\n* **.. [1] \"Ranking\", https**: //en.wikipedia.org/wiki/Ranking\n\n"
},{
    "source file": "struve_convergence.py",
    "line number": "105",
    "func name": "main",
    "func arg": "()",
    "comments": ""
},{
    "source file": "suppress_output.py",
    "line number": "190",
    "func name": "test_suppress_long_failed",
    "func arg": "(tmpdir)",
    "comments": ""
},{
    "source file": "system_info158.py",
    "line number": "20",
    "func name": "combine_dict",
    "func arg": "(**kw)",
    "comments": "Combine Numpy distutils style library configuration dictionaries.\n\nParameters ---------- *dicts Dictionaries of keys. List-valued keys will be concatenated. Otherwise, duplicate keys with different values result to an error. The input arguments are not modified. **kw Keyword arguments are treated as an additional dictionary (the first one, i.e., prepended).\n##### Returns\n"
},{
    "source file": "test__basinhopping.py",
    "line number": "58",
    "func name": "myTakeStep2",
    "func arg": "(x)",
    "comments": "redo RandomDisplacement in function form without the attribute stepsize to make sure everything still works ok\n\n\n"
},{
    "source file": "test__gcutils.py",
    "line number": "94",
    "func name": "test_assert_deallocated_circular2",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test__linprog_clean_inputs.py",
    "line number": "252",
    "func name": "test_good_bounds",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test__numdiff.py",
    "line number": "627",
    "func name": "test_absolute_step",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test__pep440.py",
    "line number": "63",
    "func name": "test_legacy_version",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test__quad_vec.py",
    "line number": "149",
    "func name": "test_points",
    "func arg": "(a, b)",
    "comments": ""
},{
    "source file": "test__remove_redundancy.py",
    "line number": "26",
    "func name": "_assert_success",
    "func arg": "(res, desired_fun, desired_x, rtol, atol)",
    "comments": ""
},{
    "source file": "test__shgo.py",
    "line number": "279",
    "func name": "run_test",
    "func arg": "(test, args, test_atol, n, iters, callback, minimizer_kwargs, options, sampling_method)",
    "comments": ""
},{
    "source file": "test__spectral.py",
    "line number": "207",
    "func name": "x0_10",
    "func arg": "(n)",
    "comments": ""
},{
    "source file": "test__testutils.py",
    "line number": "26",
    "func name": "test__mem_available",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test__threadsafety.py",
    "line number": "44",
    "func name": "test_reentering",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test__util.py",
    "line number": "194",
    "func name": "test_rng_integers",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_arpack161.py",
    "line number": "987",
    "func name": "test_real_eigs_real_k_subset",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_backend163.py",
    "line number": "76",
    "func name": "test_backend_plan",
    "func arg": "(func, mock)",
    "comments": ""
},{
    "source file": "test_banded_ode_solvers.py",
    "line number": "127",
    "func name": "test_banded_ode_solvers",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_base164.py",
    "line number": "4623",
    "func name": "cases_64bit",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_basic.py",
    "line number": "1321",
    "func name": "test_auto_rcond",
    "func arg": "(scale, pinv_)",
    "comments": ""
},{
    "source file": "test_basic165.py",
    "line number": "101",
    "func name": "direct_irdft",
    "func arg": "(x)",
    "comments": ""
},{
    "source file": "test_basic166.py",
    "line number": "1018",
    "func name": "test_swapped_byte_order_real",
    "func arg": "(func)",
    "comments": ""
},{
    "source file": "test_basic167.py",
    "line number": "3380",
    "func name": "test_pseudo_huber",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_blas.py",
    "line number": "1048",
    "func name": "test_trsm",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_boxcox.py",
    "line number": "101",
    "func name": "test_inv_boxcox1p_underflow",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_bsplines170.py",
    "line number": "1150",
    "func name": "make_lsq_full_matrix",
    "func arg": "(x, y, t, k)",
    "comments": "Make the least-square spline, full matrices.\n\n\n"
},{
    "source file": "test_bvp.py",
    "line number": "583",
    "func name": "test_verbose",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_byteordercodes.py",
    "line number": "16",
    "func name": "test_to_numpy",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_c_api.py",
    "line number": "79",
    "func name": "test_geometric_transform",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_canonical_constraint.py",
    "line number": "282",
    "func name": "test_initial_constraints_as_canonical_empty",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_ccallback.py",
    "line number": "168",
    "func name": "test_threadsafety",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_cdflib.py",
    "line number": "354",
    "func name": "test_nonfinite",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_cobyla.py",
    "line number": "73",
    "func name": "test_vector_constraints",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_codata.py",
    "line number": "51",
    "func name": "test_exact_values",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_common.py",
    "line number": "14",
    "func name": "test_electrocardiogram",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_connected_components171.py",
    "line number": "94",
    "func name": "test_fully_connected_graph",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_constants.py",
    "line number": "33",
    "func name": "test_nu_to_lambda",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_constraints.py",
    "line number": "164",
    "func name": "test_bounds_repr",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_construct172.py",
    "line number": "21",
    "func name": "_sprandn",
    "func arg": "(m, n, density, format, dtype, random_state)",
    "comments": ""
},{
    "source file": "test_contingency174.py",
    "line number": "183",
    "func name": "test_chi2_contingency_bad_args",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_continuous_basic175.py",
    "line number": "646",
    "func name": "test_methods_with_lists",
    "func arg": "(method, distname, args)",
    "comments": ""
},{
    "source file": "test_conversions176.py",
    "line number": "44",
    "func name": "test_multiple_edges",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_csc177.py",
    "line number": "54",
    "func name": "test_csc_empty_slices",
    "func arg": "(matrix_input, axis, expected_shape)",
    "comments": ""
},{
    "source file": "test_csr178.py",
    "line number": "98",
    "func name": "test_csr_bool_indexing",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_cython_optimize.py",
    "line number": "86",
    "func name": "test_brentq_full_output",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_cython_special.py",
    "line number": "300",
    "func name": "test_cython_api",
    "func arg": "(param)",
    "comments": ""
},{
    "source file": "test_data.py",
    "line number": "490",
    "func name": "_test_factory",
    "func arg": "(test, dtype)",
    "comments": "Boost test\n\n\n"
},{
    "source file": "test_datatypes.py",
    "line number": "49",
    "func name": "test_uint64_max",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_decomp_cossin.py",
    "line number": "132",
    "func name": "test_cossin_separate",
    "func arg": "(dtype_)",
    "comments": ""
},{
    "source file": "test_decomp_ldl.py",
    "line number": "93",
    "func name": "test_ldl_type_size_combinations",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_decomp_polar.py",
    "line number": "87",
    "func name": "test_verify_cases",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_decomp_update.py",
    "line number": "1669",
    "func name": "check_form_qTu",
    "func arg": "(q_order, q_shape, u_order, u_shape, u_ndim, dtype)",
    "comments": ""
},{
    "source file": "test_decomp.py",
    "line number": "2743",
    "func name": "test_subspace_angles",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_deprecation.py",
    "line number": "4",
    "func name": "test_cython_api_deprecation",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_differentiable_functions.py",
    "line number": "675",
    "func name": "test_IdentityVectorFunction",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_digamma.py",
    "line number": "38",
    "func name": "test_nonfinite",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_discrete_basic179.py",
    "line number": "257",
    "func name": "test_methods_with_lists",
    "func arg": "(method, distname, args)",
    "comments": ""
},{
    "source file": "test_discrete_distns180.py",
    "line number": "61",
    "func name": "test_betabinom_bernoulli",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_distance181.py",
    "line number": "2075",
    "func name": "test__validate_vector",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_distributions182.py",
    "line number": "4415",
    "func name": "test_rvs_no_size_warning",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_doccer.py",
    "line number": "106",
    "func name": "test_inherit_docstring_from",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_ellip_harm.py",
    "line number": "272",
    "func name": "test_ellip_harm_invalid_p",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_expm_multiply184.py",
    "line number": "14",
    "func name": "less_than_or_close",
    "func arg": "(a, b)",
    "comments": ""
},{
    "source file": "test_fblas.py",
    "line number": "26",
    "func name": "matrixmultiply",
    "func arg": "(a, b)",
    "comments": ""
},{
    "source file": "test_fft_function186.py",
    "line number": "6",
    "func name": "test_fft_function",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_filter_design187.py",
    "line number": "3405",
    "func name": "test_sos_consistency",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_filters.py",
    "line number": "436",
    "func name": "test_size_footprint_both_set",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_fir_filter_design188.py",
    "line number": "32",
    "func name": "test_kaiserord",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_fit189.py",
    "line number": "115",
    "func name": "test_expon_fit",
    "func arg": "()",
    "comments": "gh-6167\n\n\n"
},{
    "source file": "test_fitpack190.py",
    "line number": "462",
    "func name": "test_bisplev_integer_overflow",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_fitpack2191.py",
    "line number": "929",
    "func name": "_numdiff_2d",
    "func arg": "(func, x, y, dx, dy, eps)",
    "comments": ""
},{
    "source file": "test_flow192.py",
    "line number": "114",
    "func name": "test_disconnected_graph",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_fortran.py",
    "line number": "221",
    "func name": "test_fortran_eof_multidimensional",
    "func arg": "(tmpdir)",
    "comments": ""
},{
    "source file": "test_gcrotmk193.py",
    "line number": "36",
    "func name": "do_solve",
    "func arg": "(**kw)",
    "comments": ""
},{
    "source file": "test_graph_laplacian195.py",
    "line number": "129",
    "func name": "test_sparse_formats",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_hb.py",
    "line number": "38",
    "func name": "assert_csc_almost_equal",
    "func arg": "(r, l)",
    "comments": ""
},{
    "source file": "test_helper198.py",
    "line number": "20",
    "func name": "_assert_n_smooth",
    "func arg": "(x, n)",
    "comments": ""
},{
    "source file": "test_hierarchy.py",
    "line number": "1062",
    "func name": "test_Heap",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_idl.py",
    "line number": "423",
    "func name": "test_invalid_pointer",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_import_cycles.py",
    "line number": "46",
    "func name": "test_modules_importable",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_integrate.py",
    "line number": "804",
    "func name": "test_repeated_t_values",
    "func arg": "()",
    "comments": "Regression test for gh-8217.\n\n\n"
},{
    "source file": "test_interface200.py",
    "line number": "440",
    "func name": "test_transpose_noconjugate",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_interpnd201.py",
    "line number": "15",
    "func name": "data_file",
    "func arg": "(basename)",
    "comments": ""
},{
    "source file": "test_interpolate202.py",
    "line number": "2315",
    "func name": "_ppoly4d_eval",
    "func arg": "(c, xs, xnew, ynew, znew, unew, nu)",
    "comments": "Straightforward evaluation of 4-D piecewise polynomial\n\n\n"
},{
    "source file": "test_interpolative.py",
    "line number": "41",
    "func name": "_debug_print",
    "func arg": "(s)",
    "comments": ""
},{
    "source file": "test_iterative203.py",
    "line number": "486",
    "func name": "test_x0_working",
    "func arg": "(solver)",
    "comments": ""
},{
    "source file": "test_ivp.py",
    "line number": "978",
    "func name": "test_integration_zero_rhs",
    "func arg": "(method)",
    "comments": ""
},{
    "source file": "test_kdeoth204.py",
    "line number": "423",
    "func name": "test_seed",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_kdtree205.py",
    "line number": "1469",
    "func name": "test_kdtree_complex_data",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_lambertw.py",
    "line number": "91",
    "func name": "test_lambertw_ufunc_loop_selection",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_lapack.py",
    "line number": "2915",
    "func name": "test_ptsvx_NAG",
    "func arg": "(d, e, b, x)",
    "comments": ""
},{
    "source file": "test_lbfgsb_hessinv.py",
    "line number": "22",
    "func name": "test_2",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_lbfgsb_setulb.py",
    "line number": "69",
    "func name": "test_setulb_floatround",
    "func arg": "()",
    "comments": "test if setulb() violates bounds\n\nchecks for violation due to floating point rounding error\n"
},{
    "source file": "test_least_squares.py",
    "line number": "751",
    "func name": "test_small_tolerances_for_lm",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_lgmres206.py",
    "line number": "38",
    "func name": "do_solve",
    "func arg": "(**kw)",
    "comments": ""
},{
    "source file": "test_linear_assignment.py",
    "line number": "96",
    "func name": "test_constant_cost_matrix",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_linesearch.py",
    "line number": "46",
    "func name": "assert_fp_equal",
    "func arg": "(x, y, err_msg, nulp)",
    "comments": "Assert two arrays are equal, up to some floating-point rounding error\n\n\n"
},{
    "source file": "test_linprog.py",
    "line number": "215",
    "func name": "test_unknown_solver",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_linsolve207.py",
    "line number": "44",
    "func name": "setup_bug_8278",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_lobpcg208.py",
    "line number": "322",
    "func name": "test_diagonal_data_types",
    "func arg": "()",
    "comments": "Check lobpcg for diagonal matrices for all matrix types.\n\n\n"
},{
    "source file": "test_log_softmax.py",
    "line number": "108",
    "func name": "test_log_softmax_scalar",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_loggamma.py",
    "line number": "65",
    "func name": "test_branch_cut",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_logsumexp.py",
    "line number": "170",
    "func name": "test_softmax_multi_axes",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_lsmr209.py",
    "line number": "182",
    "func name": "lsmrtest",
    "func arg": "(m, n, damp)",
    "comments": "Verbose testing of lsmr\n\n\n"
},{
    "source file": "test_lsq_common.py",
    "line number": "276",
    "func name": "test_linear_operators",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_lsqr210.py",
    "line number": "91",
    "func name": "test_initialization",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_ltisys211.py",
    "line number": "17",
    "func name": "_assert_poles_close",
    "func arg": "(P1, P2, rtol, atol)",
    "comments": "Check each pole in P1 is close to a pole in P2 with a 1e-8 relative tolerance or 1e-8 absolute tolerance (useful for zero poles). These tolerances are very strict but the systems tested are known to accept these poles so we should not be far from what is requested.\n\n\n"
},{
    "source file": "test_matching212.py",
    "line number": "109",
    "func name": "test_large_random_graph_with_one_edge_incident_to_each_vertex",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_matfuncs.py",
    "line number": "765",
    "func name": "_relative_error",
    "func arg": "(f, A, perturbation)",
    "comments": ""
},{
    "source file": "test_matfuncs213.py",
    "line number": "60",
    "func name": "test_onenorm_matrix_power_nnm",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_matrix_io214.py",
    "line number": "79",
    "func name": "test_implemented_error",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_measurements.py",
    "line number": "1072",
    "func name": "test_stat_funcs_2d",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_minimize_constrained.py",
    "line number": "670",
    "func name": "test_bug_11886",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_minpack.py",
    "line number": "107",
    "func name": "pressure_network_fun_and_grad",
    "func arg": "(flow_rates, Qtot, k)",
    "comments": ""
},{
    "source file": "test_minres216.py",
    "line number": "89",
    "func name": "test_minres_precond_exact_x0",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_mio_funcs.py",
    "line number": "50",
    "func name": "test_jottings",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_mio_utils.py",
    "line number": "23",
    "func name": "test_chars_strings",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_mio.py",
    "line number": "1230",
    "func name": "test_simplify_cells",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_mio5_utils.py",
    "line number": "153",
    "func name": "test_zero_byte_string",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_miobase.py",
    "line number": "12",
    "func name": "test_matdims",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_mmio.py",
    "line number": "702",
    "func name": "test_gh11389",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_morphology.py",
    "line number": "39",
    "func name": "test_binary_closing_noninteger_brute_force_passes_when_true",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_mpmath.py",
    "line number": "657",
    "func name": "test_lambertw_smallz",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_mstats_basic218.py",
    "line number": "755",
    "func name": "test_plotting_positions",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_mstats_extras219.py",
    "line number": "67",
    "func name": "test_idealfourths",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_multithreading220.py",
    "line number": "75",
    "func name": "test_set_workers_invalid",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_multivariate221.py",
    "line number": "1658",
    "func name": "test_random_state_property",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_nan_inputs.py",
    "line number": "59",
    "func name": "test_legacy_cast",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_ndgriddata222.py",
    "line number": "177",
    "func name": "test_nearest_list_argument",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_ndimage.py",
    "line number": "47",
    "func name": "sumsq",
    "func arg": "(a, b)",
    "comments": ""
},{
    "source file": "test_ndtr.py",
    "line number": "6",
    "func name": "test_ndtr",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_netcdf.py",
    "line number": "532",
    "func name": "test_read_withMaskAndScaleFalse",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_nonlin.py",
    "line number": "87",
    "func name": "F6",
    "func arg": "(x)",
    "comments": ""
},{
    "source file": "test_numpy224.py",
    "line number": "305",
    "func name": "test_multiprocess",
    "func arg": "(func)",
    "comments": ""
},{
    "source file": "test_odeint_jac.py",
    "line number": "74",
    "func name": "test_odeint_banded_jac",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_optimize.py",
    "line number": "2154",
    "func name": "test_memoize_jac_with_bfgs",
    "func arg": "(function_with_gradient)",
    "comments": "Tests that using MemoizedJac in combination with ScalarFunction and BFGS does not lead to repeated function evaluations. Tests changes made in response to GH11868.\n\n\n"
},{
    "source file": "test_orthogonal_eval.py",
    "line number": "262",
    "func name": "test_gegenbauer_nan",
    "func arg": "(n, alpha, x)",
    "comments": ""
},{
    "source file": "test_orthogonal.py",
    "line number": "746",
    "func name": "test_gh_6721",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_owens_t.py",
    "line number": "30",
    "func name": "test_infs",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_pade226.py",
    "line number": "84",
    "func name": "test_pade_complex",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_pathological.py",
    "line number": "25",
    "func name": "test_malformed1",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_pcf.py",
    "line number": "19",
    "func name": "test_pbwa_nan",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_peak_finding227.py",
    "line number": "574",
    "func name": "test_unpack_condition_args",
    "func arg": "()",
    "comments": "Verify parsing of condition arguments for `scipy.signal.find_peaks` function.\n\n\n"
},{
    "source file": "test_polyint228.py",
    "line number": "691",
    "func name": "test_roots_extrapolate_gh_11185",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_precompute_expn_asy.py",
    "line number": "14",
    "func name": "test_generate_A",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_precompute_gammainc.py",
    "line number": "97",
    "func name": "test_gammaincc",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_procrustes.py",
    "line number": "161",
    "func name": "test_orthogonal_procrustes_skbio_example",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_pseudo_diffs229.py",
    "line number": "73",
    "func name": "direct_shift",
    "func arg": "(x, a, period)",
    "comments": ""
},{
    "source file": "test_pydata_sparse230.py",
    "line number": "233",
    "func name": "test_ne",
    "func arg": "(same_matrix)",
    "comments": ""
},{
    "source file": "test_qhull231.py",
    "line number": "547",
    "func name": "assert_hulls_equal",
    "func arg": "(points, facets_1, facets_2)",
    "comments": ""
},{
    "source file": "test_quadpack.py",
    "line number": "26",
    "func name": "get_clib_test_routine",
    "func arg": "(name, restype)",
    "comments": ""
},{
    "source file": "test_rank232.py",
    "line number": "237",
    "func name": "test_cases",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_rbf233.py",
    "line number": "214",
    "func name": "test_rbf_epsilon_none_collinear",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_real_transforms234.py",
    "line number": "142",
    "func name": "naive_dst4",
    "func arg": "(x, norm)",
    "comments": "Calculate textbook definition version of DST-IV.\n\n\n"
},{
    "source file": "test_real_transforms235.py",
    "line number": "139",
    "func name": "test_fftpack_equivalience",
    "func arg": "(func, type, norm)",
    "comments": ""
},{
    "source file": "test_real_transforms236.py",
    "line number": "483",
    "func name": "test_swapped_byte_order",
    "func arg": "(func)",
    "comments": ""
},{
    "source file": "test_regression.py",
    "line number": "37",
    "func name": "test_gh_issue_3025",
    "func arg": "()",
    "comments": "Github issue #3025 - improper merging of labels\n\n\n"
},{
    "source file": "test_reordering239.py",
    "line number": "50",
    "func name": "test_graph_structural_rank",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_report.py",
    "line number": "3",
    "func name": "test_gh10880",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_result_type240.py",
    "line number": "52",
    "func name": "test_sosfilt_zi",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_rk.py",
    "line number": "22",
    "func name": "test_error_estimation",
    "func arg": "(solver_class)",
    "comments": ""
},{
    "source file": "test_rotation_groups241.py",
    "line number": "165",
    "func name": "test_single_reduction",
    "func arg": "(name)",
    "comments": ""
},{
    "source file": "test_rotation_spline242.py",
    "line number": "142",
    "func name": "test_error_handling",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_rotation243.py",
    "line number": "1129",
    "func name": "test_rotation_within_numpy_array",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_round.py",
    "line number": "14",
    "func name": "test_add_round_down",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_savitzky_golay244.py",
    "line number": "262",
    "func name": "test_sg_filter_interp_edges_3d",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_scipy_version245.py",
    "line number": "7",
    "func name": "test_valid_scipy_version",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_sf_error.py",
    "line number": "106",
    "func name": "test_errstate_all_but_one",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_shortest_path246.py",
    "line number": "321",
    "func name": "test_sparse_matrices",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_sici.py",
    "line number": "22",
    "func name": "test_shichi_consistency",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_signaltools247.py",
    "line number": "3112",
    "func name": "test_nonnumeric_dtypes",
    "func arg": "(func)",
    "comments": ""
},{
    "source file": "test_slerp248.py",
    "line number": "10",
    "func name": "_generate_spherical_points",
    "func arg": "(ndim, n_pts)",
    "comments": ""
},{
    "source file": "test_solve_toeplitz.py",
    "line number": "104",
    "func name": "test_unstable",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_solvers.py",
    "line number": "657",
    "func name": "test_are_validate_args",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_spanning_tree249.py",
    "line number": "9",
    "func name": "test_minimum_spanning_tree",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_sparsetools250.py",
    "line number": "317",
    "func name": "test_endianness",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_special_matrices.py",
    "line number": "628",
    "func name": "test_fiedler_companion",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_spence.py",
    "line number": "16",
    "func name": "test_special_points",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_spfun_stats.py",
    "line number": "42",
    "func name": "test_multigammaln_array_arg",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_sph_harm.py",
    "line number": "6",
    "func name": "test_first_harmonics",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_spherical_voronoi253.py",
    "line number": "90",
    "func name": "_sample_sphere",
    "func arg": "(n, dim, seed)",
    "comments": ""
},{
    "source file": "test_splines.py",
    "line number": "56",
    "func name": "test_spline_filter_vs_matrix_solution",
    "func arg": "(order, mode)",
    "comments": ""
},{
    "source file": "test_stats255.py",
    "line number": "4481",
    "func name": "test_binomtest3",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_streams.py",
    "line number": "62",
    "func name": "test_read",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_tmpdirs.py",
    "line number": "32",
    "func name": "test_given_directory",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_traversal256.py",
    "line number": "59",
    "func name": "test_graph_depth_first_trivial_graph",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_trig.py",
    "line number": "55",
    "func name": "test_zero_sign",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_trustregion_exact.py",
    "line number": "18",
    "func name": "random_entry",
    "func arg": "(n, min_eig, max_eig, case)",
    "comments": ""
},{
    "source file": "test_tukeylambda_stats257.py",
    "line number": "77",
    "func name": "test_tukeylambda_stats_invalid",
    "func arg": "()",
    "comments": "Test values of lambda outside the domains of the functions.\n\n\n"
},{
    "source file": "test_upfirdn258.py",
    "line number": "47",
    "func name": "upfirdn_naive",
    "func arg": "(x, h, up, down)",
    "comments": "Naive upfirdn processing in Python.\n\nNote: arg order (x, h) differs to facilitate apply_along_axis use.\n"
},{
    "source file": "test_utils259.py",
    "line number": "7",
    "func name": "test_make_system_bad_shape",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_warnings.py",
    "line number": "105",
    "func name": "test_warning_calls_stacklevels",
    "func arg": "(warning_calls)",
    "comments": ""
},{
    "source file": "test_waveforms260.py",
    "line number": "35",
    "func name": "compute_frequency",
    "func arg": "(t, theta)",
    "comments": "Compute theta'(t)/(2*pi), where theta'(t) is the derivative of theta(t).\n\n\n"
},{
    "source file": "test_wavfile.py",
    "line number": "179",
    "func name": "test_write_roundtrip",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_windows262.py",
    "line number": "636",
    "func name": "test_deprecated_pickleable",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_wrightomega.py",
    "line number": "114",
    "func name": "test_wrightomega_real_versus_complex",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test_zeros.py",
    "line number": "740",
    "func name": "test_gh9551_raise_error_if_disp_true",
    "func arg": "()",
    "comments": "Test that if disp is true then zero derivative raises RuntimeError\n\n\n"
},{
    "source file": "test_zeta.py",
    "line number": "46",
    "func name": "test_riemann_zeta_avoid_overflow",
    "func arg": "()",
    "comments": ""
},{
    "source file": "test263.py",
    "line number": "41",
    "func name": "test_psolveq_t",
    "func arg": "(x, b, which, n)",
    "comments": ""
},{
    "source file": "tnc.py",
    "line number": "281",
    "func name": "_minimize_tnc",
    "func arg": "(fun, x0, args, jac, bounds, eps, scale, offset, mesg_num, maxCGit, maxiter, eta, stepmx, accuracy, minfev, ftol, xtol, gtol, rescale, disp, callback, finite_diff_rel_step, maxfun, **unknown_options)",
    "comments": "Minimize a scalar function of one or more variables using a truncated Newton (TNC) algorithm.\n\nOptions ------- eps : float or ndarray If `jac is None` the absolute step size used for numerical approximation of the jacobian via forward differences. scale : list of floats Scaling factors to apply to each variable. If None, the factors are up-low for interval bounded variables and 1+|x] fo the others. Defaults to None. offset : float Value to subtract from each variable. If None, the offsets are (up+low)/2 for interval bounded variables and x for the others. disp : bool Set to True to print convergence messages. maxCGit : int Maximum number of hessian*vector evaluations per main iteration. If maxCGit == 0, the direction chosen is -gradient if maxCGit < 0, maxCGit is set to max(1,min(50,n/2)). Defaults to -1. maxiter : int, optional Maximum number of function evaluations. This keyword is deprecated in favor of `maxfun`. Only if `maxfun` is None is this keyword used. eta : float Severity of the line search. If < 0 or > 1, set to 0.25. Defaults to -1. stepmx : float Maximum step for the line search. May be increased during call. If too small, it will be set to 10.0. Defaults to 0. accuracy : float Relative precision for finite difference calculations. If <= machine_precision, set to sqrt(machine_precision). Defaults to 0. minfev : float Minimum function value estimate. Defaults to 0. ftol : float Precision goal for the value of f in the stopping criterion. If ftol < 0.0, ftol is set to 0.0 defaults to -1. xtol : float Precision goal for the value of x in the stopping criterion (after applying x scaling factors). If xtol < 0.0, xtol is set to sqrt(machine_precision). Defaults to -1. gtol : float Precision goal for the value of the projected gradient in the stopping criterion (after applying x scaling factors). If gtol < 0.0, gtol is set to 1e-2 * sqrt(accuracy). Setting it to 0.0 is not recommended. Defaults to -1. rescale : float Scaling factor (in log10) used to trigger f value rescaling.\n\nIf 0, rescale at each iteration.\n\nIf a large value, never rescale.\n\nIf < 0, rescale is set to 1.3. finite_diff_rel_step : None or array_like, optional If `jac in ['2-point', '3-point', 'cs']` the relative step size to use for numerical approximation of the jacobian. The absolute step size is computed as ``h = rel_step * sign(x0) * max(1, abs(x0))``, possibly adjusted to fit into the bounds. For ``method='3-point'`` the sign of `h` is ignored. If None (default) then step is selected automatically. maxfun : int Maximum number of function evaluations. If None, `maxfun` is set to max(100, 10*len(x0)). Defaults to None.\n"
},{
    "source file": "tr_interior_point.py",
    "line number": "266",
    "func name": "tr_interior_point",
    "func arg": "(fun, grad, lagr_hess, n_vars, n_ineq, n_eq, constr, jac, x0, fun0, grad0, constr_ineq0, jac_ineq0, constr_eq0, jac_eq0, stop_criteria, enforce_feasibility, xtol, state, initial_barrier_parameter, initial_tolerance, initial_penalty, initial_trust_radius, factorization_method)",
    "comments": "Trust-region interior points method.\n\nSolve problem: minimize fun(x) subject to: constr_ineq(x) <= 0 constr_eq(x) = 0 using trust-region interior point method described in [1]_.\n"
},{
    "source file": "trf_linear.py",
    "line number": "143",
    "func name": "trf_linear",
    "func arg": "(A, b, x_lsq, lb, ub, tol, lsq_solver, lsmr_tol, max_iter, verbose)",
    "comments": ""
},{
    "source file": "trf.py",
    "line number": "401",
    "func name": "trf_no_bounds",
    "func arg": "(fun, jac, x0, f0, J0, ftol, xtol, gtol, max_nfev, x_scale, loss_function, tr_solver, tr_options, verbose)",
    "comments": ""
},{
    "source file": "unicode-check.py",
    "line number": "17",
    "func name": "unicode_check",
    "func arg": "(showall)",
    "comments": "If showall is True, all non-ASCII characters are displayed.\n\n\n"
},{
    "source file": "utils.py",
    "line number": "12",
    "func name": "lagrange_inversion",
    "func arg": "(a)",
    "comments": "Given a series\n\nf(x) = a[1]*x + a[2]*x**2 + ... + a[n-1]*x**(n\n\n- 1),\n\nuse the Lagrange inversion formula to compute a series\n\ng(x) = b[1]*x + b[2]*x**2 + ... + b[n-1]*x**(n\n\n- 1)\n\nso that f(g(x)) = g(f(x)) = x mod x**n. We must have a[0] = 0, so necessarily b[0] = 0 too.\n\nThe algorithm is naive and could be improved, but speed isn't an issue here and it's easy to read.\n"
},{
    "source file": "utils264.py",
    "line number": "32",
    "func name": "make_system",
    "func arg": "(A, M, x0, b)",
    "comments": "Make a linear system Ax=b\n\nParameters ---------- A : LinearOperator sparse or dense matrix (or any valid input to aslinearoperator) M : {LinearOperator, Nones} preconditioner sparse or dense matrix (or any valid input to aslinearoperator) x0 : {array_like, None} initial guess to iterative method b : array_like right hand side\n##### Returns\n* **(A, M, x, b, postprocess)\n    A **: LinearOperator\n        matrix of the linear system\n    M\n\n"
},{
    "source file": "vq.py",
    "line number": "588",
    "func name": "kmeans2",
    "func arg": "(data, k, iter, thresh, minit, missing, check_finite)",
    "comments": "Classify a set of observations into k clusters using the k-means algorithm.\n\nThe algorithm attempts to minimize the Euclidean distance between observations and centroids. Several initialization methods are included.\n\nParameters ---------- data : ndarray A 'M' by 'N' array of 'M' observations in 'N' dimensions or a length 'M' array of 'M' 1-D observations. k : int or ndarray The number of clusters to form as well as the number of centroids to generate. If `minit` initialization string is 'matrix', or if a ndarray is given instead, it is interpreted as initial cluster to use instead. iter : int, optional Number of iterations of the k-means algorithm to run. Note that this differs in meaning from the iters parameter to the kmeans function. thresh : float, optional (not used yet) minit : str, optional Method for initialization. Available methods are 'random', 'points', '++' and 'matrix':\n\n'random': generate k centroids from a Gaussian with mean and variance estimated from the data.\n\n'points': choose k observations (rows) at random from data for the initial centroids.\n\n'++': choose k observations accordingly to the kmeans++ method (careful seeding)\n\n'matrix': interpret the k parameter as a k by M (or length k array for 1-D data) array of initial centroids. missing : str, optional Method to deal with empty clusters. Available methods are 'warn' and 'raise':\n\n'warn': give a warning and continue.\n\n'raise': raise an ClusterError and terminate the algorithm. check_finite : bool, optional Whether to check that the input matrices contain only finite numbers. Disabling may give a performance gain, but may result in problems (crashes, non-termination) if the inputs do contain infinities or NaNs. Default: True\n##### Returns\n* **centroid **: ndarray\n    A 'k' by 'N' array of centroids found at the last iteration of\n    k-means.\n\n* **label **: ndarray\n    label[i] is the code or index of the centroid the\n    ith observation is closest to.\n\n* **.. [1] D. Arthur and S. Vassilvitskii, \"k-means++**: the advantages of\n   careful seeding\", Proceedings of the Eighteenth Annual ACM-SIAM Symposium\n   on Discrete Algorithms, 2007.\n\n* **>>> plt.plot(w0[**: , 0], w0[\n\n* **>>> plt.plot(w1[**: , 0], w1[\n\n* **>>> plt.plot(w2[**: , 0], w2[\n\n* **>>> plt.plot(centroid[**: , 0], centroid[\n\n"
},{
    "source file": "waveforms265.py",
    "line number": "579",
    "func name": "unit_impulse",
    "func arg": "(shape, idx, dtype)",
    "comments": "Unit impulse signal (discrete delta function) or unit basis vector.\n\nParameters ---------- shape : int or tuple of int Number of samples in the output (1-D), or a tuple that represents the shape of the output (N-D). idx : None or int or tuple of int or 'mid', optional Index at which the value is 1.\n\nIf None, defaults to the 0th element. If ``idx='mid'``, the impulse will be centered at ``shape // 2`` in all dimensions.\n\nIf an int, the impulse will be at `idx` in all dimensions. dtype : data-type, optional The desired data-type for the array, e.g., ``numpy.int8``.\n\nDefault is ``numpy.float64``.\n##### Returns\n* **y **: ndarray\n    Output array containing an impulse signal.\n\n* **.. versionadded**: \n\n* **An impulse at the 0th element (**: math\n\n* **Impulse offset by 2 samples (**: math\n\n* **2-dimensional impulse, centered**: \n\n* **Impulse at (2, 2), using broadcasting**: \n\n* **Plot the impulse response of a 4th-order Butterworth lowpass filter**: \n\n"
},{
    "source file": "wavelets266.py",
    "line number": "389",
    "func name": "cwt",
    "func arg": "(data, wavelet, widths, dtype, **kwargs)",
    "comments": "Continuous wavelet transform.\n\nPerforms a continuous wavelet transform on `data`, using the `wavelet` function. A CWT performs a convolution with `data` using the `wavelet` function, which is characterized by a width parameter and length parameter. The `wavelet` function is allowed to be complex.\n\nParameters ---------- data : (N,) ndarray data on which to perform the transform. wavelet : function Wavelet function, which should take 2 arguments. The first argument is the number of points that the returned vector will have (len(wavelet(length,width)) == length). The second is a width parameter, defining the size of the wavelet (e.g. standard deviation of a gaussian). See `ricker`, which satisfies these requirements. widths : (M,) sequence Widths to use for transform. dtype : data-type, optional The desired data type of output. Defaults to ``float64`` if the output of `wavelet` is real and ``complex128`` if it is complex.\n\n.. versionadded:: 1.4.0\n\nkwargs Keyword arguments passed to wavelet function.\n\n.. versionadded:: 1.4.0\n##### Returns\n* **cwt**: (M, N) ndarray\n    Will have shape of (len(widths), len(data)).\n\n* **.. versionadded**: \n\n* ****: \n\n"
},{
    "source file": "wavfile.py",
    "line number": "771",
    "func name": "_array_tofile",
    "func arg": "(fid, data)",
    "comments": ""
},{
    "source file": "windows267.py",
    "line number": "2020",
    "func name": "get_window",
    "func arg": "(window, Nx, fftbins)",
    "comments": "Return a window of a given length and type.\n\nParameters ---------- window : string, float, or tuple The type of window to create. See below for more details. Nx : int The number of samples in the window. fftbins : bool, optional If True (default), create a \"periodic\" window, ready to use with `ifftshift` and be multiplied by the result of an FFT (see also :func:`~scipy.fft.fftfreq`). If False, create a \"symmetric\" window, for use in filter design.\n##### Returns\n* **Window types**: \n\n"
},{
    "source file": "wrightomega.py",
    "line number": "25",
    "func name": "main",
    "func arg": "()",
    "comments": ""
},{
    "source file": "zeros.py",
    "line number": "1243",
    "func name": "toms748",
    "func arg": "(f, a, b, args, k, xtol, rtol, maxiter, full_output, disp)",
    "comments": "Find a zero using TOMS Algorithm 748 method.\n\nImplements the Algorithm 748 method of Alefeld, Potro and Shi to find a zero of the function `f` on the interval `[a , b]`, where `f(a)` and `f(b)` must have opposite signs.\n\nIt uses a mixture of inverse cubic interpolation and \"Newton-quadratic\" steps. [APS1995].\n\nParameters ---------- f : function Python function returning a scalar. The function :math:`f` must be continuous, and :math:`f(a)` and :math:`f(b)` have opposite signs. a : scalar, lower boundary of the search interval b : scalar, upper boundary of the search interval args : tuple, optional containing extra arguments for the function `f`. `f` is called by ``f(x, *args)``. k : int, optional The number of Newton quadratic steps to perform each iteration. ``k>=1``. xtol : scalar, optional The computed root ``x0`` will satisfy ``np.allclose(x, x0, atol=xtol, rtol=rtol)``, where ``x`` is the exact root. The parameter must be nonnegative. rtol : scalar, optional The computed root ``x0`` will satisfy ``np.allclose(x, x0, atol=xtol, rtol=rtol)``, where ``x`` is the exact root. maxiter : int, optional If convergence is not achieved in `maxiter` iterations, an error is raised. Must be >= 0. full_output : bool, optional If `full_output` is False, the root is returned. If `full_output` is True, the return value is ``(x, r)``, where `x` is the root, and `r` is a `RootResults` object. disp : bool, optional If True, raise RuntimeError if the algorithm didn't converge. Otherwise, the convergence status is recorded in the `RootResults` return object.\n##### Returns\n* **x0 **: float\n    Approximate Zero of `f`\n\n* **r **: `RootResults` (present if ``full_output = True``)\n    Object containing information about the convergence. In particular,\n    ``r.converged`` is True if the routine converged.\n\n* **fsolve **: find zeroes in N dimensions.\n\n* **.. [APS1995]\n   Alefeld, G. E. and Potra, F. A. and Shi, Yixun,\n   *Algorithm 748**: Enclosing Zeros of Continuous Functions*,\n   ACM Trans. Math. Softw. Volume 221(1995)\n   doi = {10.1145/210089.210111}\n\n* **>>> def f(x)**: \n\n* **>>> results\n      converged**: True\n           flag\n\n"
},{
    "source file": "zetac.py",
    "line number": "18",
    "func name": "main",
    "func arg": "()",
    "comments": ""
}]
}