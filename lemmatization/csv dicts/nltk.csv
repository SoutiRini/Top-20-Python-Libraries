0,"{'func name': 'demo', 'comments': ""A demonstration of the result of aligning phonetic sequences used in Kondrak's (2002) dissertation.\n\n\n"", 'stemmed comments': ['s', 'demonstr', 'dissert', 'kondrak', 'A', '2002', 'phonet', 'result', 'align', 'sequenc', 'use']}"
1,"{'func name': 'additional_tests', 'comments': '', 'stemmed comments': []}"
2,"{'func name': '_weighted_choice', 'comments': 'Like random.choice, but with weights.\n\nHeavily inspired by python 3.6 `random.choices`.\n', 'stemmed comments': ['weight', 'python', '36', 'inspir', 'heavili', 'like', 'randomchoic']}"
3,"{'func name': '_check_alignment', 'comments': 'Check whether the alignments are legal.\n\nparam num_words: the number of source language words :type num_words: int :param num_mots: the number of target language words :type num_mots: int :param alignment: alignment to be checked :type alignment: Alignment :raise IndexError: if alignment falls outside the sentence\n', 'stemmed comments': ['word', 'target', 'sourc', 'number', 'int', 'languag', 'align', 'num_word', 'fall', 'outsid', 'check', 'whether', 'rais', 'sentenc', 'legal', 'type', 'indexerror', 'num_mot', 'param']}"
4,"{'func name': 'babelize_shell', 'comments': '', 'stemmed comments': []}"
5,"{'func name': 'brevity_penalty', 'comments': ""Calculate brevity penalty.\n\nAs the modified n-gram precision still has the problem from the short length sentence, brevity penalty is used to modify the overall BLEU score according to length.\n\nAn example from the paper. There are three references with length 12, 15 and 17. And a concise hypothesis of the length 12. The brevity penalty is 1.\n\n>>> reference1 = list('aaaaaaaaaaaa')\n\n\n\n\n\n# i.e. ['a'] * 12 >>> reference2 = list('aaaaaaaaaaaaaaa')\n\n # i.e. ['a'] * 15 >>> reference3 = list('aaaaaaaaaaaaaaaaa') # i.e. ['a'] * 17 >>> hypothesis = list('aaaaaaaaaaaa')\n\n\n\n\n\n# i.e. ['a'] * 12 >>> references = [reference1, reference2, reference3] >>> hyp_len = len(hypothesis) >>> closest_ref_len =\n\nclosest_ref_length(references, hyp_len) >>> brevity_penalty(closest_ref_len, hyp_len) 1.0\n\nIn case a hypothesis translation is shorter than the references, penalty is applied.\n\n>>> references = [['a'] * 28, ['a'] * 28] >>> hypothesis = ['a'] * 12 >>> hyp_len = len(hypothesis) >>> closest_ref_len =\n\nclosest_ref_length(references, hyp_len) >>> brevity_penalty(closest_ref_len, hyp_len) 0.2635971381157267\n\nThe length of the closest reference is used to compute the penalty. If the length of a hypothesis is 12, and the reference lengths are 13 and 2, the penalty is applied because the hypothesis length (12) is less then the closest reference length (13).\n\n>>> references = [['a'] * 13, ['a'] * 2] >>> hypothesis = ['a'] * 12 >>> hyp_len = len(hypothesis) >>> closest_ref_len =\n\nclosest_ref_length(references, hyp_len) >>> brevity_penalty(closest_ref_len, hyp_len) # doctest: +ELLIPSIS 0.9200...\n\nThe brevity penalty doesn't depend on reference order. More importantly, when two reference sentences are at the same distance, the shortest reference sentence length is used.\n\n>>> references = [['a'] * 13, ['a'] * 11] >>> hypothesis = ['a'] * 12 >>> hyp_len = len(hypothesis) >>> closest_ref_len =\n\nclosest_ref_length(references, hyp_len) >>> bp1 = brevity_penalty(closest_ref_len, hyp_len) >>> hyp_len = len(hypothesis) >>> closest_ref_len =\n\nclosest_ref_length(reversed(references), hyp_len) >>> bp2 = brevity_penalty(closest_ref_len, hyp_len) >>> bp1 == bp2 == 1 True\n\nA test example from mteval-v13a.pl (starting from the line 705):\n\n>>> references = [['a'] * 11, ['a'] * 8] >>> hypothesis = ['a'] * 7 >>> hyp_len = len(hypothesis) >>> closest_ref_len =\n\nclosest_ref_length(references, hyp_len) >>> brevity_penalty(closest_ref_len, hyp_len) # doctest: +ELLIPSIS 0.8668...\n\n>>> references = [['a'] * 11, ['a'] * 8, ['a'] * 6, ['a'] * 7] >>> hypothesis = ['a'] * 7 >>> hyp_len = len(hypothesis) >>> closest_ref_len =\n\nclosest_ref_length(references, hyp_len) >>> brevity_penalty(closest_ref_len, hyp_len) 1.0\n\n:param hyp_len: The length of the hypothesis for a single sentence OR the sum of all the hypotheses' lengths for a corpus :type hyp_len: int :param closest_ref_len: The length of the closest reference for a single hypothesis OR the sum of all the closest references for every hypotheses. :type closest_ref_len: int :return: BLEU's brevity penalty. :rtype: float\n"", 'stemmed comments': ['closest_ref_len', 'nt', 'comput', 'doctest', '8', 'breviti', 'modifi', 'use', 'overal', '705', 'ellipsi', 'hypothesi', 'singl', 'sentenc', '7', '6', 'type', 'line', 'reference3', 'short', 'closest_ref_length', 'true', 'return', 'As', 'mtevalv13apl', 'three', 'exampl', '10', 'float', '09200', 'brevity_penalti', 'there', 'An', 'hyp_len', 'In', '02635971381157267', 'importantli', 'and', '2', '=', 'shorter', '15', 'reference2', 'less', 'concis', 'the', 'revers', 'distanc', 's', '1', 'everi', '==', 'corpu', '11', 'If', 'bleu', 'OR', 'aaaaaaaaaaaa', 'hypothes', 'start', 'penalti', 'score', 'two', 'refer', 'closest', ']', 'accord', 'shortest', 'appli', 'aaaaaaaaaaaaaaa', '17', 'still', 'reference1', '08668', 'case', 'ngram', 'problem', 'aaaaaaaaaaaaaaaaa', 'len', 'length', '28', '>', '13', 'int', 'test', 'bp1', 'rtype', 'depend', 'paper', 'sum', 'calcul', 'order', 'A', 'bp2', 'translat', 'list', 'param', 'precis', '[', 'more', 'ie', '12']}"
6,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
7,"{'func name': '_all_xmlwords_in', 'comments': '', 'stemmed comments': []}"
8,"{'func name': 'sents', 'comments': '', 'stemmed comments': []}"
9,"{'func name': 'describe_template_sets', 'comments': 'Print the available template sets in this demo, with a short description""\n\n\n', 'stemmed comments': ['set', 'avail', 'demo', 'descript', 'templat', 'short', 'print']}"
10,"{'func name': 'casual_tokenize', 'comments': 'Convenience function for wrapping the tokenizer.\n\n\n', 'stemmed comments': ['wrap', 'conveni', 'token', 'function']}"
11,"{'func name': 'demo3', 'comments': '', 'stemmed comments': []}"
12,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
13,"{'func name': 'demo', 'comments': 'A demonstration of the chart parsers.\n\n\n', 'stemmed comments': ['chart', 'A', 'parser', 'demonstr']}"
14,"{'func name': 'app', 'comments': '', 'stemmed comments': []}"
15,"{'func name': 'test', 'comments': '', 'stemmed comments': []}"
16,"{'func name': 'sql_demo', 'comments': ""Print out every row from the 'city.db' database.\n\n\n"", 'stemmed comments': ['citydb', 'databas', 'everi', 'print', 'row']}"
17,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
18,"{'func name': 'demo', 'comments': 'The CHILDES corpus should be manually downloaded and saved to ``[NLTK_Data_Dir]/corpora/childes/``\n\n\n', 'stemmed comments': [']', '[', 'nltk_data_dir', '/corpora/childes/', 'child', 'manual', 'the', 'download', 'corpu', 'save']}"
19,"{'func name': 'generate_chomsky', 'comments': '', 'stemmed comments': []}"
20,"{'func name': 'corpus_chrf', 'comments': ""Calculates the corpus level CHRF (Character n-gram F-score), it is the macro-averaged value of the sentence/segment level CHRF score.\n\nThis implementation of CHRF only supports a single reference at the moment.\n\n>>> ref1 = str('It is a guide to action that ensures that the military ' ...\n\n\n\n\n\n\n\n\n\n\n\n'will forever heed Party commands').split() >>> ref2 = str('It is the guiding principle which guarantees the military ' ...\n\n\n\n\n\n\n\n\n\n\n\n'forces always being under the command of the Party').split() >>> >>> hyp1 = str('It is a guide to action which ensures that the military ' ...\n\n\n\n\n\n\n\n\n\n\n\n'always obeys the commands of the party').split() >>> hyp2 = str('It is to insure the troops forever hearing the activity ' ...\n\n\n\n\n\n\n\n\n\n\n\n'guidebook that party direct') >>> corpus_chrf([ref1, ref2, ref1, ref2], [hyp1, hyp2, hyp2, hyp1]) # doctest: +ELLIPSIS 0.3910...\n\n:param references: a corpus of list of reference sentences, w.r.t. hypotheses :type references: list(list(str)) :param hypotheses: a list of hypothesis sentences :type hypotheses: list(list(str)) :param min_len: The minimum order of n-gram this function should extract. :type min_len: int :param max_len: The maximum order of n-gram this function should extract. :type max_len: int :param beta: the parameter to assign more importance to recall over precision :type beta: float :param ignore_whitespace: ignore whitespace characters in scoring :type ignore_whitespace: bool :return: the sentence level CHRF score. :rtype: float\n"", 'stemmed comments': ['beta', 'heed', 'doctest', 'activ', 'assign', 'charact', 'ellipsi', 'moment', 'hypothesi', 'singl', 'sentenc', 'will', 'type', 'command', 'hear', 'thi', 'min_len', 'return', 'wrt', 'split', 'float', 'corpus_chrf', 'principl', 'direct', 'ensur', 'import', 'recal', '03910', 'action', 'maximum', 'parti', '=', 'forc', 'guidebook', 'hyp1', 'whitespac', 'the', 'It', 'macroaverag', 'guid', 'ignor', 'corpu', 'str', 'function', 'hypothes', 'ref2', 'forev', 'score', 'refer', 'fscore', 'ref1', 'minimum', 'support', ']', 'troop', 'guarante', 'sentence/seg', 'implement', 'militari', 'ngram', 'chrf', 'bool', 'obey', '>', 'int', 'max_len', 'level', 'rtype', 'hyp2', 'calcul', 'order', 'paramet', 'extract', 'alway', 'list', 'ignore_whitespac', 'valu', 'precis', '[', 'insur', 'param']}"
21,"{'func name': 'app', 'comments': '', 'stemmed comments': []}"
22,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
23,"{'func name': 'tokenize_file', 'comments': 'This command tokenizes text stream using nltk.word_tokenize\n\n\n', 'stemmed comments': ['text', 'command', 'stream', 'nltkword_token', 'token', 'thi', 'use']}"
24,"{'func name': 'read_cmudict_block', 'comments': '', 'stemmed comments': []}"
25,"{'func name': 'app', 'comments': '', 'stemmed comments': []}"
26,"{'func name': 'demo', 'comments': 'Finds bigram collocations in the files of the WebText corpus.\n\n\n', 'stemmed comments': ['file', 'bigram', 'webtext', 'find', 'corpu', 'colloc']}"
27,"{'func name': 'backwardTConstraint', 'comments': '', 'stemmed comments': []}"
28,"{'func name': '_write_to_file', 'comments': '', 'stemmed comments': []}"
29,"{'func name': 'py3_data', 'comments': '', 'stemmed comments': []}"
30,"{'func name': 'app', 'comments': '', 'stemmed comments': []}"
31,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
32,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
33,"{'func name': 'teardown_module', 'comments': '', 'stemmed comments': []}"
34,"{'func name': '_open', 'comments': 'Helper function that returns an open file object for a resource, given its resource URL.  If the given resource URL uses the ""nltk:"" protocol, or uses no protocol, then use ``nltk.data.find`` to find its path, and open it with the given mode; if the resource URL uses the \'file\' protocol, then open the file with the given mode; otherwise, delegate to ``urllib2.urlopen``.\n\ntype resource_url: str :param resource_url: A URL specifying where the resource should be loaded from.\n\nThe default protocol is ""nltk:"", which searches for the file in the the NLTK data package.\n', 'stemmed comments': ['return', 'file', 'search', 'open', 'specifi', 'nltk', 'mode', 'If', 'nltkdatafind', 'str', ';', 'object', 'function', 'helper', 'given', 'otherwis', 'default', 'use', 'url', 'protocol', 'urllib2urlopen', 'resource_url', 'A', 'deleg', 'data', 'type', 'packag', 'load', 'resourc', 'find', 'path', 'the', 'param']}"
35,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
36,"{'func name': 'memoize', 'comments': '', 'stemmed comments': []}"
37,"{'func name': 'corpus_size', 'comments': '', 'stemmed comments': []}"
38,"{'func name': 'cycle_finding_demo', 'comments': '', 'stemmed comments': []}"
39,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
40,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
41,"{'func name': 'dispersion_plot', 'comments': 'Generate a lexical dispersion plot.\n\nparam text: The source text :type text: list(str) or enum(str) :param words: The target words :type words: list of str :param ignore_case: flag to set if case should be ignored when searching text :type ignore_case: bool\n', 'stemmed comments': ['text', 'search', 'word', 'case', 'ignor', 'dispers', 'gener', 'bool', 'target', 'sourc', 'enum', 'str', 'set', 'flag', 'plot', 'lexic', 'list', 'type', 'ignore_cas', 'the', 'param']}"
42,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
43,"{'func name': 'update', 'comments': '', 'stemmed comments': []}"
44,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
45,"{'func name': 'test_draw', 'comments': '', 'stemmed comments': []}"
46,"{'func name': 'demo', 'comments': 'A demonstration of the Earley parsers.\n\n\n', 'stemmed comments': ['earley', 'A', 'parser', 'demonstr']}"
47,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
48,"{'func name': 'demo', 'comments': 'Non-interactive demonstration of the clusterers with simple 2-D data.\n\n\n', 'stemmed comments': ['cluster', 'demonstr', 'noninteract', 'data', '2D', 'simpl']}"
49,"{'func name': 'error_list', 'comments': 'Returns a list of human-readable strings indicating the errors in the given tagging of the corpus.\n\nparam train_sents: The correct tagging of the corpus :type train_sents: list(tuple) :param test_sents: The tagged corpus :type test_sents: list(tuple)\n', 'stemmed comments': ['return', 'indic', 'type', 'tag', 'train_sent', 'correct', 'string', 'given', 'tupl', 'the', 'test_sent', 'corpu', 'error', 'humanread', 'list', 'param']}"
50,"{'func name': 'demo', 'comments': 'Run exists demos.\n\n- num = 1: propositional logic demo\n\n- num = 2: first order model demo (only if trace is set)\n\n- num = 3: first order sentences demo\n\n- num = 4: satisfaction of open formulas demo\n\n- any other value: run all the demos\n\n:param trace: trace = 1, or trace = 2 for more verbose tracing\n', 'stemmed comments': ['1', '4', 'model', 'verbos', 'open', 'formula', 'satisfact', 'set', 'exist', '3', 'first', 'num', 'order', 'trace', 'run', 'proposit', 'sentenc', '2', '=', 'valu', 'demo', 'logic', 'param']}"
51,"{'func name': 'demo', 'comments': 'Just for testing\n\n\n', 'stemmed comments': ['test', 'just']}"
52,"{'func name': 'run_profile', 'comments': '', 'stemmed comments': []}"
53,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
54,"{'func name': 'demo', 'comments': 'Non-interactive demonstration of the clusterers with simple 2-D data.\n\n\n', 'stemmed comments': ['cluster', 'demonstr', 'noninteract', 'data', '2D', 'simpl']}"
55,"{'func name': 'parse_token_stream', 'comments': 'Parses a stream of tokens and splits it into sentences (using C{soft_delimiter} tokens) and blocks (using C{hard_delimiter} tokens) for use with the L{align_texts} function.\n\n\n', 'stemmed comments': ['stream', 'C', 'pars', 'soft_delimit', 'token', 'function', 'L', '{', 'align_text', 'sentenc', 'block', 'split', '}', 'use', 'hard_delimit']}"
56,"{'func name': 'grow_diag_final_and', 'comments': 'This module symmetrisatizes the source-to-target and target-to-source word alignment output and produces, aka. GDFA algorithm (Koehn, 2005).\n\nStep 1: Find the intersection of the bidirectional alignment.\n\nStep 2: Search for additional neighbor alignment points to be added, given these criteria: (i) neighbor alignments points are not in the intersection and (ii) neighbor alignments are in the union.\n\nStep 3: Add all other alignment points thats not in the intersection, not in the neighboring alignments that met the criteria but in the original foward/backward alignment outputs.\n\n>>> forw = (\'0-0 2-1 9-2 21-3 10-4 7-5 11-6 9-7 12-8 1-9 3-10 \' ...\n\n\n\n\n\n\n\n \'4-11 17-12 17-13 25-14 13-15 24-16 11-17 28-18\') >>> back = (\'0-0 1-9 2-9 3-10 4-11 5-12 6-6 7-5 8-6 9-7 10-4 \' ...\n\n\n\n\n\n\n\n \'11-6 12-8 13-12 15-12 17-13 18-13 19-12 20-13 \' ...\n\n\n\n\n\n\n\n \'21-3 22-12 23-14 24-17 25-15 26-17 27-18 28-18\') >>> srctext = (""この よう な ハロー 白色 わい 星 の Ｌ 関数 "" ...\n\n\n\n\n\n\n\n\n\n\n\n""は Ｌ と 共 に 不連続 に 増加 する こと が "" ...\n\n\n\n\n\n\n\n\n\n\n\n""期待 さ れる こと を 示し た 。"") >>> trgtext = (""Therefore , we expect that the luminosity function "" ...\n\n\n\n\n\n\n\n\n\n\n\n""of such halo white dwarfs increases discontinuously "" ...\n\n\n\n\n\n\n\n\n\n\n\n""with the luminosity ."") >>> srclen = len(srctext.split()) >>> trglen = len(trgtext.split()) >>> >>> gdfa = grow_diag_final_and(srclen, trglen, forw, back) >>> gdfa == sorted(set([(28, 18), (6, 6), (24, 17), (2, 1), (15, 12), (13, 12), ...\n\n\n\n\n\n\n\n (2, 9), (3, 10), (26, 17), (25, 15), (8, 6), (9, 7), (20, ...\n\n\n\n\n\n\n\n 13), (18, 13), (0, 0), (10, 4), (13, 15), (23, 14), (7, 5), ...\n\n\n\n\n\n\n\n (25, 14), (1, 9), (17, 13), (4, 11), (11, 17), (9, 2), (22, ...\n\n\n\n\n\n\n\n 12), (27, 18), (24, 16), (21, 3), (19, 12), (17, 12), (5, ...\n\n\n\n\n\n\n\n 12), (11, 6), (12, 8)])) True\n\nReferences: Koehn, P., A. Axelrod, A. Birch, C. Callison, M. Osborne, and D. Talbot. 2005. Edinburgh System Description for the 2005 IWSLT Speech Translation Evaluation. In MT Eval Workshop.\n\n:type srclen: int :param srclen: the number of tokens in the source language :type trglen: int :param trglen: the number of tokens in the target language :type e2f: str :param e2f: the forward word alignment outputs from source-to-target language (in pharaoh output format) :type f2e: str :param f2e: the backward word alignment outputs from target-to-source language (in pharaoh output format) :rtype: set(tuple(int)) :return: the symmetrized alignment points from the GDFA algorithm\n', 'stemmed comments': ['が', 'f2e', 'た', '4', 'system', '8', 'e2f', 'search', 'ii', 'discontinu', 'する', 'edinburgh', 'MT', 'わい', 'は', '66', '星', 'srctext', 'symmetrisat', '97', '22', '1312', '19', '2818', 'output', 'expect', '1912', 'srctextsplit', 'tupl', 'trglen', '7', '不連続', 'れる', '6', 'type', 'descript', 'origin', 'thi', '23', '116', '2417', 'true', '5', 'return', '213', 'こと', 'callison', 'と', 'forward', '104', '1512', 'word', '10', 'symmetr', 'luminos', 'sourcetotarget', 'align', 'In', 'evalu', '411', 'halo', 'intersect', '1117', '512', '白色', '2005', '00', '128', 'srclen', 'modul', '25', 'algorithm', '2', 'met', '=', 'osborn', '15', '増加', '310', '20', 'speech', 'find', 'trgtext', 'targettosourc', '1712', '1', '2514', '86', 'よう', 'token', '==', '24', '27', '2416', '11', 'Ｌ', 'bidirect', 'target', '2515', '2314', 'この', 'ハロー', 'set', '3', '16', 'eval', 'str', 'function', 'languag', 'given', '1315', 'な', 'ad', 'dwarf', 'refer', 'that', '2718', 'add', 'criteria', 'white', '2617', ']', '26', '9', '14', 'produc', 'pharaoh', 'koehn', '。', 'iwslt', 'addit', '18', '17', 'gdfa', '2212', '示し', 'therefor', '29', 'axelrod', '92', 'neighbor', '75', 'D', 'foward/backward', 'の', 'format', '関数', 'forw', 'sourc', 'union', 'len', 'birch', '28', '2013', '>', '13', 'int', 'number', '1713', 'sort', 'aka', 'rtype', '1813', 'talbot', '期待', 'A', 'point', 'step', 'さ', 'trgtextsplit', '共', 'P', 'translat', 'back', '21', 'increas', 'M', 'に', 'C', '[', 'grow_diag_final_and', 'backward', 'を', '0', 'workshop', 'param', '12']}"
57,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
58,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
59,"{'func name': 'corpus_gleu', 'comments': 'Calculate a single corpus-level GLEU score (aka. system-level GLEU) for all the hypotheses and their respective references.\n\nInstead of averaging the sentence level GLEU scores (i.e. macro-average precision), Wu et al. (2016) sum up the matching tokens and the max of hypothesis and reference tokens for each sentence, then compute using the aggregate values.\n\nFrom Mike Schuster (via email): ""For the corpus, we just add up the two statistics n_match and n_all = max(n_all_output, n_all_target) for all sentences, then calculate gleu_score = n_match / n_all, so it is not just a mean of the sentence gleu scores (in our case, longer sentences count more, which I think makes sense as they are more difficult to translate).""\n\n>>> hyp1 = [\'It\', \'is\', \'a\', \'guide\', \'to\', \'action\', \'which\', ...\n\n\n\n\n\n\n\n \'ensures\', \'that\', \'the\', \'military\', \'always\', ...\n\n\n\n\n\n\n\n \'obeys\', \'the\', \'commands\', \'of\', \'the\', \'party\'] >>> ref1a = [\'It\', \'is\', \'a\', \'guide\', \'to\', \'action\', \'that\', ...\n\n\n\n\n\n\n\n\n\n\'ensures\', \'that\', \'the\', \'military\', \'will\', \'forever\', ...\n\n\n\n\n\n\n\n\n\n\'heed\', \'Party\', \'commands\'] >>> ref1b = [\'It\', \'is\', \'the\', \'guiding\', \'principle\', \'which\', ...\n\n\n\n\n\n\n\n\n\n\'guarantees\', \'the\', \'military\', \'forces\', \'always\', ...\n\n\n\n\n\n\n\n\n\n\'being\', \'under\', \'the\', \'command\', \'of\', \'the\', \'Party\'] >>> ref1c = [\'It\', \'is\', \'the\', \'practical\', \'guide\', \'for\', \'the\', ...\n\n\n\n\n\n\n\n\n\n\'army\', \'always\', \'to\', \'heed\', \'the\', \'directions\', ...\n\n\n\n\n\n\n\n\n\n\'of\', \'the\', \'party\']\n\n>>> hyp2 = [\'he\', \'read\', \'the\', \'book\', \'because\', \'he\', \'was\', ...\n\n\n\n\n\n\n\n \'interested\', \'in\', \'world\', \'history\'] >>> ref2a = [\'he\', \'was\', \'interested\', \'in\', \'world\', \'history\', ...\n\n\n\n\n\n\n\n\n\n\'because\', \'he\', \'read\', \'the\', \'book\']\n\n>>> list_of_references = [[ref1a, ref1b, ref1c], [ref2a]] >>> hypotheses = [hyp1, hyp2] >>> corpus_gleu(list_of_references, hypotheses) # doctest: +ELLIPSIS 0.5673...\n\nThe example below show that corpus_gleu() is different from averaging sentence_gleu() for hypotheses\n\n>>> score1 = sentence_gleu([ref1a], hyp1) >>> score2 = sentence_gleu([ref2a], hyp2) >>> (score1 + score2) / 2 # doctest: +ELLIPSIS 0.6144...\n\n:param list_of_references: a list of reference sentences, w.r.t. hypotheses :type list_of_references: list(list(list(str))) :param hypotheses: a list of hypothesis sentences :type hypotheses: list(list(str)) :param min_len: The minimum order of n-gram this function should extract. :type min_len: int :param max_len: The maximum order of n-gram this function should extract. :type max_len: int :return: The corpus-level GLEU score. :rtype: float\n', 'stemmed comments': ['comput', 'heed', 'doctest', 'difficult', 'score1', 'interest', 'max', 'schuster', 'use', 'ref1b', 'ellipsi', 'hypothesi', 'via', 'singl', 'sentenc', 'will', 'n_all_output', 'type', 'email', 'command', 'he', 'min_len', 'gleu_scor', 'return', 'read', '06144', 'wrt', 'exampl', 'show', 'float', 'which', 'in', 'ref1a', 'principl', 'direct', 'ensur', 'action', 'maximum', 'parti', 'score2', '=', '2', '05673', 'forc', 'n_all_target', 'be', 'hyp1', 'for', 'the', 'n_match', 'armi', 'It', 'et', 'macroaverag', 'token', 'sens', 'under', 'guid', 'histori', 'corpu', 'differ', 'str', 'aggreg', 'mean', 'of', 'corpus_gleu', 'mike', 'function', 'longer', 'hypothes', 'forev', 'score', 'two', 'think', 'make', 'refer', 'to', 'list_of_refer', 'that', 'minimum', 'respect', 'averag', 'from', 'add', 'book', 'systemlevel', ']', 'guarante', 'ref1c', '/', 'militari', 'becaus', 'sentence_gleu', 'is', 'ref2a', 'world', 'al', 'case', 'ngram', 'count', 'instead', 'obey', '>', 'int', 'max_len', 'aka', 'level', 'rtype', 'hyp2', 'sum', 'wa', 'n_all', 'calcul', 'gleu', 'corpuslevel', 'order', 'practic', 'extract', '2016', 'translat', 'alway', 'list', 'valu', 'match', 'param', 'precis', 'I', '[', 'statist', 'ie', 'Wu']}"
60,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
61,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
62,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
63,"{'func name': '_format_tagset', 'comments': '', 'stemmed comments': []}"
64,"{'func name': 'demo_bw', 'comments': '', 'stemmed comments': []}"
65,"{'func name': 'hole_readings', 'comments': '', 'stemmed comments': []}"
66,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
67,"{'func name': 'longest_target_sentence_length', 'comments': 'param sentence_aligned_corpus: Parallel corpus under consideration :type sentence_aligned_corpus: list(AlignedSent) :return: Number of words in the longest target language sentence of ``sentence_aligned_corpus``\n\n\n', 'stemmed comments': ['type', 'return', 'sentence_aligned_corpu', 'number', 'languag', 'parallel', 'word', 'aligneds', 'sentenc', 'corpu', 'longest', 'consider', 'list', 'param', 'target']}"
68,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
69,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
70,"{'func name': 'raise_unorderable_types', 'comments': '', 'stemmed comments': []}"
71,"{'func name': '_parse_args', 'comments': '', 'stemmed comments': []}"
72,"{'func name': 'register_tag', 'comments': ""Decorates a class to register it's json tag.\n\n\n"", 'stemmed comments': ['s', 'tag', 'decor', 'json', 'regist', 'class']}"
73,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
74,"{'func name': 'test', 'comments': '', 'stemmed comments': []}"
75,"{'func name': 'parseLexicon', 'comments': '', 'stemmed comments': []}"
76,"{'func name': 'demo_read_depgraph', 'comments': '', 'stemmed comments': []}"
77,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
78,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
79,"{'func name': 'compute_substitution_semantics', 'comments': '', 'stemmed comments': []}"
80,"{'func name': 'printtype', 'comments': '', 'stemmed comments': []}"
81,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
82,"{'func name': 'find_malt_model', 'comments': 'A module to find pre-trained MaltParser model.\n\n\n', 'stemmed comments': ['model', 'A', 'modul', 'find', 'maltpars', 'pretrain']}"
83,"{'func name': 'map_tag', 'comments': ""Maps the tag from the source tagset to the target tagset.\n\n>>> map_tag('en-ptb', 'universal', 'VBZ') 'VERB' >>> map_tag('en-ptb', 'universal', 'VBP') 'VERB' >>> map_tag('en-ptb', 'universal', '``') '.'\n"", 'stemmed comments': ['sourc', 'enptb', 'tag', 'vbz', 'univers', '>', 'vbp', 'verb', 'map', 'tagset', 'map_tag', 'target']}"
84,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
85,"{'func name': 'call_megam', 'comments': 'Call the ``megam`` binary with the given arguments.\n\n\n', 'stemmed comments': ['megam', 'binari', 'call', 'given', 'argument']}"
86,"{'func name': 'meteor_score', 'comments': 'Calculates METEOR score for hypothesis with multiple references as described in ""Meteor: An Automatic Metric for MT Evaluation with HighLevels of Correlation with Human Judgments"" by Alon Lavie and Abhaya Agarwal, in Proceedings of ACL. http://www.cs.cmu.edu/~alavie/METEOR/pdf/Lavie-Agarwal-2007-METEOR.pdf\n\nIn case of multiple references the best score is chosen. This method iterates over single_meteor_score and picks the best pair among all the references for a given hypothesis\n\n>>> hypothesis1 = \'It is a guide to action which ensures that the military always obeys the commands of the party\' >>> hypothesis2 = \'It is to insure the troops forever hearing the activity guidebook that party direct\'\n\n>>> reference1 = \'It is a guide to action that ensures that the military will forever heed Party commands\' >>> reference2 = \'It is the guiding principle which guarantees the military forces always being under the command of the Party\' >>> reference3 = \'It is the practical guide for the army always to heed the directions of the party\'\n\n>>> round(meteor_score([reference1, reference2, reference3], hypothesis1),4) 0.7398\n\nIf there is no words match during the alignment the method returns the score as 0. We can safely\n\nreturn a zero instead of raising a division by zero error as no match usually implies a bad translation.\n\n>>> round(meteor_score([\'this is a cat\'], \'non matching hypothesis\'),4) 0.0\n\n:param references: reference sentences :type references: list(str) :param hypothesis: a hypothesis sentence :type hypothesis: str :param preprocess: preprocessing function (default str.lower) :type preprocess: method :param stemmer: nltk.stem.api.StemmerI object (default PorterStemmer()) :type stemmer: nltk.stem.api.StemmerI or any class that implements a stem method :param wordnet: a wordnet corpus reader object (default nltk.corpus.wordnet) :type wordnet: WordNetCorpusReader :param alpha: parameter for controlling relative weights of precision and recall. :type alpha: float :param beta: parameter for controlling shape of penalty as a function of as a function of fragmentation. :type beta: float :param gamma: relative weight assigned to fragmentation penality. :type gamma: float :return: The sentence-level METEOR score. :rtype: float\n', 'stemmed comments': ['alpha', 'weight', '4', 'beta', 'chosen', 'heed', 'abhaya', 'activ', 'assign', 'divis', 'usual', 'automat', 'MT', 'wordnet', 'agarw', 'hypothesis2', 'hypothesi', 'zero', 'proceed', 'describ', 'round', 'sentenc', 'type', 'command', 'fragment', 'hear', 'reference3', 'thi', 'rel', 'error', 'return', 'preprocess', 'stem', 'meteor_scor', 'word', 'float', 'direct', 'principl', 'An', 'align', 'ensur', 'In', 'evalu', 'default', 'recal', '07398', 'action', '00', 'among', 'sentencelevel', 'shape', 'parti', '=', 'forc', 'guidebook', 'best', 'reference2', 'penal', 'the', 'hypothesis1', '//wwwcscmuedu/~alavie/meteor/pdf/lavieagarwal2007meteorpdf', 'armi', 'safe', 'It', 'lavi', 'guid', 'http', 'corpu', 'nltkcorpuswordnet', 'If', 'porterstemm', 'str', 'acl', 'object', 'function', 'given', 'metric', 'stemmer', 'pair', 'forev', 'penalti', 'score', 'non', 'refer', 'rais', 'bad', ']', 'gamma', 'troop', 'guarante', 'multipl', 'pick', 'correl', 'impli', 'implement', 'meteor', 'militari', 'strlower', 'judgment', 'cat', 'alon', 'reference1', 'case', 'method', 'obey', 'highlevel', '>', 'instead', 'single_meteor_scor', 'rtype', 'reader', 'calcul', 'We', 'practic', 'class', 'control', 'paramet', 'translat', 'human', 'alway', 'list', 'iter', 'match', 'precis', '[', '0', 'nltkstemapistemmeri', 'insur', 'param', 'wordnetcorpusread']}"
87,"{'func name': 'alignment_error_rate', 'comments': 'Return the Alignment Error Rate (AER) of an alignment with respect to a ""gold standard"" reference alignment. Return an error rate between 0.0 (perfect alignment) and 1.0 (no alignment).\n\n>>> from nltk.translate import Alignment >>> ref = Alignment([(0, 0), (1, 1), (2, 2)]) >>> test = Alignment([(0, 0), (1, 2), (2, 1)]) >>> alignment_error_rate(ref, test) # doctest: +ELLIPSIS 0.6666666666666667\n\n:type reference: Alignment :param reference: A gold standard alignment (sure alignments) :type hypothesis: Alignment :param hypothesis: A hypothesis alignment (aka. candidate alignments) :type possible: Alignment or None :param possible: A gold standard reference of possible alignments (defaults to *reference* if None) :rtype: float or None\n', 'stemmed comments': ['return', '1', 'ref', 'doctest', '06666666666666667', '10', 'rate', 'standard', 'float', 'none', '>', 'gold', 'test', 'align', 'aka', 'import', 'rtype', 'default', 'ellipsi', 'aer', 'refer', 'hypothesi', '00', 'A', 'candid', 'respect', '2', '=', 'nltktranslat', ']', 'type', 'perfect', '[', 'sure', 'alignment_error_r', '0', 'error', 'possibl', 'param']}"
88,"{'func name': 'xpath', 'comments': '', 'stemmed comments': []}"
89,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
90,"{'func name': 'build_model', 'comments': '', 'stemmed comments': []}"
91,"{'func name': 'app', 'comments': '', 'stemmed comments': []}"
92,"{'func name': 'nist_length_penalty', 'comments': ""Calculates the NIST length penalty, from Eq. 3 in Doddington (2002)\n\npenalty = exp( beta * log( min( len(hyp)/len(ref) , 1.0 )))\n\nwhere,\n\n`beta` is chosen to make the brevity penalty factor = 0.5 when the no. of words in the system output (hyp) is 2/3 of the average no. of words in the reference translation (ref)\n\nThe NIST penalty is different from BLEU's such that it minimize the impact of the score of small variations in the length of a translation. See Fig. 4 in\n\nDoddington (2002)\n"", 'stemmed comments': ['s', 'ref', '4', 'beta', 'chosen', 'system', 'fig', '2002', 'min', 'word', '10', 'breviti', 'differ', 'bleu', '2/3', 'Eq', 'len', '3', 'length', '/len', 'factor', 'impact', 'nist', 'penalti', 'score', 'calcul', 'make', 'refer', 'output', 'averag', 'doddington', 'exp', '=', 'translat', '05', 'see', 'small', 'log', 'hyp', 'minim', 'variat', 'the']}"
93,"{'func name': '_parse_args', 'comments': 'Wraps function arguments: if fileids not specified then function set NKJPCorpusReader paths.\n\n\n', 'stemmed comments': ['fileid', 'set', 'function', 'wrap', 'nkjpcorpusread', 'argument', 'path', 'specifi']}"
94,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
95,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
96,"{'func name': 'rule_based_demo', 'comments': '', 'stemmed comments': []}"
97,"{'func name': 'demo', 'comments': 'Demonstration of the module.\n\n\n', 'stemmed comments': ['modul', 'demonstr']}"
98,"{'func name': 'demo', 'comments': 'A demonstration of the probabilistic parsers.  The user is prompted to select which demo to run, and how many parses should be found; and then each parser is run on the same demo, and a summary of the results are displayed.\n\n\n', 'stemmed comments': ['probabilist', 'demonstr', 'select', ';', 'demo', 'pars', 'A', 'mani', 'parser', 'result', 'run', 'display', 'user', 'the', 'prompt', 'summari', 'found']}"
99,"{'func name': '_get_pretrain_model', 'comments': '', 'stemmed comments': []}"
100,"{'func name': 'phrase_extraction', 'comments': 'Phrase extraction algorithm extracts all consistent phrase pairs from a word-aligned sentence pair.\n\nThe idea is to loop over all possible source language (e) phrases and find the minimal foreign phrase (f) that matches each of them. Matching is done by identifying all alignment points for the source phrase and finding the shortest foreign phrase that includes all the foreign counterparts for the source words.\n\nIn short, a phrase alignment has to (a) contain all alignment points for all covered words (b) contain at least one alignment point\n\n>>> srctext = ""michael assumes that he will stay in the house"" >>> trgtext = ""michael geht davon aus , dass er im haus bleibt"" >>> alignment = [(0,0), (1,1), (1,2), (1,3), (2,5), (3,6), (4,9), ... (5,9), (6,7), (7,7), (8,8)] >>> phrases = phrase_extraction(srctext, trgtext, alignment) >>> for i in sorted(phrases): ...\n\n\n\nprint(i) ... ((0, 1), (0, 1), \'michael\', \'michael\') ((0, 2), (0, 4), \'michael assumes\', \'michael geht davon aus\') ((0, 2), (0, 5), \'michael assumes\', \'michael geht davon aus ,\') ((0, 3), (0, 6), \'michael assumes that\', \'michael geht davon aus , dass\') ((0, 4), (0, 7), \'michael assumes that he\', \'michael geht davon aus , dass er\') ((0, 9), (0, 10), \'michael assumes that he will stay in the house\', \'michael geht davon aus , dass er im haus bleibt\') ((1, 2), (1, 4), \'assumes\', \'geht davon aus\') ((1, 2), (1, 5), \'assumes\', \'geht davon aus ,\') ((1, 3), (1, 6), \'assumes that\', \'geht davon aus , dass\') ((1, 4), (1, 7), \'assumes that he\', \'geht davon aus , dass er\') ((1, 9), (1, 10), \'assumes that he will stay in the house\', \'geht davon aus , dass er im haus bleibt\') ((2, 3), (4, 6), \'that\', \', dass\') ((2, 3), (5, 6), \'that\', \'dass\') ((2, 4), (4, 7), \'that he\', \', dass er\') ((2, 4), (5, 7), \'that he\', \'dass er\') ((2, 9), (4, 10), \'that he will stay in the house\', \', dass er im haus bleibt\') ((2, 9), (5, 10), \'that he will stay in the house\', \'dass er im haus bleibt\') ((3, 4), (6, 7), \'he\', \'er\') ((3, 9), (6, 10), \'he will stay in the house\', \'er im haus bleibt\') ((4, 6), (9, 10), \'will stay\', \'bleibt\') ((4, 9), (7, 10), \'will stay in the house\', \'im haus bleibt\') ((6, 8), (7, 8), \'in the\', \'im\') ((6, 9), (7, 9), \'in the house\', \'im haus\') ((8, 9), (8, 9), \'house\', \'haus\')\n\n:type srctext: str :param srctext: The sentence string from the source language. :type trgtext: str :param trgtext: The sentence string from the target language. :type alignment: list(tuple) :param alignment: The word alignment outputs as list of tuples, where the first elements of tuples are the source words\' indices and second elements are the target words\' indices. This is also the output format of nltk.translate.ibm1 :rtype: list(tuple) :return: A list of tuples, each element in a list is a phrase and each phrase is a tuple made up of (i) its source location, (ii) its target location, (iii) the source phrase and (iii) the target phrase. The phrase list of tuples represents all the possible phrases extracted from the word alignments. :type max_phrase_length: int :param max_phrase_length: maximal phrase length, if 0 or not specified it is set to a length of the longer sentence (srctext or trgtext).\n', 'stemmed comments': ['4', 'foreign', '8', 'ii', 'print', 'specifi', 'iii', 'cover', 'hous', 'srctext', 'davon', 'max_phrase_length', '88', 'tupl', 'output', 'sentenc', 'nltktranslateibm1', '7', 'will', '6', 'type', 'short', 'thi', 'he', 'possibl', 'locat', '5', 'return', 'loop', 'word', '10', 'repres', 'au', 'in', 'string', 'align', 'In', '00', 'contain', 'also', '25', 'algorithm', '2', '=', 'f', 'hau', 'bleibt', 'least', 'the', 'find', 'consist', 'trgtext', '1', 'idea', 'michael', 'e', 'wordalign', '11', 'phrase_extract', 'target', 'str', 'stay', 'set', '3', 'languag', 'assum', 'longer', 'pair', '67', 'geht', 'im', 'b', 'that', 'element', 'includ', ']', 'second', 'shortest', '49', '9', 'one', 'minim', 'made', 'counterpart', '36', 'er', 'maxim', 'format', '77', 'sourc', 'indic', 'length', '13', '>', 'int', 'dass', 'sort', 'first', 'rtype', 'phrase', 'A', 'point', 'extract', 'list', 'match', 'done', '[', '59', '0', 'identifi', 'param', '12']}"
101,"{'func name': 'demo', 'comments': 'A demonstration of the porter stemmer on a sample from the Penn Treebank corpus.\n\n\n', 'stemmed comments': ['corpu', 'demonstr', 'porter', 'A', 'treebank', 'sampl', 'stemmer', 'penn']}"
102,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
103,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
104,"{'func name': 'padded_everygram_pipeline', 'comments': 'Default preprocessing for a sequence of sentences.\n\nCreates two iterators:\n\n- sentences padded and turned into sequences of `nltk.util.everygrams`\n\n- sentences padded as above and chained together for a flat stream of words\n\n:param order: Largest ngram length produced by `everygrams`. :param text: Text to iterate over. Expected to be an iterable of sentences: Iterable[Iterable[str]] :return: iterator over text as ngrams, iterator over text as vocabulary data\n', 'stemmed comments': ['return', 'preprocess', 'text', 'word', 'vocabulari', 'str', 'chain', 'everygram', 'length', 'sequenc', 'default', 'two', 'order', 'expect', 'sentenc', 'data', 'iter', 'nltkutileverygram', 'togeth', 'param', ']', 'stream', 'largest', 'pad', 'produc', '[', 'turn', 'creat', 'flat', 'ngram']}"
105,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
106,"{'func name': 'gt_demo', 'comments': '', 'stemmed comments': []}"
107,"{'func name': 'projective_prob_parse_demo', 'comments': 'A demo showing the training and use of a projective dependency parser.\n\n\n', 'stemmed comments': ['demo', 'A', 'project', 'parser', 'show', 'depend', 'use', 'train']}"
108,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
109,"{'func name': 'demo', 'comments': 'Builds a punkt model and applies it to the same text\n\n\n', 'stemmed comments': ['text', 'build', 'model', 'punkt', 'appli']}"
110,"{'func name': 'app', 'comments': 'Create a recursive descent parser demo, using a simple grammar and text.\n\n\n', 'stemmed comments': ['text', 'demo', 'grammar', 'descent', 'parser', 'recurs', 'creat', 'simpl', 'use']}"
111,"{'func name': 'demo', 'comments': 'A demonstration of the recursive descent parser.\n\n\n', 'stemmed comments': ['demonstr', 'A', 'descent', 'parser', 'recurs']}"
112,"{'func name': 'demo', 'comments': 'A demonstration for the ``RegexpChunkParser`` class.  A single text is parsed with four different chunk parsers, using a variety of rules and strategies.\n\n\n', 'stemmed comments': ['demonstr', 'text', 'varieti', 'pars', 'A', 'strategi', 'four', 'class', 'chunk', 'regexpchunkpars', 'parser', 'rule', 'singl', 'use', 'differ']}"
113,"{'func name': 'regexp_tokenize', 'comments': 'Return a tokenized copy of *text*.  See :class:`.RegexpTokenizer` for descriptions of the arguments.\n\n\n', 'stemmed comments': ['return', 'text', 'descript', 'see', 'token', 'class', 'argument', 'regexptoken', 'copi']}"
114,"{'func name': 'ne_chunked', 'comments': '', 'stemmed comments': []}"
115,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
116,"{'func name': 'spearman_rho', 'comments': ""Calculates the Spearman's Rho correlation coefficient given the *worder* list of word alignment from word_rank_alignment(), using the formula\n\nrho = 1\n\n- sum(d**2) / choose(len(worder)+1, 3)\n\nGiven that d is the sum of difference between the *worder* list of indices and the original word indices from the reference sentence.\n\nUsing the (H0,R0) and (H5, R5) example from the paper\n\n>>> worder =\n\n[7, 8, 9, 10, 6, 0, 1, 2, 3, 4, 5] >>> round(spearman_rho(worder, normalize=False), 3) -0.591 >>> round(spearman_rho(worder), 3) 0.205\n\n:param worder: The worder list output from word_rank_alignment :param type: list(int)\n"", 'stemmed comments': ['R0', 's', '1', '4', '8', 'H5', 'word', 'exampl', 'choos', '10', 'formula', 'spearman', 'differ', 'indic', 'len', '3', '>', 'int', 'given', 'align', 'R5', 'use', 'paper', 'sum', 'worder', 'calcul', 'refer', 'coeffici', 'H0', '0205', 'rho', 'word_rank_align', 'normalize=fals', 'round', 'output', 'sentenc', '2', '=', '7', 'list', '6', ']', '0591', 'type', '9', 'origin', 'correl', '[', 'spearman_rho', '/', '0', 'the', 'param', '5']}"
117,"{'func name': 'rte_classifier', 'comments': '', 'stemmed comments': []}"
118,"{'func name': 'norm', 'comments': ""Normalize the string value in an RTE pair's ``value`` or ``entailment`` attribute as an integer (1, 0).\n\nparam value_string: the label used to classify a text/hypothesis pair :type value_string: str :rtype: int\n"", 'stemmed comments': ['s', '1', 'attribut', 'label', 'value_str', 'text/hypothesi', 'str', 'int', 'string', 'pair', 'rtype', 'use', 'rte', 'classifi', 'integ', 'entail', 'valu', 'type', 'normal', '0', 'param']}"
119,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
120,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
121,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
122,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
123,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
124,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
125,"{'func name': '_all_xmlwords_in', 'comments': '', 'stemmed comments': []}"
126,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
127,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
128,"{'func name': '_fixXML', 'comments': 'Fix the various issues with Senseval pseudo-XML.\n\n\n', 'stemmed comments': ['sensev', 'issu', 'pseudoxml', 'fix', 'variou']}"
129,"{'func name': 'demo', 'comments': 'A demonstration of the shift-reduce parser.\n\n\n', 'stemmed comments': ['A', 'parser', 'shiftreduc', 'demonstr']}"
130,"{'func name': 'line_tokenize', 'comments': '', 'stemmed comments': []}"
131,"{'func name': 'to_cnf', 'comments': 'Convert this split disjunction to conjunctive normal form (CNF)\n\n\n', 'stemmed comments': ['normal', 'convert', 'cnf', 'split', 'form', 'disjunct', 'conjunct']}"
132,"{'func name': '_count_non_zero_vals', 'comments': '', 'stemmed comments': []}"
133,"{'func name': 'demo', 'comments': 'This function provides a demonstration of the Snowball stemmers.\n\nAfter invoking this function and specifying a language, it stems an excerpt of the Universal Declaration of Human Rights (which is a part of the NLTK corpus collection) and then prints out the original and the stemmed text.\n', 'stemmed comments': ['stem', 'demonstr', 'text', 'invok', 'part', 'print', 'corpu', 'specifi', 'collect', 'function', 'languag', 'excerpt', 'stemmer', 'snowbal', 'after', 'declar', 'univers', 'provid', 'human', 'right', 'origin', 'thi', 'nltk']}"
134,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
135,"{'func name': 'ranks_from_scores', 'comments': ""Given a sequence of (key, score) tuples, yields each key with an increasing rank, tying with previous key's rank if the difference between their scores is less than rank_gap. Suitable for use as an argument to ``spearman_correlation``.\n\n\n"", 'stemmed comments': ['score', 's', 'suitabl', 'tie', 'rank_gap', 'rank', 'previou', 'less', 'given', 'yield', 'tupl', 'sequenc', 'argument', 'spearman_correl', 'key', 'use', 'increas', 'differ']}"
136,"{'func name': 'app', 'comments': 'Create a shift reduce parser app, using a simple grammar and text.\n\n\n', 'stemmed comments': ['text', 'shift', 'grammar', 'parser', 'reduc', 'creat', 'simpl', 'use', 'app']}"
137,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
138,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
139,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
140,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
141,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
142,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
143,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
144,"{'func name': 'encoding_demo', 'comments': '', 'stemmed comments': []}"
145,"{'func name': 'test_tadm', 'comments': '', 'stemmed comments': []}"
146,"{'func name': 'close_enough', 'comments': 'Verify that two sequences of n-gram association values are within _EPSILON of each other.\n\n\n', 'stemmed comments': ['verifi', 'two', 'associ', 'sequenc', 'within', 'ngram', 'valu', '_epsilon']}"
147,"{'func name': 'stdout_redirect', 'comments': '', 'stemmed comments': []}"
148,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
149,"{'func name': 'are_files_identical', 'comments': 'Compare two files, ignoring carriage returns.\n\n\n', 'stemmed comments': ['return', 'file', 'two', 'carriag', 'ignor', 'compar']}"
150,"{'func name': '_prepare_test_data', 'comments': '', 'stemmed comments': []}"
151,"{'func name': 'teardown_module', 'comments': '', 'stemmed comments': []}"
152,"{'func name': 'setup_module', 'comments': '', 'stemmed comments': []}"
153,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
154,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
155,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
156,"{'func name': 'tgrep_nodes', 'comments': 'Return the tree nodes in the trees which match the given pattern.\n\nparam pattern: a tgrep search pattern :type pattern: str or output of tgrep_compile() :param trees: a sequence of NLTK trees (usually ParentedTrees) :type trees: iter(ParentedTree) or iter(Tree) :param search_leaves: whether ot return matching leaf nodes :type search_leaves: bool :rtype: iter(tree nodes)\n', 'stemmed comments': ['return', 'search', 'bool', 'usual', 'str', 'pattern', 'given', 'tgrep_compil', 'sequenc', 'tgrep', 'rtype', 'search_leav', 'leaf', 'output', 'node', 'whether', 'iter', 'type', 'match', 'param', 'nltk', 'ot', 'parentedtre', 'tree']}"
157,"{'func name': 'read_timit_block', 'comments': 'Block reader for timit tagged sentences, which are preceded by a sentence number that will be ignored.\n\n\n', 'stemmed comments': ['tag', 'preced', 'timit', 'number', 'ignor', 'sentenc', 'block', 'reader']}"
158,"{'func name': 'demo3', 'comments': '', 'stemmed comments': []}"
159,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
160,"{'func name': 'demo', 'comments': '>>> from nltk.parse import DependencyGraph, DependencyEvaluator >>> from nltk.parse.transitionparser import TransitionParser, Configuration, Transition >>> gold_sent = DependencyGraph("""""" ... Economic  JJ     2      ATT ... news  NN     3       SBJ ... has       VBD       0       ROOT ... little      JJ      5       ATT ... effect   NN     3       OBJ ... on     IN      5       ATT ... financial       JJ       8       ATT ... markets    NNS      6       PC ... .    .      3       PU ... """""")\n\n>>> conf = Configuration(gold_sent)\n\n###################### Check the Initial Feature ########################\n\n>>> print(\', \'.join(conf.extract_features())) STK_0_POS_TOP, BUF_0_FORM_Economic, BUF_0_LEMMA_Economic, BUF_0_POS_JJ, BUF_1_FORM_news, BUF_1_POS_NN, BUF_2_POS_VBD, BUF_3_POS_JJ\n\n###################### Check The Transition ####################### Check the Initialized Configuration >>> print(conf) Stack : [0]\n\nBuffer : [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n Arcs : []\n\nA. Do some transition checks for ARC-STANDARD\n\n>>> operation = Transition(\'arc-standard\') >>> operation.shift(conf) >>> operation.left_arc(conf, ""ATT"") >>> operation.shift(conf) >>> operation.left_arc(conf,""SBJ"") >>> operation.shift(conf) >>> operation.shift(conf) >>> operation.left_arc(conf, ""ATT"") >>> operation.shift(conf) >>> operation.shift(conf) >>> operation.shift(conf) >>> operation.left_arc(conf, ""ATT"")\n\nMiddle Configuration and Features Check >>> print(conf) Stack : [0, 3, 5, 6]\n\nBuffer : [8, 9]\n\n Arcs : [(2, \'ATT\', 1), (3, \'SBJ\', 2), (5, \'ATT\', 4), (8, \'ATT\', 7)]\n\n>>> print(\', \'.join(conf.extract_features())) STK_0_FORM_on, STK_0_LEMMA_on, STK_0_POS_IN, STK_1_POS_NN, BUF_0_FORM_markets, BUF_0_LEMMA_markets, BUF_0_POS_NNS, BUF_1_FORM_., BUF_1_POS_., BUF_0_LDEP_ATT\n\n>>> operation.right_arc(conf, ""PC"") >>> operation.right_arc(conf, ""ATT"") >>> operation.right_arc(conf, ""OBJ"") >>> operation.shift(conf) >>> operation.right_arc(conf, ""PU"") >>> operation.right_arc(conf, ""ROOT"") >>> operation.shift(conf)\n\nTerminated Configuration Check >>> print(conf) Stack : [0]\n\nBuffer : []\n\n Arcs : [(2, \'ATT\', 1), (3, \'SBJ\', 2), (5, \'ATT\', 4), (8, \'ATT\', 7), (6, \'PC\', 8), (5, \'ATT\', 6), (3, \'OBJ\', 5), (3, \'PU\', 9), (0, \'ROOT\', 3)]\n\n B. Do some transition checks for ARC-EAGER\n\n>>> conf = Configuration(gold_sent) >>> operation = Transition(\'arc-eager\') >>> operation.shift(conf) >>> operation.left_arc(conf,\'ATT\') >>> operation.shift(conf) >>> operation.left_arc(conf,\'SBJ\') >>> operation.right_arc(conf,\'ROOT\') >>> operation.shift(conf) >>> operation.left_arc(conf,\'ATT\') >>> operation.right_arc(conf,\'OBJ\') >>> operation.right_arc(conf,\'ATT\') >>> operation.shift(conf) >>> operation.left_arc(conf,\'ATT\') >>> operation.right_arc(conf,\'PC\') >>> operation.reduce(conf) >>> operation.reduce(conf) >>> operation.reduce(conf) >>> operation.right_arc(conf,\'PU\') >>> print(conf) Stack : [0, 3, 9]\n\nBuffer : []\n\n Arcs : [(2, \'ATT\', 1), (3, \'SBJ\', 2), (0, \'ROOT\', 3), (5, \'ATT\', 4), (3, \'OBJ\', 5), (5, \'ATT\', 6), (8, \'ATT\', 7), (6, \'PC\', 8), (3, \'PU\', 9)]\n\n###################### Check The Training Function #######################\n\nA. Check the ARC-STANDARD training >>> import tempfile >>> import os >>> input_file = tempfile.NamedTemporaryFile(prefix=\'transition_parse.train\', dir=tempfile.gettempdir(), delete=False)\n\n>>> parser_std = TransitionParser(\'arc-standard\') >>> print(\', \'.join(parser_std._create_training_examples_arc_std([gold_sent], input_file))) Number of training examples : 1 Number of valid (projective) examples : 1 SHIFT, LEFTARC:ATT, SHIFT, LEFTARC:SBJ, SHIFT, SHIFT, LEFTARC:ATT, SHIFT, SHIFT, SHIFT, LEFTARC:ATT, RIGHTARC:PC, RIGHTARC:ATT, RIGHTARC:OBJ, SHIFT, RIGHTARC:PU, RIGHTARC:ROOT, SHIFT\n\n>>> parser_std.train([gold_sent],\'temp.arcstd.model\', verbose=False) Number of training examples : 1 Number of valid (projective) examples : 1 >>> remove(input_file.name)\n\nB. Check the ARC-EAGER training\n\n>>> input_file = tempfile.NamedTemporaryFile(prefix=\'transition_parse.train\', dir=tempfile.gettempdir(),delete=False) >>> parser_eager = TransitionParser(\'arc-eager\') >>> print(\', \'.join(parser_eager._create_training_examples_arc_eager([gold_sent], input_file))) Number of training examples : 1 Number of valid (projective) examples : 1 SHIFT, LEFTARC:ATT, SHIFT, LEFTARC:SBJ, RIGHTARC:ROOT, SHIFT, LEFTARC:ATT, RIGHTARC:OBJ, RIGHTARC:ATT, SHIFT, LEFTARC:ATT, RIGHTARC:PC, REDUCE, REDUCE, REDUCE, RIGHTARC:PU\n\n>>> parser_eager.train([gold_sent],\'temp.arceager.model\', verbose=False) Number of training examples : 1 Number of valid (projective) examples : 1\n\n>>> remove(input_file.name)\n\n###################### Check The Parsing Function ########################\n\nA. Check the ARC-STANDARD parser\n\n>>> result = parser_std.parse([gold_sent], \'temp.arcstd.model\') >>> de = DependencyEvaluator(result, [gold_sent]) >>> de.eval() >= (0, 0) True\n\nB. Check the ARC-EAGER parser >>> result = parser_eager.parse([gold_sent], \'temp.arceager.model\') >>> de = DependencyEvaluator(result, [gold_sent]) >>> de.eval() >= (0, 0) True\n\nRemove test temporary files >>> remove(\'temp.arceager.model\') >>> remove(\'temp.arcstd.model\')\n\nNote that result is very poor because of only one training example.\n', 'stemmed comments': ['transitionpars', '4', 'confextract_featur', 'temparceagermodel', 'B', '8', 'print', 'root', 'effect', 'arceag', 'att', 'de', 'littl', 'verbose=fals', 'buf_1_form_new', 'prefix=transition_parsetrain', 'dir=tempfilegettempdir', 'NN', 'reduc', 'conf', '7', '6', 'deeval', 'parser', 'buf_2_pos_vbd', 'result', 'parser_eag', 'buf_1_form_', 'buf_0_form_econom', 'true', '5', 'financi', 'exampl', 'parser_eagertrain', 'dependencygraph', 'buf_0_pos_nn', 'parser_stdtrain', 'train', 'vbd', 'input_fil', 'oper', 'IN', 'remov', 'valid', 'import', 'join', 'nltkpars', 'project', 'rightarc', 'check', 'operationleft_arc', 'delete=fals', '2', '=', 'poor', 'sbj', 'JJ', 'Do', 'operationshift', 'buf_0_lemma_econom', 'the', 'middl', 'dependencyevalu', 'temporari', '1', 'tempfilenamedtemporaryfil', 'market', 'termin', 'buf_3_pos_jj', 'temparcstdmodel', 'stk_0_pos_in', 'obj', 'buf_0_ldep_att', '3', 'tempfil', 'buf_0_lemma_market', 'function', 'arcstandard', 'configur', 'PU', 'econom', 'stk_0_lemma_on', 'PC', 'featur', ']', 'buf_1_pos_nn', '9', 'one', 'buf_0_pos_jj', 'file', 'os', 'parser_std_create_training_examples_arc_std', 'shift', 'pars', 'leftarc', 'operationright_arc', 'initi', 'stk_0_form_on', 'arc', 'buffer', 'stk_0_pos_top', 'operationreduc', 'parser_eager_create_training_examples_arc_eag', 'stack', '>', 'number', 'test', 'note', 'nn', 'input_filenam', 'parser_eagerpars', 'parser_std', 'stk_1_pos_nn', 'parser_stdpars', 'A', 'gold_sent', 'nltkparsetransitionpars', 'transit', 'buf_0_form_market', 'buf_1_pos_', '[', '0', 'news']}"
161,"{'func name': 'demo', 'comments': 'A demonstration showing how Trees and Trees can be used.  This demonstration creates a Tree, and loads a Tree from the Treebank corpus, and shows the results of calling several of their methods.\n\n\n', 'stemmed comments': ['demonstr', 'load', 'call', 'A', 'sever', 'treebank', 'thi', 'result', 'show', 'creat', 'corpu', 'method', 'use', 'tree']}"
162,"{'func name': 'test', 'comments': 'Do some tree drawing tests.\n\n\n', 'stemmed comments': ['test', 'draw', 'Do', 'tree']}"
163,"{'func name': 'demo', 'comments': 'A demonstration showing how each tree transform can be used.\n\n\n', 'stemmed comments': ['demonstr', 'A', 'show', 'transform', 'use', 'tree']}"
164,"{'func name': 'expand_tweetids_demo', 'comments': 'Given a file object containing a list of Tweet IDs, fetch the corresponding full Tweets, if available.\n\n\n', 'stemmed comments': ['file', 'full', 'avail', 'fetch', 'object', 'contain', 'id', 'given', 'correspond', 'tweet', 'list']}"
165,"{'func name': 'parallelize_preprocess', 'comments': '', 'stemmed comments': []}"
166,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
167,"{'func name': 'check_megam_config', 'comments': 'Checks whether the MEGAM binary is configured.\n\n\n', 'stemmed comments': ['megam', 'binari', 'check', 'whether', 'configur']}"
168,"{'func name': 'cosine_distance', 'comments': 'Returns 1 minus the cosine of the angle between vectors v and u. This is equal to 1 - (u.v / |u||v|).\n\n\n', 'stemmed comments': ['return', '1', 'cosin', 'minu', 'v', 'angl', '/', '|u||v|', 'thi', 'uv', 'u', 'vector', 'equal']}"
169,"{'func name': '_make_bound_method', 'comments': 'Magic for creating bound methods (used for _unload).\n\n\n', 'stemmed comments': ['_unload', 'bound', 'creat', 'method', 'magic', 'use']}"
170,"{'func name': 'tagged_treebank_para_block_reader', 'comments': '', 'stemmed comments': []}"
171,"{'func name': 'demo', 'comments': 'A simple demonstration showing how to use canvas widgets.\n\n\n', 'stemmed comments': ['demonstr', 'A', 'widget', 'show', 'simpl', 'use', 'canva']}"
172,"{'func name': 'log_base2', 'comments': 'Convenience function for computing logarithms with base 2.\n\n\n', 'stemmed comments': ['conveni', 'base', 'logarithm', 'comput', 'function', '2']}"
173,"{'func name': 'extract_test_sentences', 'comments': 'Parses a string with one test sentence per line. Lines can optionally begin with: - a bool, saying if the sentence is grammatical or not, or - an int, giving the number of parse trees is should have, The result information is followed by a colon, and then the sentence. Empty lines and lines beginning with a comment char are ignored.\n\nreturn: a list of tuple of sentences and expected results, where a sentence is a list of str, and a result is None, or bool, or int\n\n:param comment_chars: ``str`` of possible comment characters. :param encoding: the encoding of the string, if it is binary\n', 'stemmed comments': ['return', 'comment_char', 'pars', 'option', 'encod', 'per', 'follow', 'ignor', 'bool', 'say', 'str', 'none', 'number', 'int', 'empti', 'string', 'test', 'begin', 'comment', 'charact', 'tupl', 'expect', 'sentenc', 'char', 'list', 'binari', 'possibl', 'colon', 'inform', 'one', 'line', 'result', 'give', 'the', 'grammat', 'param', 'tree']}"
174,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
175,"{'func name': 'demo_vader_tweets', 'comments': 'Classify 10000 positive and negative tweets using Vader approach.\n\nparam n_instances: the number of total tweets that have to be classified. :param output: the output file where results have to be reported.\n', 'stemmed comments': ['param', 'classifi', 'file', 'approach', 'number', 'total', 'result', 'posit', 'n_instanc', '10000', 'output', 'tweet', 'neg', 'report', 'vader', 'use']}"
176,"{'func name': 'prefix_replace', 'comments': 'Replaces the old prefix of the original string by a new suffix :param original: string :param old: string :param new: string :return: string\n\n\n', 'stemmed comments': ['return', 'suffix', 'replac', 'origin', 'old', 'string', 'new', 'prefix', 'param']}"
177,"{'func name': 'untag', 'comments': ""Given a tagged sentence, return an untagged version of that sentence.  I.e., return a list containing the first element of each tuple in *tagged_sentence*.\n\n>>> from nltk.tag.util import untag >>> untag([('John', 'NNP'), ('saw', 'VBD'), ('Mary', 'NNP')]) ['John', 'saw', 'Mary']\n"", 'stemmed comments': ['return', 'nnp', 'saw', 'tagged_sent', 'version', 'vbd', 'tag', '>', 'given', 'first', 'import', 'contain', 'john', 'Ie', 'tupl', 'element', 'mari', 'sentenc', 'list', ']', 'untag', '[', 'nltktagutil']}"
178,"{'func name': 'align_tokens', 'comments': 'This module attempt to find the offsets of the tokens in *s*, as a sequence of ``(start, end)`` tuples, given the tokens and also the source string.\n\n>>> from nltk.tokenize import TreebankWordTokenizer >>> from nltk.tokenize.util import align_tokens >>> s = str(""The plane, bound for St Petersburg, crashed in Egypt\'s "" ... ""Sinai desert just 23 minutes after take-off from Sharm el-Sheikh "" ... ""on Saturday."") >>> tokens = TreebankWordTokenizer().tokenize(s) >>> expected = [(0, 3), (4, 9), (9, 10), (11, 16), (17, 20), (21, 23), ... (24, 34), (34, 35), (36, 43), (44, 46), (47, 52), (52, 54), ... (55, 60), (61, 67), (68, 72), (73, 75), (76, 83), (84, 89), ... (90, 98), (99, 103), (104, 109), (110, 119), (120, 122), ... (123, 131), (131, 132)] >>> output = list(align_tokens(tokens, s)) >>> len(tokens) == len(expected) == len(output)\n\n# Check that length of tokens and tuples are the same. True >>> expected == list(align_tokens(tokens, s))\n\n# Check that the output is as expected. True >>> tokens == [s[start:end] for start, end in output]\n\n# Check that the slices of the string corresponds to the tokens. True\n\n:param tokens: The list of strings that are the result of tokenization :type tokens: list(str) :param sentence: The original string :type sentence: str :rtype: list(tuple(int,int))\n', 'stemmed comments': ['4', 'slice', '99', '110', 'St', 'align_token', 'attempt', 'tupl', 'output', 'expect', 'sentenc', 'type', 'origin', 'thi', 'correspond', 'result', '23', 'true', '104', 'egypt', 'nltktoken', '10', '109', '122', 'bound', '83', 'end', '131', 'string', 'plane', 'import', 'modul', 'also', 'check', '=', '73', '47', '84', '103', '20', 'treebankwordtoken', 'find', 'the', 'elsheikh', '132', '43', 's', 'minut', '90', 'token', '68', '==', '24', '54', '11', '72', '16', 'str', 'desert', '3', '35', 'given', '89', 'sequenc', '46', 'takeoff', 'start', '67', '61', ']', '123', '9', 'nltktokenizeutil', '17', 'sinai', '98', '36', '75', '34', '119', '44', 'offset', 'sourc', 'len', '120', 'length', '>', 'petersburg', 'int', '60', '76', 'rtype', '55', '52', 'list', '21', '[', 'saturday', '0', 'crash', 'sharm', 'param']}"
179,"{'func name': 'guess_path', 'comments': ""If the path is not absolute, guess that it is a subdirectory of the user's home directory.\n\nparam str pth: The pathname of the directory where files of tweets should be written\n"", 'stemmed comments': ['guess', 's', 'param', 'str', 'pathnam', 'pth', 'file', 'home', 'directori', 'written', 'absolut', 'user', 'the', 'path', 'tweet', 'subdirectori', 'If']}"
180,"{'func name': 'skipIf', 'comments': 'Skip a test if the condition is true.\n\n\n', 'stemmed comments': ['test', 'true', 'condit', 'skip']}"
181,"{'func name': 'demo', 'comments': 'A demonstration of the probabilistic parsers.  The user is prompted to select which demo to run, and how many parses should be found; and then each parser is run on the same demo, and a summary of the results are displayed.\n\n\n', 'stemmed comments': ['probabilist', 'demonstr', 'select', ';', 'demo', 'pars', 'A', 'mani', 'parser', 'result', 'run', 'display', 'user', 'the', 'prompt', 'summari', 'found']}"
182,"{'func name': '_string_lookup', 'comments': 'Looks up one word in the vocabulary.\n\n\n', 'stemmed comments': ['vocabulari', 'word', 'look', 'one']}"
183,"{'func name': '_check_weka_version', 'comments': '', 'stemmed comments': []}"
184,"{'func name': 'word_finder', 'comments': '', 'stemmed comments': []}"
185,"{'func name': 'app', 'comments': '', 'stemmed comments': []}"
186,"{'func name': 'app', 'comments': '', 'stemmed comments': []}"
187,"{'func name': 'teardown_module', 'comments': '', 'stemmed comments': []}"
188,"{'func name': 'teardown_module', 'comments': '', 'stemmed comments': []}"
189,"{'func name': 'teardown_module', 'comments': '', 'stemmed comments': []}"
190,"{'func name': 'lesk', 'comments': 'Return a synset for an ambiguous word in a context.\n\nparam iter context_sentence: The context sentence where the ambiguous word occurs, passed as an iterable of words. :param str ambiguous_word: The ambiguous word that requires WSD. :param str pos: A specified Part-of-Speech (POS). :param iter synsets: Possible synsets of the ambiguous word. :return: ``lesk_sense`` The Synset() object with the highest signature overlaps.\n\nThis function is an implementation of the original Lesk algorithm (1986) [1].\n\nUsage example::\n\n>>> lesk([\'I\', \'went\', \'to\', \'the\', \'bank\', \'to\', \'deposit\', \'money\', \'.\'], \'bank\', \'n\') Synset(\'savings_bank.n.02\')\n\n[1] Lesk, Michael. ""Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone."" Proceedings of the 5th Annual International Conference on Systems Documentation. ACM, 1986. http://dl.acm.org/citation.cfm?id=318728\n', 'stemmed comments': ['return', 'n', '1', 'michael', 'partofspeech', 'usag', 'acm', 'disambigu', 'signatur', 'system', 'deposit', 'word', 'exampl', 'sens', 'http', '?', 'specifi', 'context_sent', 'ice', 'po', 'requir', 'str', 'overlap', 'bank', 'automat', 'readabl', 'highest', '>', 'object', 'went', 'cream', 'function', 'cone', 'lesk', 'confer', 'pass', 'money', 'intern', 'savings_bankn02', 'use', 'machin', 'to', 'tell', 'A', 'id=318728', 'proceed', 'algorithm', 'sentenc', 'context', 'lesk_sens', 'pine', 'iter', ']', '1986', 'possibl', 'document', '//dlacmorg/citationcfm', 'origin', '[', 'I', 'implement', 'synset', 'thi', 'ambigu', 'occur', 'ambiguous_word', 'the', 'annual', 'dictionari', 'wsd', 'param', '5th']}"
191,"{'func name': 'demo', 'comments': '', 'stemmed comments': []}"
