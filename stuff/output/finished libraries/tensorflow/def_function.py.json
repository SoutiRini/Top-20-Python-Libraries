{
    "source file": "def_function.py",
    "line number": "1206",
    "func name": "function",
    "func arg": "(func, input_signature, autograph, experimental_implements, experimental_autograph_options, experimental_relax_shapes, experimental_compile)",
    "comments": "Compiles a function into a callable TensorFlow graph.\n\n`tf.function` constructs a callable that executes a TensorFlow graph (`tf.Graph`) created by trace-compiling the TensorFlow operations in `func`, effectively executing `func` as a TensorFlow graph.\n\nExample usage:\n\n>>> @tf.function ... def f(x, y): ...\n\n return x ** 2 + y >>> x = tf.constant([2, 3]) >>> y = tf.constant([3, -2]) >>> f(x, y) <tf.Tensor: ... numpy=array([7, 7], ...)>\n\n_Features_\n\n`func` may use data-dependent control flow, including `if`, `for`, `while` `break`, `continue` and `return` statements:\n\n>>> @tf.function ... def f(x): ...\n\n if tf.reduce_sum(x) > 0: ...\n\n\n\n return x * x ...\n\n else: ...\n\n\n\n return -x // 2 >>> f(tf.constant(-2)) <tf.Tensor: ... numpy=1>\n\n`func`'s closure may include `tf.Tensor` and `tf.Variable` objects:\n\n>>> @tf.function ... def f(): ...\n\n return x ** 2 + y >>> x = tf.constant([-2, -3]) >>> y = tf.Variable([3, -2]) >>> f() <tf.Tensor: ... numpy=array([7, 7], ...)>\n\n`func` may also use ops with side effects, such as `tf.print`, `tf.Variable` and others:\n\n>>> v = tf.Variable(1) >>> @tf.function ... def f(x): ...\n\n for i in tf.range(x): ...\n\n\n\n v.assign_add(i) >>> f(3) >>> v <tf.Variable ... numpy=4>\n\nImportant: Any Python side-effects (appending to a list, printing with `print`, etc) will only happen once, when `func` is traced. To have side-effects executed into your `tf.function` they need to be written as TF ops:\n\n>>> l = [] >>> @tf.function ... def f(x): ...\n\n for i in x: ...\n\n\n\n l.append(i + 1)\n\n\n\n# Caution! Will only happen once when tracing >>> f(tf.constant([1, 2, 3])) >>> l [<tf.Tensor ...>]\n\nInstead, use TensorFlow collections like `tf.TensorArray`:\n\n>>> @tf.function ... def f(x): ...\n\n ta = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True) ...\n\n for i in range(len(x)): ...\n\n\n\n ta = ta.write(i, x[i] + 1) ...\n\n return ta.stack() >>> f(tf.constant([1, 2, 3])) <tf.Tensor: ..., numpy=array([2, 3, 4], ...)>\n\n_`tf.function` is polymorphic_\n\nInternally, `tf.function` can build more than one graph, to support arguments with different data types or shapes, since TensorFlow can build more efficient graphs that are specialized on shapes and dtypes. `tf.function` also treats any pure Python value as opaque objects, and builds a separate graph for each set of Python arguments that it encounters.\n\nTo obtain an individual graph, use the `get_concrete_function` method of the callable created by `tf.function`. It can be called with the same arguments as `func` and returns a special `tf.Graph` object:\n\n>>> @tf.function ... def f(x): ...\n\n return x + 1 >>> isinstance(f.get_concrete_function(1).graph, tf.Graph) True\n\nCaution: Passing python scalars or lists as arguments to `tf.function` will always build a new graph. To avoid this, pass numeric arguments as Tensors whenever possible:\n\n>>> @tf.function ... def f(x): ...\n\n return tf.abs(x) >>> f1 = f.get_concrete_function(1) >>> f2 = f.get_concrete_function(2)\n\n# Slow\n\n- builds new graph >>> f1 is f2 False >>> f1 = f.get_concrete_function(tf.constant(1)) >>> f2 = f.get_concrete_function(tf.constant(2))\n\n# Fast\n\n- reuses f1 >>> f1 is f2 True\n\nPython numerical arguments should only be used when they take few distinct values, such as hyperparameters like the number of layers in a neural network.\n\n_Input signatures_\n\nFor Tensor arguments, `tf.function` instantiates a separate graph for every unique set of input shapes and datatypes. The example below creates two separate graphs, each specialized to a different shape:\n\n>>> @tf.function ... def f(x): ...\n\n return x + 1 >>> vector = tf.constant([1.0, 1.0]) >>> matrix = tf.constant([[3.0]]) >>> f.get_concrete_function(vector) is f.get_concrete_function(matrix) False\n\nAn \"input signature\" can be optionally provided to `tf.function` to control the graphs traced. The input signature specifies the shape and type of each Tensor argument to the function using a `tf.TensorSpec` object. More general shapes can be used. This is useful to avoid creating multiple graphs when Tensors have dynamic shapes. It also restricts the shape and datatype of Tensors that can be used:\n\n>>> @tf.function( ...\n\n\n\n input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32)]) ... def f(x): ...\n\n return x + 1 >>> vector = tf.constant([1.0, 1.0]) >>> matrix = tf.constant([[3.0]]) >>> f.get_concrete_function(vector) is f.get_concrete_function(matrix) True\n\n_Variables may only be created once_\n\n`tf.function` only allows creating new `tf.Variable` objects when it is called for the first time:\n\n>>> class MyModule(tf.Module): ...\n\n def __init__(self): ...\n\n\n\n self.v = None ... ...\n\n @tf.function ...\n\n def __call__(self, x): ...\n\n\n\n if self.v is None: ...\n\n\n\n\n\n self.v = tf.Variable(tf.ones_like(x)) ...\n\n\n\n return self.v * x\n\nIn general, it is recommended to create stateful objects like `tf.Variable` outside of `tf.function` and passing them as arguments.\n##### Args\n* **func**: the function to be compiled. If `func` is None, `tf.function` returns\n  a decorator that can be invoked with a single argument - `func`. In other\n  words, `tf.function(input_signature=...)(func)` is equivalent to\n  `tf.function(func, input_signature=...)`. The former can be used as\n  decorator.\n\n* **input_signature**: A possibly nested sequence of `tf.TensorSpec` objects\n  specifying the shapes and dtypes of the Tensors that will be supplied to\n  this function. If `None`, a separate function is instantiated for each\n  inferred input signature.  If input_signature is specified, every input to\n  `func` must be a `Tensor`, and `func` cannot accept `**kwargs`.\n\n* **autograph**: Whether autograph should be applied on `func` before tracing a\n  graph. Data-dependent control flow requires `autograph=True`. For more\n  information, see the [tf.function and AutoGraph guide](\n  https\n\n* **experimental_implements**: If provided, contains a name of a \"known\" function\n  this implements. For example \"mycompany.my_recurrent_cell\".\n  This is stored as an attribute in inference function,\n  which can then be detected when processing serialized function.\n  See [standardizing composite ops](https\n\n* **experimental_autograph_options**: Optional tuple of\n  `tf.autograph.experimental.Feature` values.\n\n* **experimental_relax_shapes**: When True, `tf.function` may generate fewer,\n  graphs that are less specialized on input shapes.\n\n* **experimental_compile**: If True, the function is always compiled by\n  [XLA](https\n\n##### Returns\n"
}