{
    "source file": "directives1.py",
    "line number": "50",
    "func name": "set_loop_options",
    "func arg": "(parallel_iterations, swap_memory, maximum_iterations, shape_invariants)",
    "comments": "Specifies additional arguments to be passed to the enclosing while_loop.\n\nThe parameters apply to and only to the immediately enclosing loop. It only has effect if the loop is staged as a TF while_loop; otherwise the parameters have no effect.\n\nUsage:\n\n>>> @tf.function(autograph=True) ... def f(): ...\n\n n = 0 ...\n\n for i in tf.range(10): ...\n\n\n\n tf.autograph.experimental.set_loop_options(maximum_iterations=3) ...\n\n\n\n n += 1 ...\n\n return n\n\n>>> @tf.function(autograph=True) ... def f(): ...\n\n v = tf.constant((0,)) ...\n\n for i in tf.range(3): ...\n\n\n\n tf.autograph.experimental.set_loop_options( ...\n\n\n\n\n\n\n\n shape_invariants=[(v, tf.TensorShape([None]))] ...\n\n\n\n ) ...\n\n\n\n v = tf.concat((v, [i]), 0) ...\n\n return v\n\nAlso see tf.while_loop.\n##### Args\n* **parallel_iterations**: The maximum number of iterations allowed to run in\n    parallel at any given time. Note that this does not guarantee parallel\n    execution.\n\n* **swap_memory**: Whether to store intermediate values needed for\n    gradients on the CPU instead of GPU.\n\n* **maximum_iterations**: Allows limiting the total number of iterations executed\n    by the loop.\n\n* **shape_invariants**: Allows controlling the argument with the same name passed\n    to tf.while_loop. Unlike tf.while_loop, this is a list of\n    `(tensor, shape)` pairs.\n\n"
}