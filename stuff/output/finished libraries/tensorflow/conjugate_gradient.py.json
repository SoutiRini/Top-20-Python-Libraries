{
    "source file": "conjugate_gradient.py",
    "line number": "36",
    "func name": "conjugate_gradient",
    "func arg": "(operator, rhs, preconditioner, x, tol, max_iter, name)",
    "comments": "Conjugate gradient solver.\n\nSolves a linear system of equations `A*x = rhs` for self-adjoint, positive definite matrix `A` and right-hand side vector `rhs`, using an iterative, matrix-free algorithm where the action of the matrix A is represented by `operator`. The iteration terminates when either the number of iterations exceeds `max_iter` or when the residual norm has been reduced to `tol` times its initial value, i.e. \\\\(||rhs\n\n- A x_k|| <= tol ||rhs||\\\\).\n##### Args\n* **operator**: A `LinearOperator` that is self-adjoint and positive definite.\n\n* **rhs**: A possibly batched vector of shape `[..., N]` containing the right-hand\n  size vector.\n\n* **preconditioner**: A `LinearOperator` that approximates the inverse of `A`.\n  An efficient preconditioner could dramatically improve the rate of\n  convergence. If `preconditioner` represents matrix `M`(`M` approximates\n  `A^{-1}`), the algorithm uses `preconditioner.apply(x)` to estimate\n  `A^{-1}x`. For this to be useful, the cost of applying `M` should be\n  much lower than computing `A^{-1}` directly.\n\n* **x**: A possibly batched vector of shape `[..., N]` containing the initial\n  guess for the solution.\n\n* **tol**: A float scalar convergence tolerance.\n\n* **max_iter**: An integer giving the maximum number of iterations.\n\n* **name**: A name scope for the operation.\n\n##### Returns\n* **output**: A namedtuple representing the final state with fields\n\n"
}