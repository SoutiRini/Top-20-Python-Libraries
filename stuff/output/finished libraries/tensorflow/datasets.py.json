{
    "source file": "datasets.py",
    "line number": "50",
    "func name": "StreamingFilesDataset",
    "func arg": "(files, filetype, file_reader_job, worker_job, num_epochs, filename_shuffle_buffer_size, num_parallel_reads, batch_transfer_size, sloppy)",
    "comments": "StreamingFilesDataset constructs a dataset to stream from workers (GCE VM).\n\nBecause Cloud TPUs are allocated over the network, a Cloud TPU cannot read files local to your GCE VM. In order to train using files stored on your local VM (e.g. on local SSD for extreme performance), use the StreamingFilesDataset helper to generate a dataset to feed your Cloud TPU with files from your GCE VM.\n\nThe resulting dataset may return an OutOfRangeError if there are no files found as a result of the fileglob expansion.\n\nNote: StreamingFilesDataset assumes that the session is using a TPUClusterResolver and has therefore a worker and a coordinator job. File loading will be done on the coordinator job.\n##### Args\n* **files**: A string glob to match files, or a `tf.data.Dataset` generating file\n  names.\n\n* **filetype**: A string (one of 'tfrecord', or 'textline') or a single-argument\n  TensorFlow function that when given a filename returns a dataset.\n\n* **file_reader_job**: An optional string that corresponds to the job that should\n  perform the file reads.\n\n* **worker_job**: An optional string that corresponds to the job that should\n  process the tensors (i.e. your GPU or TPU worker).\n\n* **num_epochs**: The number of epochs through the training set that should be\n  generated. By default, it will repeat infinitely.\n\n* **filename_shuffle_buffer_size**: An optional integer whose value controls the\n  shuffling of the file names. If you would like to read from the files in\n  the same order, set to 0 or False.\n\n* **num_parallel_reads**: An optional integer controlling the number of files to\n  read from concurrently. (Set to 1 for no parallelism.)\n\n* **batch_transfer_size**: An optional integer controlling the batching used to\n  amortize the remote function invocation overhead. Set to a very large\n  number to increase throughput. Set to a very small number to reduce memory\n  consumption. Set to False to skip batching.\n\n* **sloppy**: (Optional.) If `False`, read input data while maintaining a\n  deterministic order. (This may have significant performance impacts.)\n  sloppy defaults to\n\n##### Returns\n"
}