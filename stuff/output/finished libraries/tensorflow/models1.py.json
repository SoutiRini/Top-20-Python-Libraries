{
    "source file": "models1.py",
    "line number": "589",
    "func name": "clone_and_build_model",
    "func arg": "(model, input_tensors, target_tensors, custom_objects, compile_clone, in_place_reset, optimizer_iterations, optimizer_config)",
    "comments": "Clone a `Model` and build/compile it with the same settings used before.\n\nThis function can be be run in the same graph or in a separate graph from the model. When using a separate graph, `in_place_reset` must be `False`.\n\nNote that, currently, the clone produced from this function may not work with TPU DistributionStrategy. Try at your own risk.\n##### Args\n* **model**: `tf.keras.Model` object. Can be Functional, Sequential, or\n  sub-classed.\n\n* **input_tensors**: Optional list or dictionary of input tensors to build the\n  model upon. If not provided, placeholders will be created.\n\n* **target_tensors**: Optional list of target tensors for compiling the model. If\n  not provided, placeholders will be created.\n\n* **custom_objects**: Optional dictionary mapping string names to custom classes\n  or functions.\n\n* **compile_clone**: Boolean, whether to compile model clone (default `True`).\n\n* **in_place_reset**: Boolean, whether to reset the model in place. Only used if\n  the model is a subclassed model. In the case of a subclassed model,\n  this argument must be set to `True` (default `False`). To restore the\n  original model, use the function\n  `in_place_subclassed_model_state_restoration(model)`.\n\n* **optimizer_iterations**: An iterations variable that will be incremented by the\n  optimizer if the clone is compiled. This argument is used when a Keras\n  model is cloned into an Estimator model function, because Estimators\n  create their own global step variable.\n\n* **optimizer_config**: Optimizer config dictionary or list of dictionary\n  returned from `get_config()`. This argument should be defined if\n  `clone_and_build_model` is called in a different graph or session from\n  the original model, and the optimizer is an instance of `OptimizerV2`.\n\n##### Returns\n"
}