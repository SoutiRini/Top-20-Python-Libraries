{
    "source file": "legacy_learning_rate_decay.py",
    "line number": "682",
    "func name": "noisy_linear_cosine_decay",
    "func arg": "(learning_rate, global_step, decay_steps, initial_variance, variance_decay, num_periods, alpha, beta, name)",
    "comments": "Applies noisy linear cosine decay to the learning rate.\n\nNote that linear cosine decay is more aggressive than cosine decay and larger initial learning rates can typically be used.\n\nWhen training a model, it is often recommended to lower the learning rate as the training progresses.\n\nThis function applies a noisy linear cosine decay function to a provided initial learning rate. It requires a `global_step` value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.\n\nThe function returns the decayed learning rate.\n\nIt is computed as: ```python global_step = min(global_step, decay_steps) linear_decay = (decay_steps\n\n- global_step) / decay_steps) cosine_decay = 0.5 * ( 1 + cos(pi * 2 * num_periods * global_step / decay_steps)) decayed = (alpha + linear_decay + eps_t) * cosine_decay + beta decayed_learning_rate = learning_rate * decayed ``` where eps_t is 0-centered gaussian noise with variance initial_variance / (1 + global_step) ** variance_decay\n\nExample usage: ```python decay_steps = 1000 lr_decayed = noisy_linear_cosine_decay( learning_rate, global_step, decay_steps) ```\n##### Args\n* **learning_rate**: A scalar `float32` or `float64` Tensor or a Python number.\n  The initial learning rate.\n\n* **global_step**: A scalar `int32` or `int64` `Tensor` or a Python number. Global\n  step to use for the decay computation.\n\n* **decay_steps**: A scalar `int32` or `int64` `Tensor` or a Python number. Number\n  of steps to decay over.\n\n* **initial_variance**: initial variance for the noise. See computation above.\n\n* **variance_decay**: decay for the noise's variance. See computation above.\n\n* **num_periods**: Number of periods in the cosine part of the decay. See\n  computation above.\n\n* **alpha**: See computation above.\n\n* **beta**: See computation above.\n\n* **name**: String.  Optional name of the operation.  Defaults to\n  'NoisyLinearCosineDecay'.\n\n##### Returns\n"
}