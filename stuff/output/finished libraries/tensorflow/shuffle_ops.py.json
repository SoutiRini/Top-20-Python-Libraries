{
    "source file": "shuffle_ops.py",
    "line number": "60",
    "func name": "shuffle_and_repeat",
    "func arg": "(buffer_size, count, seed)",
    "comments": "Shuffles and repeats a Dataset, reshuffling with each repetition.\n\n>>> d = tf.data.Dataset.from_tensor_slices([1, 2, 3]) >>> d = d.apply(tf.data.experimental.shuffle_and_repeat(2, count=2)) >>> [elem.numpy() for elem in d] # doctest: +SKIP [2, 3, 1, 1, 3, 2]\n\n```python dataset.apply( tf.data.experimental.shuffle_and_repeat(buffer_size, count, seed)) ```\n\nproduces the same output as\n\n```python dataset.shuffle( buffer_size, seed=seed, reshuffle_each_iteration=True).repeat(count) ```\n\nIn each repetition, this dataset fills a buffer with `buffer_size` elements, then randomly samples elements from this buffer, replacing the selected elements with new elements. For perfect shuffling, set the buffer size equal to the full size of the dataset.\n\nFor instance, if your dataset contains 10,000 elements but `buffer_size` is set to 1,000, then `shuffle` will initially select a random element from only the first 1,000 elements in the buffer. Once an element is selected, its space in the buffer is replaced by the next (i.e. 1,001-st) element, maintaining the 1,000 element buffer.\n##### Args\n* **buffer_size**: A `tf.int64` scalar `tf.Tensor`, representing the maximum\n  number elements that will be buffered when prefetching.\n\n* **count**: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the number\n  of times the dataset should be repeated. The default behavior (if `count`\n  is `None` or `-1`) is for the dataset be repeated indefinitely.\n\n* **seed**: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\n  seed that will be used to create the distribution. See\n  `tf.random.set_seed` for behavior.\n\n##### Returns\n"
}