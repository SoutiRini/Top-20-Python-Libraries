{
    "source file": "tpu_ops.py",
    "line number": "450",
    "func name": "enqueue_tpu_embedding_ragged_tensor_batch",
    "func arg": "(sample_splits, embedding_indices, aggregation_weights, table_ids, device_ordinal, max_sequence_lengths, combiners, mode_override, name)",
    "comments": "A placeholder op for enqueueing embedding IDs to the TPU.\n\n\n##### Args\n* **sample_splits**: A list of rank 1 Tensors specifying the break points for\n  splitting embedding_indices and aggregation_weights into rows. It\n  corresponds to ids.row_splits in embedding_lookup(), when ids is a\n  RaggedTensor. Both int32 and int64 are allowed and will be converted to\n  int32 internally.\n\n* **embedding_indices**: A list of rank 1 Tensors, indices into the embedding\n  tables. It corresponds to ids.values in embedding_lookup(), when ids is a\n  RaggedTensor. Both int32 and int64 are allowed and will be converted to\n  int32 internally.\n\n* **aggregation_weights**: A list of rank 1 Tensors containing per training\n  example aggregation weights. It corresponds to the values field of a\n  RaggedTensor with the same row_splits as ids in embedding_lookup(), when\n  ids is a RaggedTensor. Both float32 and float64 are allowed and will be\n  converted to float32 internally.\n\n* **table_ids**: A list of integers specifying the identifier of the embedding\n  table (offset of TableDescriptor in the TPUEmbeddingConfiguration) to\n  lookup the corresponding input. The ith input is looked up using\n  table_ids[i]. The size of the table_ids list must be equal to that of\n  sample_indices, embedding_indices and aggregation_weights.\n\n* **device_ordinal**: The TPU device to use. Should be >= 0 and less than the\n  number of TPU cores in the task on which the node is placed.\n\n* **max_sequence_lengths**: A list of integers, the size of which is equal to\n  sample_indices. If equal to 0, the corresponding feature is considered to\n  be a non-sequence feature, If greater than 0, the corresponding feature is\n  a sequence feature with the given maximal length. If None, then we assume\n  a list of all zeroes.\n\n* **combiners**: A list of string scalars, one for each embedding table that\n  specify how to normalize the embedding activations after weighted\n  summation. Supported combiners are 'mean', 'sum', or 'sqrtn'. It is\n  invalid to have the sum of the weights be 0 for 'mean' or the sum of the\n  squared weights be 0 for 'sqrtn'. If combiners isn't passed, the default\n  is to use 'sum' for all tables (optional).\n\n* **mode_override**: A string input that overrides the mode specified in the\n  TPUEmbeddingConfiguration. Supported values are {'unspecified',\n  'inference', 'training', 'backward_pass_only'}. When set to 'unspecified',\n  the mode set in TPUEmbeddingConfiguration is used, otherwise mode_override\n  is used (optional).\n\n* **name**: A name for the operation (optional).\n\n##### Returns\n"
}