{
    "source file": "trt_convert.py",
    "line number": "1270",
    "func name": "create_inference_graph",
    "func arg": "(input_graph_def, outputs, max_batch_size, max_workspace_size_bytes, precision_mode, minimum_segment_size, is_dynamic_op, maximum_cached_engines, input_saved_model_dir, input_saved_model_tags, input_saved_model_signature_key, output_saved_model_dir, session_config)",
    "comments": "Python wrapper for the TRT transformation.\n\n\n##### Args\n* **input_graph_def**: a GraphDef object containing a model to be transformed. If\n  set to None, the graph will be read from the SavedModel loaded from\n  input_saved_model_dir.\n\n* **outputs**: list of tensors or node names for the model outputs. Only used when\n  input_graph_def is not None.\n\n* **max_batch_size**: max size for the input batch.\n\n* **max_workspace_size_bytes**: the maximum GPU temporary memory which the TRT\n  engine can use at execution time. This corresponds to the 'workspaceSize'\n  parameter of nvinfer1\n\n* **precision_mode**: one of TrtPrecisionMode.supported_precision_modes().\n\n* **minimum_segment_size**: the minimum number of nodes required for a subgraph to\n  be replaced by TRTEngineOp.\n\n* **is_dynamic_op**: whether to generate dynamic TRT ops which will build the TRT\n  network and engine at run time.\n\n* **maximum_cached_engines**: max number of cached TRT engines in dynamic TRT ops.\n  If the number of cached engines is already at max but none of them can\n  serve the input, the TRTEngineOp will fall back to run the TF function\n  based on which the TRTEngineOp is created.\n\n* **input_saved_model_dir**: the directory to load the SavedModel which contains\n  the input graph to transforms. Used only when input_graph_def is None.\n\n* **input_saved_model_tags**: list of tags to load the SavedModel.\n\n* **input_saved_model_signature_key**: the key of the signature to optimize the\n  graph for.\n\n* **output_saved_model_dir**: if not None, construct a SavedModel using the\n  returned GraphDef and save it to the specified directory. This option only\n  works when the input graph is loaded from a SavedModel, i.e. when\n  input_saved_model_dir is specified and input_graph_def is None.\n\n* **session_config**: the ConfigProto used to create a Session. It's also used as\n  a template to create a TRT-enabled ConfigProto for conversion. If not\n  specified, a default ConfigProto will be used.\n\n##### Returns\n"
}