{
    "source file": "rnn1.py",
    "line number": "1520",
    "func name": "static_bidirectional_rnn",
    "func arg": "(cell_fw, cell_bw, inputs, initial_state_fw, initial_state_bw, dtype, sequence_length, scope)",
    "comments": "Creates a bidirectional recurrent neural network.\n\nSimilar to the unidirectional case above (rnn) but takes input and builds independent forward and backward RNNs with the final forward and backward outputs depth-concatenated, such that the output will have the format [time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of forward and backward cell must match. The initial state for both directions is zero by default (but can be set optionally) and no intermediate states are ever returned -- the network is fully unrolled for the given (passed in) length(s) of the sequence(s) or completely unrolled if length(s) is not given.\n##### Args\n* **cell_fw**: An instance of RNNCell, to be used for forward direction.\n\n* **cell_bw**: An instance of RNNCell, to be used for backward direction.\n\n* **inputs**: A length T list of inputs, each a tensor of shape [batch_size,\n  input_size], or a nested tuple of such elements.\n\n* **initial_state_fw**: (optional) An initial state for the forward RNN. This must\n  be a tensor of appropriate type and shape `[batch_size,\n  cell_fw.state_size]`. If `cell_fw.state_size` is a tuple, this should be a\n  tuple of tensors having shapes `[batch_size, s] for s in\n  cell_fw.state_size`.\n\n* **initial_state_bw**: (optional) Same as for `initial_state_fw`, but using the\n  corresponding properties of `cell_bw`.\n\n* **dtype**: (optional) The data type for the initial state.  Required if either\n  of the initial states are not provided.\n\n* **sequence_length**: (optional) An int32/int64 vector, size `[batch_size]`,\n  containing the actual lengths for each of the sequences.\n\n* **scope**: VariableScope for the created subgraph; defaults to\n  \"bidirectional_rnn\"\n\n##### Returns\n* **A tuple (outputs, output_state_fw, output_state_bw) where**: outputs is a length `T` list of outputs (one for each input), which\n    are depth-concatenated forward and backward outputs.\n  output_state_fw is the final state of the forward rnn.\n  output_state_bw is the final state of the backward rnn.\n\n"
}