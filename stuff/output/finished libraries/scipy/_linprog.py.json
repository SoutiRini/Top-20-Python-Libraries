{
    "source file": "_linprog.py",
    "line number": "163",
    "func name": "linprog",
    "func arg": "(c, A_ub, b_ub, A_eq, b_eq, bounds, method, callback, options, x0)",
    "comments": "Linear programming: minimize a linear objective function subject to linear equality and inequality constraints.\n\nLinear programming solves problems of the following form:\n\n.. math::\n\n\\min_x \\ & c^T x \\\\ \\mbox{such that} \\ & A_{ub} x \\leq b_{ub},\\\\ & A_{eq} x = b_{eq},\\\\ & l \\leq x \\leq u ,\n\nwhere :math:`x` is a vector of decision variables; :math:`c`, :math:`b_{ub}`, :math:`b_{eq}`, :math:`l`, and :math:`u` are vectors; and :math:`A_{ub}` and :math:`A_{eq}` are matrices.\n\nInformally, that's:\n\nminimize::\n\nc @ x\n\nsuch that::\n\nA_ub @ x <= b_ub A_eq @ x == b_eq lb <= x <= ub\n\nNote that by default ``lb = 0`` and ``ub = None`` unless specified with ``bounds``.\n\nParameters ---------- c : 1-D array The coefficients of the linear objective function to be minimized. A_ub : 2-D array, optional The inequality constraint matrix. Each row of ``A_ub`` specifies the coefficients of a linear inequality constraint on ``x``. b_ub : 1-D array, optional The inequality constraint vector. Each element represents an upper bound on the corresponding value of ``A_ub @ x``. A_eq : 2-D array, optional The equality constraint matrix. Each row of ``A_eq`` specifies the coefficients of a linear equality constraint on ``x``. b_eq : 1-D array, optional The equality constraint vector. Each element of ``A_eq @ x`` must equal the corresponding element of ``b_eq``. bounds : sequence, optional A sequence of ``(min, max)`` pairs for each element in ``x``, defining the minimum and maximum values of that decision variable. Use ``None`` to indicate that there is no bound. By default, bounds are ``(0, None)`` (all decision variables are non-negative). If a single tuple ``(min, max)`` is provided, then ``min`` and ``max`` will serve as bounds for all decision variables. method : {'interior-point', 'revised simplex', 'simplex'}, optional The algorithm used to solve the standard form problem. :ref:`'interior-point' <optimize.linprog-interior-point>` (default), :ref:`'revised simplex' <optimize.linprog-revised_simplex>`, and :ref:`'simplex' <optimize.linprog-simplex>` (legacy) are supported. callback : callable, optional If a callback function is provided, it will be called at least once per iteration of the algorithm. The callback function must accept a single `scipy.optimize.OptimizeResult` consisting of the following fields:\n\nx : 1-D array The current solution vector. fun : float The current value of the objective function ``c @ x``. success : bool ``True`` when the algorithm has completed successfully. slack : 1-D array The (nominally positive) values of the slack, ``b_ub\n\n- A_ub @ x``. con : 1-D array The (nominally zero) residuals of the equality constraints, ``b_eq\n\n- A_eq @ x``. phase : int The phase of the algorithm being executed. status : int An integer representing the status of the algorithm.\n\n``0`` : Optimization proceeding nominally.\n\n``1`` : Iteration limit reached.\n\n``2`` : Problem appears to be infeasible.\n\n``3`` : Problem appears to be unbounded.\n\n``4`` : Numerical difficulties encountered.\n\nnit : int The current iteration number. message : str A string descriptor of the algorithm status.\n\noptions : dict, optional A dictionary of solver options. All methods accept the following options:\n\nmaxiter : int Maximum number of iterations to perform. Default: see method-specific documentation. disp : bool Set to ``True`` to print convergence messages. Default: ``False``. autoscale : bool Set to ``True`` to automatically perform equilibration. Consider using this option if the numerical values in the constraints are separated by several orders of magnitude. Default: ``False``. presolve : bool Set to ``False`` to disable automatic presolve. Default: ``True``. rr : bool Set to ``False`` to disable automatic redundancy removal. Default: ``True``.\n\nFor method-specific options, see :func:`show_options('linprog') <show_options>`.\n\nx0 : 1-D array, optional Guess values of the decision variables, which will be refined by the optimization algorithm. This argument is currently used only by the 'revised simplex' method, and can only be used if `x0` represents a basic feasible solution.\n##### Returns\n* **res **: OptimizeResult\n    A\n\n* **show_options **: Additional options accepted by the solvers.\n\n* ****: ref\n\n* **.. versionadded**: \n\n* **problem simplifications. Specifically, it checks for**: \n\n* **Several potential improvements can be made here**: additional presolve\n\n* **.. [3] Bland, Robert G. New finite pivoting rules for the simplex method.\n       Mathematics of Operations Research (2), 1977**: pp. 103-107.\n\n* **.. [4] Andersen, Erling D., and Knud D. Andersen. \"The MOSEK interior point\n       optimizer for linear programming**: an implementation of the\n       homogeneous algorithm.\" High performance optimization. Springer US,\n       2000. 197-232.\n\n* **.. [5] Andersen, Erling D. \"Finding all linearly dependent rows in\n       large-scale linear programming.\" Optimization Methods and Software\n       6.3 (1995)**: 219-227.\n\n* **.. [6] Freund, Robert M. \"Primal-Dual Interior-Point Methods for Linear\n       Programming based on Newton's Method.\" Unpublished Course Notes,\n       March 2004. Available 2/25/2017 at\n       https**: //ocw.mit.edu/courses/sloan-school-of-management/15-084j-nonlinear-programming-spring-2004/lecture-notes/lec14_int_pt_mthd.pdf\n\n* **.. [7] Fourer, Robert. \"Solving Linear Programs by Interior-Point Methods.\"\n       Unpublished Course Notes, August 26, 2005. Available 2/25/2017 at\n       http**: //www.4er.org/CourseNotes/Book%20B/B-III.pdf\n\n* **.. [8] Andersen, Erling D., and Knud D. Andersen. \"Presolving in linear\n       programming.\" Mathematical Programming 71.2 (1995)**: 221-245.\n\n* **.. [9] Bertsimas, Dimitris, and J. Tsitsiklis. \"Introduction to linear\n       programming.\" Athena Scientific 1 (1997)**: 997.\n\n* **.. [11] Bartels, Richard H. \"A stabilization of the simplex method.\"\n        Journal in  Numerische Mathematik 16.5 (1971)**: 414-434.\n\n* **.. [12] Tomlin, J. A. \"On scaling linear programming problems.\"\n        Mathematical Programming Study 4 (1975)**: 146-166.\n\n* **Consider the following problem**: \n\n* **.. math**: \n\n* **multiplying both sides by a factor of **: math\n\n* **constraint is really the simple bound **: math\n\n* **Finally, since there are no bounds on **: math\n\n* **specify the bounds **: math\n\n* **into arrays and tuples, the input for this problem is**: \n\n* **>>> print(res)\n     con**: array([], dtype=float64)\n     fun\n\n"
}