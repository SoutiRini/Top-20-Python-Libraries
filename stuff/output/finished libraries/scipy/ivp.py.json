{
    "source file": "ivp.py",
    "line number": "156",
    "func name": "solve_ivp",
    "func arg": "(fun, t_span, y0, method, t_eval, dense_output, events, vectorized, args, **options)",
    "comments": "Solve an initial value problem for a system of ODEs.\n\nThis function numerically integrates a system of ordinary differential equations given an initial value::\n\ndy / dt = f(t, y) y(t0) = y0\n\nHere t is a 1-D independent variable (time), y(t) is an N-D vector-valued function (state), and an N-D vector-valued function f(t, y) determines the differential equations. The goal is to find y(t) approximately satisfying the differential equations, given an initial value y(t0)=y0.\n\nSome of the solvers support integration in the complex domain, but note that for stiff ODE solvers, the right-hand side must be complex-differentiable (satisfy Cauchy-Riemann equations [11]_). To solve a problem in the complex domain, pass y0 with a complex data type. Another option always available is to rewrite your problem for real and imaginary parts separately.\n\nParameters ---------- fun : callable Right-hand side of the system. The calling signature is ``fun(t, y)``. Here `t` is a scalar, and there are two options for the ndarray `y`: It can either have shape (n,); then `fun` must return array_like with shape (n,). Alternatively, it can have shape (n, k); then `fun` must return an array_like with shape (n, k), i.e., each column corresponds to a single column in `y`. The choice between the two options is determined by `vectorized` argument (see below). The vectorized implementation allows a faster approximation of the Jacobian by finite differences (required for stiff solvers). t_span : 2-tuple of floats Interval of integration (t0, tf). The solver starts with t=t0 and integrates until it reaches t=tf. y0 : array_like, shape (n,) Initial state. For problems in the complex domain, pass `y0` with a complex data type (even if the initial value is purely real). method : string or `OdeSolver`, optional Integration method to use:\n\n* 'RK45' (default): Explicit Runge-Kutta method of order 5(4) [1]_. The error is controlled assuming accuracy of the fourth-order method, but steps are taken using the fifth-order accurate formula (local extrapolation is done). A quartic interpolation polynomial is used for the dense output [2]_. Can be applied in the complex domain. * 'RK23': Explicit Runge-Kutta method of order 3(2) [3]_. The error is controlled assuming accuracy of the second-order method, but steps are taken using the third-order accurate formula (local extrapolation is done). A cubic Hermite polynomial is used for the dense output. Can be applied in the complex domain. * 'DOP853': Explicit Runge-Kutta method of order 8 [13]_. Python implementation of the \"DOP853\" algorithm originally written in Fortran [14]_. A 7-th order interpolation polynomial accurate to 7-th order is used for the dense output. Can be applied in the complex domain. * 'Radau': Implicit Runge-Kutta method of the Radau IIA family of order 5 [4]_. The error is controlled with a third-order accurate embedded formula. A cubic polynomial which satisfies the collocation conditions is used for the dense output. * 'BDF': Implicit multi-step variable-order (1 to 5) method based on a backward differentiation formula for the derivative approximation [5]_. The implementation follows the one described in [6]_. A quasi-constant step scheme is used and accuracy is enhanced using the NDF modification. Can be applied in the complex domain. * 'LSODA': Adams/BDF method with automatic stiffness detection and switching [7]_, [8]_. This is a wrapper of the Fortran solver from ODEPACK.\n\nExplicit Runge-Kutta methods ('RK23', 'RK45', 'DOP853') should be used for non-stiff problems and implicit methods ('Radau', 'BDF') for stiff problems [9]_. Among Runge-Kutta methods, 'DOP853' is recommended for solving with high precision (low values of `rtol` and `atol`).\n\nIf not sure, first try to run 'RK45'. If it makes unusually many iterations, diverges, or fails, your problem is likely to be stiff and you should use 'Radau' or 'BDF'. 'LSODA' can also be a good universal choice, but it might be somewhat less convenient to work with as it wraps old Fortran code.\n\nYou can also pass an arbitrary class derived from `OdeSolver` which implements the solver. t_eval : array_like or None, optional Times at which to store the computed solution, must be sorted and lie within `t_span`. If None (default), use points selected by the solver. dense_output : bool, optional Whether to compute a continuous solution. Default is False. events : callable, or list of callables, optional Events to track. If None (default), no events will be tracked. Each event occurs at the zeros of a continuous function of time and state. Each function must have the signature ``event(t, y)`` and return a float. The solver will find an accurate value of `t` at which ``event(t, y(t)) = 0`` using a root-finding algorithm. By default, all zeros will be found. The solver looks for a sign change over each step, so if multiple zero crossings occur within one step, events may be missed. Additionally each `event` function might have the following attributes:\n\nterminal: bool, optional Whether to terminate integration if this event occurs. Implicitly False if not assigned. direction: float, optional Direction of a zero crossing. If `direction` is positive, `event` will only trigger when going from negative to positive, and vice versa if `direction` is negative. If 0, then either direction will trigger event. Implicitly 0 if not assigned.\n\nYou can assign attributes like ``event.terminal = True`` to any function in Python. vectorized : bool, optional Whether `fun` is implemented in a vectorized fashion. Default is False. args : tuple, optional Additional arguments to pass to the user-defined functions.\n\nIf given, the additional arguments are passed to all user-defined functions. So if, for example, `fun` has the signature ``fun(t, y, a, b, c)``, then `jac` (if given) and any event functions must have the same signature, and `args` must be a tuple of length 3. options Options passed to a chosen solver. All options available for already implemented solvers are listed below. first_step : float or None, optional Initial step size. Default is `None` which means that the algorithm should choose. max_step : float, optional Maximum allowed step size. Default is np.inf, i.e., the step size is not bounded and determined solely by the solver. rtol, atol : float or array_like, optional Relative and absolute tolerances. The solver keeps the local error estimates less than ``atol + rtol * abs(y)``. Here `rtol` controls a relative accuracy (number of correct digits). But if a component of `y` is approximately below `atol`, the error only needs to fall within the same `atol` threshold, and the number of correct digits is not guaranteed. If components of y have different scales, it might be beneficial to set different `atol` values for different components by passing array_like with shape (n,) for `atol`. Default values are 1e-3 for `rtol` and 1e-6 for `atol`. jac : array_like, sparse_matrix, callable or None, optional Jacobian matrix of the right-hand side of the system with respect to y, required by the 'Radau', 'BDF' and 'LSODA' method. The Jacobian matrix has shape (n, n) and its element (i, j) is equal to ``d f_i / d y_j``.\n\nThere are three ways to define the Jacobian:\n\n* If array_like or sparse_matrix, the Jacobian is assumed to be constant. Not supported by 'LSODA'. * If callable, the Jacobian is assumed to depend on both t and y; it will be called as ``jac(t, y)``, as necessary. For 'Radau' and 'BDF' methods, the return value might be a sparse matrix. * If None (default), the Jacobian will be approximated by finite differences.\n\nIt is generally recommended to provide the Jacobian rather than relying on a finite-difference approximation. jac_sparsity : array_like, sparse matrix or None, optional Defines a sparsity structure of the Jacobian matrix for a finite- difference approximation. Its shape must be (n, n). This argument is ignored if `jac` is not `None`. If the Jacobian has only few non-zero elements in *each* row, providing the sparsity structure will greatly speed up the computations [10]_. A zero entry means that a corresponding element in the Jacobian is always zero. If None (default), the Jacobian is assumed to be dense. Not supported by 'LSODA', see `lband` and `uband` instead. lband, uband : int or None, optional Parameters defining the bandwidth of the Jacobian for the 'LSODA' method, i.e., ``jac[i, j] != 0 only for i\n\n- lband <= j <= i + uband``. Default is None. Setting these requires your jac routine to return the Jacobian in the packed format: the returned array must have ``n`` columns and ``uband + lband + 1`` rows in which Jacobian diagonals are written. Specifically ``jac_packed[uband + i\n\n- j , j] = jac[i, j]``. The same format is used in `scipy.linalg.solve_banded` (check for an illustration).\n\nThese parameters can be also used with ``jac=None`` to reduce the number of Jacobian elements estimated by finite differences. min_step : float, optional The minimum allowed step size for 'LSODA' method. By default `min_step` is zero.\n##### Returns\n* **Bunch object with the following fields defined**: \n\n* **t **: ndarray, shape (n_points,)\n    Time points.\n\n* **y **: ndarray, shape (n, n_points)\n    Values of the solution at `t`.\n\n* **sol **: `OdeSolution` or None\n    Found solution as `OdeSolution` instance; None if `dense_output` was\n    set to False.\n\n* **t_events **: list of ndarray or None\n    Contains for each event type a list of arrays at which an event of\n    that type event was detected. None if `events` was None.\n\n* **y_events **: list of ndarray or None\n    For each value of `t_events`, the corresponding value of the solution.\n    None if `events` was None.\n\n* **nfev **: int\n    Number of evaluations of the right-hand side.\n\n* **njev **: int\n    Number of evaluations of the Jacobian.\n\n* **nlu **: int\n    Number of LU decompositions.\n\n* **status **: int\n    Reason for algorithm termination\n\n* **message **: string\n    Human-readable description of the termination reason.\n\n* **success **: bool\n    True if the solver reached the interval end or a termination event\n    occurred (``status >= 0``).\n\n* **.. [4] E. Hairer, G. Wanner, \"Solving Ordinary Differential Equations II**: Stiff and Differential-Algebraic Problems\", Sec. IV.8.\n\n* **.. [5] `Backward Differentiation Formula\n        <https**: //en.wikipedia.org/wiki/Backward_differentiation_formula>`_\n        on Wikipedia.\n\n* **.. [9] `Stiff equation <https**: //en.wikipedia.org/wiki/Stiff_equation>`_ on\n       Wikipedia.\n\n* **.. [11] `Cauchy-Riemann equations\n         <https**: //en.wikipedia.org/wiki/Cauchy-Riemann_equations>`_ on\n         Wikipedia.\n\n* **.. [12] `Lotka-Volterra equations\n        <https**: //en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations>`_\n        on Wikipedia.\n\n* **.. [13] E. Hairer, S. P. Norsett G. Wanner, \"Solving Ordinary Differential\n        Equations I**: Nonstiff Problems\", Sec. II.\n\n* **.. [14] `Page with original Fortran code of DOP853\n        <http**: //www.unige.ch/~hairer/software.html>`_.\n\n* **>>> def exponential_decay(t, y)**: return -0.5 * y\n\n* **>>> def upward_cannon(t, y)**: return [y[1], -0.5]\n\n* **>>> def hit_ground(t, y)**: return y[0]\n\n* **>>> def apex(t, y)**: return y[1]\n\n* **>>> def lotkavolterra(t, z, a, b, c, d)**: \n\n"
}